[
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_10/a",
        "context": "You are trying to reverse-engineer the characteristics of a cache in a system, so that you can design a more efficient, machine-specific implementation of an algorithm you are working on. To do so, you have come up with three sequences of memory accesses to various bytes in the system in an attempt to determine the following four cache characteristics: Cache block size (8, 16, 32, 64, or 128B), Cache associativity (2-, 4-, or 8-way), Cache replacement policy (LRU or FIFO), Cache size (4 or 8KiB).\nCache hit rate is 2/8 in sequence 1. This means that there are 2 hits. Depending on the cache block size, we can group addresses that belong to the same cache block as follows:",
        "context_figures": [
            "chart_p23_0.png"
        ],
        "question": "Cache block size (8, 16, 32, 64, or 128B)?",
        "solution": "16 B. Cache hit rate is 2/8 in sequence 1. This means that there are 2 hits. Depending on the cache block size, we can group addresses that belong to the same cache block as follows: 8B: {0}, {16}, {24,25}, {255}, {305}, {1024}, {1100}. \u2234 Number of possible hits = 1. 16B: {0}, {16,24,25}, {255}, {305}, {1024}, {1100}. \u2234 Number of possible hits = 2. 32B: {0,16,24,25}, {255}, {305}, {1024}, {1100}. \u2234 Number of possible hits = 3. 64B: {0,16,24,25}, {255,305}, {1024}, {1100}. \u2234 Number of possible hits = 4. 128B: {0,16,24,25}, {255,305}, {1024,1100}. \u2234 Number of possible hits = 5. Therefore, we can know that the cache block size is 16B.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_10/b",
        "context": "You are trying to reverse-engineer the characteristics of a cache in a system, so that you can design a more efficient, machine-specific implementation of an algorithm you are working on. To do so, you have come up with three sequences of memory accesses to various bytes in the system in an attempt to determine the following four cache characteristics: Cache block size (8, 16, 32, 64, or 128B), Cache associativity (2-, 4-, or 8-way), Cache replacement policy (LRU or FIFO), Cache size (4 or 8KiB).\nCache hit rate is 3/8 in sequence 2, which means that there are 3 hits. We already know that the cache block size is 16B. Thus, there are 4 offset bits.",
        "context_figures": [
            "chart_p23_0.png"
        ],
        "question": "Cache associativity (2-, 4-, or 8-way)?",
        "solution": "2-way. Cache hit rate is 3/8 in sequence 2, which means that there are 3 hits. We already know that the cache block size is 16B. Thus, there are 4 offset bits. The access to address 31 in sequence 2 would hit because the cache block would not be replaced. The access to address 305 in sequence 2 would hit because the cache block would not be replaced. The access to address 65537 in sequence 2 would hit because the cache block would not be replaced. Therefore, all the other accesses should miss. The access to address 65536, 131072 and 262144 in sequence 2 would miss because addresses 65536, 131072 and 262144 do not belong to any cache block previously accessed. Addresses 65536, 131072 and 262144 would be placed in set 0 if the cache associativity is 2-way, 4-way, or 8-way, independently of the cache size. Address 8 must be a miss, so its cache block must be replaced by cache blocks that map to set 0 (addresses 65536, 131072 and 262144). For this to happen, the associativity must be 2-way. Therefore, the cache is 2-way associative.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_10/c",
        "context": "You are trying to reverse-engineer the characteristics of a cache in a system, so that you can design a more efficient, machine-specific implementation of an algorithm you are working on. To do so, you have come up with three sequences of memory accesses to various bytes in the system in an attempt to determine the following four cache characteristics: Cache block size (8, 16, 32, 64, or 128B), Cache associativity (2-, 4-, or 8-way), Cache replacement policy (LRU or FIFO), Cache size (4 or 8KiB).\nFrom questions (a) and (b), we already know the following facts: The cache block size is 16 B. The cache is 2-way.",
        "context_figures": [
            "chart_p23_0.png"
        ],
        "question": "Cache replacement policy (LRU or FIFO)?",
        "solution": "FIFO. Cache hit rate is 2/3 in sequence 3, which means that there are 2 hits. With the LRU policy only the access to address 262145 in sequence 3 would hit. With the FIFO policy, accesses to addresses 262145 and 4 in sequence 3 would hit. Therefore, the cache adopts the FIFO policy.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_10/d",
        "context": "You are trying to reverse-engineer the characteristics of a cache in a system, so that you can design a more efficient, machine-specific implementation of an algorithm you are working on. To do so, you have come up with three sequences of memory accesses to various bytes in the system in an attempt to determine the following four cache characteristics: Cache block size (8, 16, 32, 64, or 128B), Cache associativity (2-, 4-, or 8-way), Cache replacement policy (LRU or FIFO), Cache size (4 or 8KiB).\nFrom questions (a), (b) and (c), we already know the following facts: The cache block size is 16 B. The cache is 2-way. FIFO replacement policy",
        "context_figures": [
            "chart_p23_0.png"
        ],
        "question": "To identify the cache size (4 or 8KiB), you can access two addresses right after sequence 3 (i.e., the contents are the same as at the end of the third sequence) and measure the cache hit rate. Which two addresses would you choose? Explain your answer (there may be several correct answers).",
        "solution": "Address 2048 and address 0 (there are other correct answers as well). We know that there are 4 bits for indexing the byte in a block, and there are 7 bits (if the cache size is 4KiB) or 8 bits (if the cache size is 8 KiB). Therefore, address 2048 would be in set 0 only if the cache size is 4KiB: we can access address 2048, and then check if a block in set 0 was replaced by address 2048 by accessing address 0. If it is a miss, the cache size is 4KiB, and if it is a hit, the cache size is 8KiB.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_11/a",
        "context": "A runahead execution processor is designed with an unintended hardware bug: every other instruction in runahead mode is dropped by the processor after the fetch stage. Recall that the runahead mode is the speculative processing mode where the processor executes instructions solely to generate prefetch requests. All other behavior of the runahead mode is exactly as we described in lectures. When a program is executed, which of the following scenarios could happen compared to a runahead processor without the hardware bug and why? Assume that the program has no bug in it and executes correctly on the processor without the hardware bug.\n",
        "context_figures": [],
        "question": "The buggy runahead processor finishes the program correctly and faster than the non-buggy runahead processor.",
        "solution": "Dropping instructions enables the discovery of more cache misses than not dropping the instructions.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_11/b",
        "context": "A runahead execution processor is designed with an unintended hardware bug: every other instruction in runahead mode is dropped by the processor after the fetch stage. Recall that the runahead mode is the speculative processing mode where the processor executes instructions solely to generate prefetch requests. All other behavior of the runahead mode is exactly as we described in lectures. When a program is executed, which of the following scenarios could happen compared to a runahead processor without the hardware bug and why? Assume that the program has no bug in it and executes correctly on the processor without the hardware bug.\n",
        "context_figures": [],
        "question": "The buggy runahead processor finishes the program correctly and slower than the non-buggy runahead processor.",
        "solution": "The buggy runahead processor is not able to generate cache misses that are dependent on dropped instructions.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_11/c",
        "context": "A runahead execution processor is designed with an unintended hardware bug: every other instruction in runahead mode is dropped by the processor after the fetch stage. Recall that the runahead mode is the speculative processing mode where the processor executes instructions solely to generate prefetch requests. All other behavior of the runahead mode is exactly as we described in lectures. When a program is executed, which of the following scenarios could happen compared to a runahead processor without the hardware bug and why? Assume that the program has no bug in it and executes correctly on the processor without the hardware bug.\n",
        "context_figures": [],
        "question": "The buggy runahead processor executes the program incorrectly.",
        "solution": "Not possible as all executions in runahead mode is purely speculative and do not commit. Hence it cannot affect the correctness of the program.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_12/",
        "context": "A systolic array consists of 4x4 Processing Elements (PEs), interconnected as shown in Figure 1. The inputs of the systolic array are labeled as H0, H1, H2, H3 and V0, V1, V2, V3. Figure 2 shows the PE logic, which performs a multiply and accumulate MAC operation and saves the result to an internal register (reg). Figure 2 also shows how each PE propagates its inputs. We make the following assumptions: The latency of each MAC operation is one cycle. The propagation of the values from i0 to o0, and from i1 to o1, takes one cycle. The initial values of all internal registers is zero.\nYour goal is to use the example systolic array shown in Figure 1 to perform the convolution (~) of a 3x3 image (matrix I3x3) with four 2x2 filters (matrices A2x2, B2x2, C2x2, and D2x2), to obtain four 2x2 outputs (matrices W2x2, X2x2, Y2x2, and Z2x2):",
        "context_figures": [
            "chart_p28_0.png"
        ],
        "question": "Fill the following table with: 1. The input elements (from matrices I3x3, A2x2, B2x2, C2x2, and D2x2) in the correct input ports of the systolic array (H0, H1, H2, H3 and V0, V1, V2, V3). 2. The output values and the corresponding PE where the output elements (of matrices W2x2, X2x2, Y2x2, and Z2x2) are generated.",
        "solution": "",
        "solution_figures": [
            "chart_p27_0.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/a",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\n",
        "context_figures": [],
        "question": "How many warps does it take to execute these code segments?",
        "solution": "32 warps. The number of warps is calculated as: #Warps = ceil(#Total_threads / #Warp_size), where #Total_threads = 1024 = 2^10 (i.e., one thread per loop iteration), and #Warp_size = 32 = 2^5 (given). Thus, the number of warps needed to run this program is: #Warps = ceil(2^10 / 2^5) = 2^5 = 32.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/b",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\nCode Segment 1",
        "context_figures": [],
        "question": "What is the SIMD utilization of the first iteration of the inner loop (j = 0) for Code Segment 1? Show your work. (Hint: The warp scheduler does not issue instructions when no thread is active)",
        "solution": "The utilization of the first iteration (j = 0) of Code Segment 1 is 7/8. Instructions 1, 2, and 4 are executed by all threads in Code Segment 1. In Code Segment 1, s = 1 during the first iteration. Thus, only even numbered threads fulfill the predicate of the if statement, and only half of the threads of each warp execute Instruction 3. Code Segment 1, j = 0: SIMD_utilization = (1024+1024+512+1024) / (1024+1024+1024+1024) = 7/8.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/c",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\nCode Segment 2",
        "context_figures": [],
        "question": "What is the SIMD utilization of the first iteration of the inner loop (j = 0) for Code Segment 2? Show your work. (Hint: The warp scheduler does not issue instructions when no thread is active)",
        "solution": "The utilization of the first iteration (j = 0) of Code Segment 2 is 100%. Instructions 1, 2, and 4 are executed by all threads in Code Segment 2. In Code Segment 2, s = 512 during the first iteration. Thus, only threads with i < 512 fulfill the predicate of the if statement, and all threads of only half of the warps execute Instruction 3. Code Segment 2, j = 0: SIMD_utilization = (1024+1024+512+1024) / (1024+1024+512+1024) = 7/7 = 100%.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/d",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\nCode Segment 1",
        "context_figures": [],
        "question": "What is the SIMD utilization of any iteration of the inner loop (0 <= j < 10) for Code Segment 1? Show your work. (Hint: Derive an analytical expression, which may be piecewise)",
        "solution": "As mentioned in part (b), Instructions 1, 2, and 4 are executed by all threads. In Code Segment 1, with 0 <= j < 5, all 32 warps are active, but the number of active threads per warp divides by half in each iteration. With 5 <= j < 10, only one thread per warp is active, and the number of active warps divides by half in each iteration. As a result: Code Segment 1, iteration j: SIMD_utilization = { (3072+2*(9-j)) / 4096, if 0 <= j < 5 (3072+2*(9-j)) / (3072+32*2*(9-j)), if 5 <= j < 10 (1)",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/e",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\nCode Segment 2",
        "context_figures": [],
        "question": "What is the SIMD utilization of any iteration of the inner loop (0 <= j < 10) for Code Segment 2? Show your work. (Hint: Derive an analytical expression, which may be piecewise)",
        "solution": "As mentioned in part (b), Instructions 1, 2, and 4 are executed by all threads. In Code Segment 2, with 0 <= j < 5, all 32 threads per warp are active, but the number of active warps divides by half in each iteration. With 5 <= j < 10, only one warp is active, and the number of active threads divides by half in each iteration. As a result: Code Segment 2, iteration j: SIMD_utilization = { (3072+32*2*(4-j)) / (3072+32*2*(4-j)) = 100%, if 0 <= j < 5 (3072+2*(9-j)) / (3072+32), if 5 <= j < 10 (2)",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/f",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\n",
        "context_figures": [],
        "question": "Is there any iteration (0 <= j < 10) where both code segments have the same utilization? Explain your reasoning",
        "solution": "Yes, with j = 9 only one thread of only one warp is active, since only one thread (out of 1024) is needed to perform the last addition.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_8/g",
        "context": "We define the SIMD utilization of a program that runs on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. The following code segments are run on a GPU. We assume that (1) A resides in memory and is shared by all threads, (2) s resides in a register and is private to each thread, and (3) the code segments are correct (i.e., do not think about any correctness issues when answering this question). A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Each thread executes a single iteration of the outermost loop (with index i). Assume that the data values of the array A are already in vector registers so there are no memory loads and stores in this program. (Hint: Notice that there are 4 instructions in each iteration of the outermost loop of both code segments.)\n",
        "context_figures": [],
        "question": "Which code is expected to run faster on a GPU? Explain your reasoning",
        "solution": "Code Segment 2 is faster because it has less intra-warp divergence, and thus higher SIMD utilization. In each iteration (except the last one), the number of warps that Code Segment 2 schedules is smaller than the number of warps that Code Segment 1 schedules. This results in fewer execution cycles.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_9/1",
        "context": "You are given the following piece of code that iterates through two large arrays, j and k, each populated with completely (i.e., truly) random positive integers. The code has five branches (labeled B1, B2, B3, B4, and B5). When we say that a branch is taken, we mean that the code inside the curly brackets is executed. Assume that the code is run to completion without any errors or interruptions (i.e., there are no exceptions). For the following questions, assume that this is the only block of code that will ever be run on the machines, and that the loop condition branch is resolved first in the iteration (i.e., the if statements execute only after resolving the loop condition branch).\nMachine A uses an always-taken branch predictor.",
        "context_figures": [],
        "question": "What is the branch misprediction rate when the above piece of code runs on Machine A? Show your work.",
        "solution": "45.01% = 2251 / 5001. B1 will generate 1 misprediction out of 1001 iterations (B1 is not taken in the 1001th iteration and the loop body does not execute). B2 will generate 500 mispredictions out of 1000 iterations, B3 will generate 750 mispredictions out of 1000 iterations, and both B4 and B5 will generate 500 mispredictions out of 1000 iterations.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_9/2",
        "context": "You are given the following piece of code that iterates through two large arrays, j and k, each populated with completely (i.e., truly) random positive integers. The code has five branches (labeled B1, B2, B3, B4, and B5). When we say that a branch is taken, we mean that the code inside the curly brackets is executed. Assume that the code is run to completion without any errors or interruptions (i.e., there are no exceptions). For the following questions, assume that this is the only block of code that will ever be run on the machines, and that the loop condition branch is resolved first in the iteration (i.e., the if statements execute only after resolving the loop condition branch).\nMachine B uses one single-level global two-bit saturating counter branch predictor shared by all branches, which starts at Weakly Taken (2'b10).",
        "context_figures": [],
        "question": "What is the branch misprediction rate when the above piece of code runs on Machine B? Show your work.",
        "solution": "59.97% = 2999 / 5001. From (0-249): 375 mispredictions (125 for B2 and 250 for B5) for 1250 branches. From (250-499): 874 mispredictions (2 for iteration 250, 4 for every odd iteration, 3 for every even iteration except for iteration 250) for 1250 branches. From (500-1000): 1750 mispredictions (3 for odd iterations, 4 for even iterations, 0 for i = 1000) for 2501 branches.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_9/3",
        "context": "You are given the following piece of code that iterates through two large arrays, j and k, each populated with completely (i.e., truly) random positive integers. The code has five branches (labeled B1, B2, B3, B4, and B5). When we say that a branch is taken, we mean that the code inside the curly brackets is executed. Assume that the code is run to completion without any errors or interruptions (i.e., there are no exceptions). For the following questions, assume that this is the only block of code that will ever be run on the machines, and that the loop condition branch is resolved first in the iteration (i.e., the if statements execute only after resolving the loop condition branch).\nMachine C uses a per-branch two-bit saturating counter as its branch predictor. All counters start at Weakly Not Taken (2'b01).",
        "context_figures": [],
        "question": "What is the branch misprediction rate when the above piece of code runs on Machine C? Show your work.",
        "solution": "20.20% = 1010 / 5001. You can split this up by branch. B1: mispredicts at i = 0, and i = 1000 (2 mispredictions out of 1001). B2: mispredicts every time since it oscillates between Weakly Not Taken and Weakly Taken (1000 mispredictions out of 1000). B3: mispredicts at i = 0, i = 250, and i = 251 (3 mispredictions out of 1000). B4: mispredicts at i = 0, i = 500, and i = 501 (3 mispredictions out of 1000). B5: mispredicts at i = 500, and i = 501 (2 mispredictions out of 1000).",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_2/2.1",
        "context": "Complete the Verilog code and explain what another given Verilog code does.\nComplete the Verilog code. For each numbered blank 1 - 5 in the following Verilog code, mark the choice below (i.e., one of options A, B, C, D) that makes the Verilog module operate as described in the comments. The resulting code must have correct syntax.",
        "context_figures": [
            "chart_p4_0.png"
        ],
        "question": "1 module my_module (input clk, input rst, input[15:0] idata, input[1:0] op, 1 [31:0] odata); ...",
        "solution": "1 : B. output reg, 2 : A. reg[31:0], 3 : D. default, 4 : D. odata <= 0;, 5 : D. odata <= nval;",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_2/2.2",
        "context": "Complete the Verilog code and explain what another given Verilog code does.\nYou are given a Verilog code that you are asked to analyze and find out what it does.",
        "context_figures": [
            "chart_p6_0.png"
        ],
        "question": "Show the values (as unsigned decimal numbers) that the out signal takes, starting from the initial state of the module, for 16 consecutive clock (i.e., clk) cycles. Explain your answer briefly.",
        "solution": "out is equal to 0, 1, 2, 3, 0, 3, 2, 3, 0, 3, 2, 3, 0, 3, 2, 3 in the first 16 clock cycles. The module either increments or decrements my_reg depending on the state. When state is equal to 0, my_reg is incremented by 1 and otherwise decremented by 1. The value of my_reg is directly assigned to the out signal, and both signals are 2-bit wide.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_3/3.1",
        "context": "Finite State Machines\nSimplifying an FSM",
        "context_figures": [
            "chart_p7_0.png"
        ],
        "question": "You are given the Mealy state machine of a one input / one output digital circuit design. Answer the following questions for the given state diagram.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_3/3.2",
        "context": "Finite State Machines\nDesigning an FSM",
        "context_figures": [],
        "question": "Design a Moore finite state machine (FSM) with one input and one output. The input provides an unsigned binary number in a bit-serial fashion from the most-significant bit to the least-significant bit. The output should be logic-1 in a clock cycle if the provided input so far is divisible by 8 (i.e., [the input number] mod 8 = 0).",
        "solution": "From the given examples, we can see that strings can be exactly divided by 8 are all ended with \"000\" (i.e., three \"0\"s). Then, we define S0, a state where the number is ended with \"000\". If \"1\" comes, then the number cannot be exactly divided by 8 and it lacks three \"0\"s at the end. We define this state as \"E\" state (S1), which means no zero at the end. When there is a \"0\", then the number lacks two \"0\"s to be exactly divided by 8. Therefore, we define the state as \"0\" (S2). When there are two \"0\"s, then the number lacks one more \"0\" to be exactly divided by 8. Therefore, we define the state as \"00\" (S3). Based on the analysis above, we can draw the finite state machine whose output (i.e., O) is \"1\" at S0 (is \"0\" at other states): reset S2: 0 O=0 1 S1: E O=0 S0: 000 O=1 0 S3: 00 O=0 1 0 1 0",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_1/a",
        "context": "Boolean Logic Circuits\nUsing Boolean algebra, find the simplest Boolean algebra equation for the following min-terms: \u2211(1111, 1110, 1000, 1001, 1011, 1010, 0000). Show your work step-by-step.",
        "context_figures": [],
        "question": "F = (B.C.D) + (A.(C +B))",
        "solution": "F = (A.B.C.D) + (A.B.C.D) + (A.B.C.D) + (A.B.C.D) + (A.B.C.D) + (A.B.C.D) + (A.B.C.D) \n F = (B.C.D).(A+A)+(A.C).(B.D+B.D+B.D+B.D)+(A.B).(C.D+C.D+C.D+C.D) \n F = (B.C.D) + (A.C) + (A.B) \n F = (B.C.D) + (A.(C +B))",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_1/b",
        "context": "Boolean Logic Circuits\nConvert the following Boolean equation so that it only contains NOR operations. Show your work step-by-step.",
        "context_figures": [],
        "question": "F = A+ (B.C +A.C)",
        "solution": "F = ((A+A+ (B.C +A.C)) + ((A+A+ (B.C +A.C)) \n B.C = B +B + C + C \n A.C = A+A+ C + C + C + C \n F = ((A+ (B.C +A.C)) \n F = ((A+ (B.C +A.C)) + ((A+ (B.C +A.C)) \n F = ((A+A+ (B.C +A.C)) + ((A+A+ (B.C +A.C)) \n B.C = B +B + C + C \n A.C = A+A+ C + C + C + C",
        "solution_figures": [
            "chart_p3_0.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/1",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of uniquely identifiable memory locations.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/2",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of instructions fetched per clock cycle.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/3",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Support for branch prediction hints conveyed by the compiler.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/4",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of general-purpose registers.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/5",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of non-programmable registers.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/6",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "SIMD processing support.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/7",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of integer arithmetic and logic units (ALUs).",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/8",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of read ports in the physical register file.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/9",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Endianness (big endian vs. small endian).",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/10",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Size of a virtual memory page.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/11",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Cache coherence protocol.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/12",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of cache blocks in the L3 cache.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/13",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Ability to flush (i.e., invalidate) a cache line using the operating system code.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/14",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "Number of pipeline stages.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_4/15",
        "context": "A new CPU has two comprehensive user manuals available for purchase which describe the ISA and the microarchitecture of the CPU, respectively. Unfortunately, the manuals are extremely expensive, and you can only afford one of the two. If both manuals might be useful, you would prefer the ISA manual since it is much cheaper than the microarchitecture manual. For each of the following questions that you would like to answer, decide which manual is more likely to help.\n",
        "context_figures": [],
        "question": "How many prefetches the hardware prefetcher generates in a clock cycle.",
        "solution": "",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_5/a",
        "context": "A multi-cycle processor P1 executes load instructions in 6 cycles, store instructions in 6 cycles, arithmetic instructions in 2 cycles, and branch instructions in 2 cycles. Consider an application A where 40% of all instructions are load instructions, 20% of all instructions are store instructions, 30% of all instructions are arithmetic instructions, and 10% of all instructions are branch instructions.\n",
        "context_figures": [],
        "question": "What is the CPI of application A when executing on processor P1? Show your work.",
        "solution": "CPI = 0.4\u00d7 6 + 0.2\u00d7 6 + 0.3\u00d7 2 + 0.1\u00d7 2 CPI = 4.4",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_5/b",
        "context": "A multi-cycle processor P1 executes load instructions in 6 cycles, store instructions in 6 cycles, arithmetic instructions in 2 cycles, and branch instructions in 2 cycles. Consider an application A where 40% of all instructions are load instructions, 20% of all instructions are store instructions, 30% of all instructions are arithmetic instructions, and 10% of all instructions are branch instructions.\nA new design of the processor doubles the clock frequency of P1. However, the latencies of all instructions increase by 4 cycles. We call this new processor P2. The compiler used to generate instructions for P2 is the same as for P1. Thus, it produces the same number of instructions for program A.",
        "context_figures": [],
        "question": "What is the CPI of application A when executing on processor P2? Show your work.",
        "solution": "CPI = 0.4\u00d7 10 + 0.2\u00d7 10 + 0.3\u00d7 6 + 0.1\u00d7 6 CPI = 8.4",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_5/c",
        "context": "A multi-cycle processor P1 executes load instructions in 6 cycles, store instructions in 6 cycles, arithmetic instructions in 2 cycles, and branch instructions in 2 cycles. Consider an application A where 40% of all instructions are load instructions, 20% of all instructions are store instructions, 30% of all instructions are arithmetic instructions, and 10% of all instructions are branch instructions.\n",
        "context_figures": [],
        "question": "Which processor is faster (P1 or P2)? By how much (i.e., what is the speedup)? Show your work.",
        "solution": "P2 is 1.05\u00d7 faster than P1.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_5/d",
        "context": "A multi-cycle processor P1 executes load instructions in 6 cycles, store instructions in 6 cycles, arithmetic instructions in 2 cycles, and branch instructions in 2 cycles. Consider an application A where 40% of all instructions are load instructions, 20% of all instructions are store instructions, 30% of all instructions are arithmetic instructions, and 10% of all instructions are branch instructions.\nYou want to improve the original P1 design by including one new optimization without changing the clock frequency. You can choose only one of the following options: (1) ALU: An optimized ALU, which halves the latency of both arithmetic and branch instructions. (2) LSU: An asymmetric load-store unit, which halves the latency of load operations but doubles the latency of store operations.",
        "context_figures": [],
        "question": "Which optimization do you add to P1 for application A? Show your work and justify your choice.",
        "solution": "The ALU optimization. Application A executes 40% load, 20% store, 30% arithmetic, and 10% branch instructions. By Amdahl's Law, we have: SpeedupALU = 1 / (1\u22120.3\u22120.1)+ 0.3+0.1 / 2 = 1.25 SpeedupLSU = 1 / (1\u22120.4\u22120.2)+ 0.4 / 2 +0.2\u00d72 = 1.0 The ALU optimization provides 1.25\u00d7 speedup, while the LSU provides no speedup at all.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_7/7.1",
        "context": "Consider an in-order fetch, out-of-order dispatch, and in-order retirement execution engine that employs Tomasulo's algorithm. This engine has the following characteristics: The engine has four main pipeline stages: Fetch (F), Decode (D), Execute (E), and Write-back (W). The engine can fetch one instruction per cycle, decode one instruction per cycle, and write back the result of one instruction per cycle. The engine has two execution units: 1) an adder to execute ADD instructions and 2) a multiplier to execute MUL instructions. The execution units are fully pipelined. The adder has two stages (E1-E2), and the multiplier has four stages (E1-E2-E3-E4). Execution of each stage takes one cycle. The adder has a two-entry reservation station, and the multiplier has a three-entry reservation station. An instruction always allocates the first available entry of the reservation station (in top-to-bottom order) of the corresponding execution unit. Full data forwarding is available, i.e., during the last cycle of the E stage, the tags and data are broadcast to the reservation station and the Register Alias Table (RAT). For example, an ADD instruction updates the reservation station entries of the dependent instructions in the E2 stage. So, the updated value can be read from the reservation station entry in the next cycle. Therefore, a dependent instruction can potentially begin its execution in the next cycle (after E2). The multiplier and adder have separate output data buses, which allow both the adder and the multiplier to update the reservation station and the RAT in the same cycle. An instruction continues to occupy a reservation station slot until it finishes the Write-back (W) stage. The reservation station entry is deallocated after the Write-back (W) stage.\nThe processor is about to fetch and execute five instructions. Assume the reservation stations (RS) are all initially empty, and the initial state of the register alias table (RAT) is given below in Figure (a). Instructions are fetched, decoded, and executed as discussed in class. At some point during the execution of the five instructions, a snapshot of the state of the RS and the RAT is taken. Figures (b) and (c) show the state of the RS and the RAT at the snapshot time. A dash (-) indicates that a value has been cleared. A question mark (?) indicates that a value is unknown to you.",
        "context_figures": [
            "chart_p15_0.png"
        ],
        "question": "Data Flow Graph [40 points] Based on the information provided above, identify the instructions and provide the data flow graph below for the instructions that have been fetched. Please appropriately connect the nodes using edges and specify the direction of each edge. Label each edge with the destination architectural register and the corresponding Tag.",
        "solution": "",
        "solution_figures": [
            "chart_p16_0.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_7/7.2",
        "context": "Consider an in-order fetch, out-of-order dispatch, and in-order retirement execution engine that employs Tomasulo's algorithm. This engine has the following characteristics: The engine has four main pipeline stages: Fetch (F), Decode (D), Execute (E), and Write-back (W). The engine can fetch one instruction per cycle, decode one instruction per cycle, and write back the result of one instruction per cycle. The engine has two execution units: 1) an adder to execute ADD instructions and 2) a multiplier to execute MUL instructions. The execution units are fully pipelined. The adder has two stages (E1-E2), and the multiplier has four stages (E1-E2-E3-E4). Execution of each stage takes one cycle. The adder has a two-entry reservation station, and the multiplier has a three-entry reservation station. An instruction always allocates the first available entry of the reservation station (in top-to-bottom order) of the corresponding execution unit. Full data forwarding is available, i.e., during the last cycle of the E stage, the tags and data are broadcast to the reservation station and the Register Alias Table (RAT). For example, an ADD instruction updates the reservation station entries of the dependent instructions in the E2 stage. So, the updated value can be read from the reservation station entry in the next cycle. Therefore, a dependent instruction can potentially begin its execution in the next cycle (after E2). The multiplier and adder have separate output data buses, which allow both the adder and the multiplier to update the reservation station and the RAT in the same cycle. An instruction continues to occupy a reservation station slot until it finishes the Write-back (W) stage. The reservation station entry is deallocated after the Write-back (W) stage.\n",
        "context_figures": [
            "chart_p15_0.png"
        ],
        "question": "Program Instructions [20 points] Fill in the blanks below with the five-instruction sequence in program order. There can be more than one correct ordering. Please provide only one correct ordering. When referring to registers, please use their architectural names (R0 through R9). Place the register with the smaller architectural name on the left source register box. For example, ADD R8 \u21d0 R1, R5.",
        "solution": "ADD R3 \u21d0 R4 , R7 MUL R5 \u21d0 R3 , R2 MUL R4 \u21d0 R5 , R4 ADD R8 \u21d0 R1 , R2 MUL R9 \u21d0 R6 , R3",
        "solution_figures": [
            "chart_p16_1.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_6/a",
        "context": "Consider two pipelined machines implementing the MIPS ISA, Machine A and Machine B. Both machines have one ALU and the following five pipeline stages, very similar to the basic 5-stage pipelined MIPS processor we discussed in lectures: 1. Fetch (one clock cycle) 2. Decode (one clock cycle) 3. Execute (one clock cycle) 4. Memory (one clock cycle) 5. Write-back (one clock cycle). Machines A and B have the following specifications: Machine A Machine B Data Forwarding/Inter-locking Does NOT implement interlocking in hardware. Relies on the compiler to order instructions or insert nop instructions such that dependent instructions are correctly executed. Implements data dependence detection and data forwarding in hardware. On detection of instruction dependence, it forwards an operand from the memory stage or from the write-back stage to the execute stage. The result of a load instruction (lw) can only be forwarded from the write-back stage. Internal register file forwarding Implemented (i.e., an instruction writes into a register in the first half of a cycle and another instruction can correctly access the same register in the second half of the cycle). Same as Machine A Branch Prediction Predicts all branches as always-taken, and the next program counter is available after the decode stage. Same as Machine A Consider the following code segment: Loop: lw $1, 0($4) lw $2, 400($4) add $3, $1, $2 sw $3, 0($4) sub $4, $4, #4 bnez $4, Loop Initially, $1 = 0, $2 = 0, $3 = 0, and $4 = 400.\nRe-write the code segment above with minimal changes so that it gets correctly executed in Machine A with minimal latency. You can either insert nop instructions or reorder instructions as needed.",
        "context_figures": [],
        "question": "Re-write the code segment above with minimal changes so that it gets correctly executed in Machine A with minimal latency.",
        "solution": "Loop: lw $1, 0($4) lw $2, 400($4) nop nop add $3, $1, $2 nop nop sw $3, 0($4) sub $4, $4, #4 nop nop bnez $4, Loop",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_6/b",
        "context": "Consider two pipelined machines implementing the MIPS ISA, Machine A and Machine B. Both machines have one ALU and the following five pipeline stages, very similar to the basic 5-stage pipelined MIPS processor we discussed in lectures: 1. Fetch (one clock cycle) 2. Decode (one clock cycle) 3. Execute (one clock cycle) 4. Memory (one clock cycle) 5. Write-back (one clock cycle). Machines A and B have the following specifications: Machine A Machine B Data Forwarding/Inter-locking Does NOT implement interlocking in hardware. Relies on the compiler to order instructions or insert nop instructions such that dependent instructions are correctly executed. Implements data dependence detection and data forwarding in hardware. On detection of instruction dependence, it forwards an operand from the memory stage or from the write-back stage to the execute stage. The result of a load instruction (lw) can only be forwarded from the write-back stage. Internal register file forwarding Implemented (i.e., an instruction writes into a register in the first half of a cycle and another instruction can correctly access the same register in the second half of the cycle). Same as Machine A Branch Prediction Predicts all branches as always-taken, and the next program counter is available after the decode stage. Same as Machine A Consider the following code segment: Loop: lw $1, 0($4) lw $2, 400($4) add $3, $1, $2 sw $3, 0($4) sub $4, $4, #4 bnez $4, Loop Initially, $1 = 0, $2 = 0, $3 = 0, and $4 = 400.\nFill the table below with the timeline of the first loop iteration of the code segment in Machine A.",
        "context_figures": [],
        "question": "Fill the table below with the timeline of the first loop iteration of the code segment in Machine A.",
        "solution": "Instruction Clock cycle number 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 lw $1, 0($4) F D E M W lw $2, 400($4) F D E M W nop F D E M W nop F D E M W add $3, $1, $2 F D E M W nop F D E M W nop F D E M W sw $3, 0($4) F D E M W sub $4, $4, #4 F D E M W nop F D E M W nop F D E M W bnez $4, Loop F D E M W",
        "solution_figures": [
            "chart_p13_0.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_6/c",
        "context": "Consider two pipelined machines implementing the MIPS ISA, Machine A and Machine B. Both machines have one ALU and the following five pipeline stages, very similar to the basic 5-stage pipelined MIPS processor we discussed in lectures: 1. Fetch (one clock cycle) 2. Decode (one clock cycle) 3. Execute (one clock cycle) 4. Memory (one clock cycle) 5. Write-back (one clock cycle). Machines A and B have the following specifications: Machine A Machine B Data Forwarding/Inter-locking Does NOT implement interlocking in hardware. Relies on the compiler to order instructions or insert nop instructions such that dependent instructions are correctly executed. Implements data dependence detection and data forwarding in hardware. On detection of instruction dependence, it forwards an operand from the memory stage or from the write-back stage to the execute stage. The result of a load instruction (lw) can only be forwarded from the write-back stage. Internal register file forwarding Implemented (i.e., an instruction writes into a register in the first half of a cycle and another instruction can correctly access the same register in the second half of the cycle). Same as Machine A Branch Prediction Predicts all branches as always-taken, and the next program counter is available after the decode stage. Same as Machine A Consider the following code segment: Loop: lw $1, 0($4) lw $2, 400($4) add $3, $1, $2 sw $3, 0($4) sub $4, $4, #4 bnez $4, Loop Initially, $1 = 0, $2 = 0, $3 = 0, and $4 = 400.\nCalculate the number of cycles it takes to execute the code segment on Machine A.",
        "context_figures": [],
        "question": "Calculate the number of cycles it takes to execute the code segment on Machine A.",
        "solution": "Total number of cycles: 1303. The compiler reorders instructions and places six nop-s. This is the execution timeline of the first iteration: Each iteration consists of 12 instructions. Since the next program counter is available after the decode stage of bnez, the next iteration starts with an additional delay of 1 cycle. The last iteration takes 16 cycles, to drain the pipeline. Thus the entire program runs for 99 * 13 + 16 = 1303 cycles.",
        "solution_figures": [],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_6/d",
        "context": "Consider two pipelined machines implementing the MIPS ISA, Machine A and Machine B. Both machines have one ALU and the following five pipeline stages, very similar to the basic 5-stage pipelined MIPS processor we discussed in lectures: 1. Fetch (one clock cycle) 2. Decode (one clock cycle) 3. Execute (one clock cycle) 4. Memory (one clock cycle) 5. Write-back (one clock cycle). Machines A and B have the following specifications: Machine A Machine B Data Forwarding/Inter-locking Does NOT implement interlocking in hardware. Relies on the compiler to order instructions or insert nop instructions such that dependent instructions are correctly executed. Implements data dependence detection and data forwarding in hardware. On detection of instruction dependence, it forwards an operand from the memory stage or from the write-back stage to the execute stage. The result of a load instruction (lw) can only be forwarded from the write-back stage. Internal register file forwarding Implemented (i.e., an instruction writes into a register in the first half of a cycle and another instruction can correctly access the same register in the second half of the cycle). Same as Machine A Branch Prediction Predicts all branches as always-taken, and the next program counter is available after the decode stage. Same as Machine A Consider the following code segment: Loop: lw $1, 0($4) lw $2, 400($4) add $3, $1, $2 sw $3, 0($4) sub $4, $4, #4 bnez $4, Loop Initially, $1 = 0, $2 = 0, $3 = 0, and $4 = 400.\nFill the table below with the timeline of the first loop iteration of the code segment in Machine B.",
        "context_figures": [],
        "question": "Fill the table below with the timeline of the first loop iteration of the code segment in Machine B.",
        "solution": "Instruction Clock cycle number 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 lw $1, 0($4) F D E M W lw $2, 400($4) F D E M W add $3, $1, $2 F D * E M W sw $3, 0($4) F * D E M W sub $4, $4, #4 F D E M W bnez $4, Loop F D E M W lw $1, 0($4) * F D E M W",
        "solution_figures": [
            "chart_p14_0.png"
        ],
        "correctly_parsed": null
    },
    {
        "question_id": "digitaltechnik-s21-en-sol/Problem_6/e",
        "context": "Consider two pipelined machines implementing the MIPS ISA, Machine A and Machine B. Both machines have one ALU and the following five pipeline stages, very similar to the basic 5-stage pipelined MIPS processor we discussed in lectures: 1. Fetch (one clock cycle) 2. Decode (one clock cycle) 3. Execute (one clock cycle) 4. Memory (one clock cycle) 5. Write-back (one clock cycle). Machines A and B have the following specifications: Machine A Machine B Data Forwarding/Inter-locking Does NOT implement interlocking in hardware. Relies on the compiler to order instructions or insert nop instructions such that dependent instructions are correctly executed. Implements data dependence detection and data forwarding in hardware. On detection of instruction dependence, it forwards an operand from the memory stage or from the write-back stage to the execute stage. The result of a load instruction (lw) can only be forwarded from the write-back stage. Internal register file forwarding Implemented (i.e., an instruction writes into a register in the first half of a cycle and another instruction can correctly access the same register in the second half of the cycle). Same as Machine A Branch Prediction Predicts all branches as always-taken, and the next program counter is available after the decode stage. Same as Machine A Consider the following code segment: Loop: lw $1, 0($4) lw $2, 400($4) add $3, $1, $2 sw $3, 0($4) sub $4, $4, #4 bnez $4, Loop Initially, $1 = 0, $2 = 0, $3 = 0, and $4 = 400.\nCalculate the number of cycles it takes to execute the code segment on Machine B.",
        "context_figures": [],
        "question": "Calculate the number of cycles it takes to execute the code segment on Machine B.",
        "solution": "Total number of cycles: 803. 1 - Forward $2 from W to E in cycle 6. 2 - Forward $3 from M to E in cycle 7. 3 - Forward $4 from M to E in cycle 9. Each iteration takes 8 cycles, including one cycle delay after bnez, because to the next program counter is available only after the decode stage of bnez. The last iteration takes 11 cycles, to drain the pipeline. Thus total number of cycles is 99*8 + 11 = 803 cycles.",
        "solution_figures": [],
        "correctly_parsed": null
    }
]