```json
{
  "exam_name": "Computer System Architecture 6.5900 Quiz #1 October 13th, 2023",
  "problems": [
    {
      "problem": "Part A: Caches and Virtual Memory",
      "parts": [
        {
          "part": 1,
          "question": [
            {
              "subproblem_context": "Consider a 2-way set-associative cache with 128-byte blocks and 2 sets. The table below shows a timeline of how the cache metadata (valid bit (V), dirty bit (D), and tags) changes after a series of memory accesses. The leftmost column indicates the address of the memory access and whether they are reads (R) or writes (W), and the rest of the row should indicate the metadata after the access is performed.",
              "subproblem_question": "Fill in the table below by showing how cache metadata changes after each access. If an entry remains unchanged after the memory access, you may leave that entry blank. Assume that the cache uses a least recently used (LRU) replacement policy (the table does not include LRU metadata). As an example, we have filled in the corresponding entries for the first memory access (0xA4C1).",
              "subproblem_figures": ["TABLE"]
            }
          ],
          "answer": [
            {
              "solution": "",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 2,
          "question": [
            {
              "subproblem_question": "Ben Bitdiddle recently bought a processor that has 16-bit virtual addresses. The following figure shows the virtual address format:\n\n| 15 | 7 | 6 | 0 |\n| :--: | :--: | :--: | :--: |\n| Virtual page number | Page offset |\n\nWhat is the size of a page in this system, in bytes?"
            }
          ],
          "answer": [
            {
              "solution": "128B",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 3,
          "question": [
            {
              "subproblem_context": "Ben's processor has an 8-entry direct-mapped TLB. The TLB is indexed by the lowest order bits of the virtual page number.\n\nBen writes the program below, which operates on a matrix A. A has 4 rows and 256 columns. Each element of A is a 32-bit integer, and elements are laid out in row-major order (i.e., consecutive elements of the same row are in contiguous memory locations). The program sums the entries of a top-right submatrix B of matrix A. Assume that A starts at virtual address 0x0000, and sum is stored in a register. Ignore instruction fetches.\n\n```\nint sum = 0;\nfor (int i = 0; i < H; i++)\n    for (int j = 0; j < W; j++)\n        sum += A[i][j];\n```",
              "subproblem_question": "(a) How many TLB misses will this program incur for H=4, W=256 (i.e., when B=A)?",
              "subproblem_figures": ["IMAGE"]
            },
            {
              "subproblem_question": "(b) How many pages does a row of A occupy?",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(c) What is the minimum TLB hit rate (i.e., TLB hits divided by number of accesses) that this program can have? What values of H and W cause this minimum? Specify all values of H and W that cause this.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(d) What is the maximum TLB hit rate this program can achieve? What values of H and W achieve this maximum? Specify all values of H and W that achieve this.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "A consists of 32 contiguous 128 B pages. We all elements in A only once in the order they are laid out in memory. So there will be 32 misses.",
              "solution_figures": []
            },
            {
              "solution": "8 Pages",
              "solution_figures": []
            },
            {
              "solution": "W=1 achieves the minimum hit rate of 0 for all possible H. Any W>1 introduces additional accesses to a page already cached by the TLB.",
              "solution_figures": []
            },
            {
              "solution": "Remember that a page contains 32 elements of matrix A. Max hit rate is having 1 miss to bring the page to the TLB, followed by 31 hits to it i.e., 31/32.\n\nTo achieve this, we need W=32*N where 0<N<=8, and H can be any value.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 4,
          "question": [
            {
              "subproblem_context": "Alyssa P. Hacker suggests that a larger page size would eliminate most of misses in the direct-mapped TLB for Ben's program.",
              "subproblem_question": "(a) For what values of H and W will the TLB hit rate not improve with pages that are double the size? Specify all values of H and W that achieve this.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(b) What is the minimum page size that will cause Ben's program to incur at least one TLB hit for all values of H and W such that H*W>1? Assume page sizes must be a power of 2.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "Now each page contains 64 elements, and a row of A consists of 4 pages.\nFor W<=32 and any H, we will have the same number of hits as with smaller pages since having a larger page doesn't reduce compulsory misses.",
              "solution_figures": []
            },
            {
              "solution": "An easy way to solve this is thinking about the scenario where we had the minimum (0) hit rate for Question 4(b). There, accessing only one element per column resulted in no reuse because elements in different columns belonged to different pages.\n\nThus, the minimum page size to ensure that we have at least one TLB hit is a size greater than 1024B. Since we assume that page sizes grow in powers of two, that is 2048B.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 5,
          "question": [
            {
              "subproblem_context": "Alyssa modifies Ben's program as follows, swapping the order of the two nested loops:\n\n```\nint sum = 0;\nfor (int j = 0; j < W; j++)\n    for (int i = 0; i < H; i++)\n        sum += A[i][j];\n```",
              "subproblem_question": "(a) Does Alyssa's program have a better TLB hit rate than Ben's?",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(b) Assume W=8. For which values of H will doubling the page size improve the TLB hit rate of Alyssa's program?",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "No. Alyssa's access pattern will, for the given column, always access four different pages that map to the same entry in the direct-mapped TLB (i.e., conflict misses).",
              "solution_figures": []
            },
            {
              "solution": "H>=2. By doubling the page size TLB entries conflict between the first and third row, and between the second and fourth row.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 6,
          "question": [
            {
              "subproblem_context": "Ben's processor uses a two-level hierarchical page table. The virtual address format is as follows:\n\n| 15 | 109 | 76 | 0 |\n| :--: | :--: | :--: | :--: |\n| L1 index | L2 index | Page offset |\n\nAssume that all page tables have been swapped out to disk, and do not worry about the pages needed for code.\n\nThe L2 index is three bits wide. Thus, one L2 page table contains 8 page table entries.",
              "subproblem_question": "(a) How many L2 page tables does accessing a row of A cover?",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(b) How many unique page table entries are accessed when scanning the entire matrix A? Include both L1 and L2 page table entries.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(c) What is the minimum submatrix size (=H*W) that will cause at least four L2 page table pages to be resident in memory after the program runs? Specify all values of H and W that achieve this.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(d) What is the maximum submatrix size that will cause exactly one L1 page table to be resident in memory after the program runs? Specify all values of H and W that achieve this.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "1",
              "solution_figures": []
            },
            {
              "solution": "Recall that A consists of 32 contiguous pages, so that's 32 L2 entries or 4 L2 page tables. To index those tables we need 4 L1 entries, for a total of 36.",
              "solution_figures": []
            },
            {
              "solution": "We need to access elements such that we access four pages with different L1 bits, which means that we access page 0,8,16, and 24. The minimum submatrix that achieves this is size 4, where H=4 and W=1.",
              "solution_figures": []
            },
            {
              "solution": "H=4 and W=256",
              "solution_figures": []
            }
          ]
        }
      ]
    },
    {
      "problem": "Part B: Out-of-Order Processor",
      "parts": [
        {
          "part": 1,
          "question": [
            {
              "subproblem_context": "This question uses the out-of-order machine described in the Quiz 1 Handout. We describe events that affect the initial state shown in the handout. Label each event with one of the actions listed in the handout. If you pick a label with a blank (____), you also have to fill in the blank using the choices (i-vii) listed below. If you pick \"R. Illegal action\", state why it is an illegal action. If in doubt, state your assumptions.",
              "subproblem_question": "(a) Assume physical register P11 becomes available and holds a value of 1. Instruction I9 executes and finds that the branch is taken.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(b) Assume all instructions up to I5 commit. I6 commits, clears the valid bit of integer physical register P7, and adds P7 to the free list.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(c) Assume P6 is written by I5 and I5 finishes execution. I7 is issued, reading physical registers P4 and P6.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(d) Assume F10 becomes available, I10 is issued, and generates an exception due to division by zero. The processor flushes the contents of both reservation stations and starts fetching from the earliest uncommitted instruction. No other action is taken.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(e) Assume I14 writes to x5. I14 is allocated in the integer reservation station and the commit queue, grabs a new physical register P8 from the free list, and updates the integer rename table entry of x5 to P8.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(f) Assume FP10 becomes available, and that the FDIV unit is unpipelined. I10 cannot be issued because the FDIV unit is currently occupied by I12.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(g) Assume instruction I14 is a conditional branch. The branch predictor is consulted in the decode stage, which predicts taken. The processor starts fetching the next instruction from the target address of the branch.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(h) Assume all instructions up to I9 commit. The snapshot of the rename table associated with branch I9 is freed.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(i) Assume instruction I14 is an addi x3, x3, 1 instruction, and is allocated in the integer reservation station and the commit queue. The instruction reads physical register P2 when it is issued.",
              "subproblem_figures": []
            },
            {
              "subproblem_question": "(j) Instruction I15 has no entry in the BTB, so the next instruction is fetched from address 0xd8.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "(K, iii): Check the correctness of a speculation on branch direction and find a correct speculation",
              "solution_figures": []
            },
            {
              "solution": "(Q): Commit correctly speculated instruction, and free log associated with greedily updated values",
              "solution_figures": []
            },
            {
              "solution": "(B, i): Satisfy a dependence on register value by bypassing a speculative value",
              "solution_figures": []
            },
            {
              "solution": "(R): Illegal or broken action",
              "solution_figures": []
            },
            {
              "solution": "(G): Write a speculative value using greedy data management",
              "solution_figures": []
            },
            {
              "solution": "(A, vii): Satisfy a dependence on functional unit by stalling",
              "solution_figures": []
            },
            {
              "solution": "(E, iii): Satisfy a dependence on branch direction by speculation using a dynamic prediction",
              "solution_figures": []
            },
            {
              "solution": "(Q): Commit correctly speculated instruction, and free log associated with greedily updated values",
              "solution_figures": []
            },
            {
              "solution": "(B, i): Satisfy a dependence on register value by bypassing a speculative value.\n(C, i): Also OK, because we don't specify the state of I7 when I14 is issued.",
              "solution_figures": []
            },
            {
              "solution": "(D, ii): Satisfy a dependence on PC value by speculation using a static prediction",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 2,
          "question": [
            {
              "subproblem_context": "We profile a program that has 50% integer and 50% floating point instructions. We find that integer and floating-point instructions have the average latencies listed below, when given infinite reservation station and commit queue sizes:\n\n| | Integer | Floating-Point |\n| :-- | :-- | :-- |\n| Decode to Issue | 3 cycles | 6 cycles |\n| Decode to Commit | 8 cycles | 20 cycles |\n| FU latency | 2 cycles | 12 cycles |\n\nIf the processor commits 0.5 instruction per cycle on average for the program, how many entries are occupied on average in the reservation stations and the commit queue?",
              "subproblem_question": "",
              "subproblem_figures": ["TABLE"]
            }
          ],
          "answer": [
            {
              "solution": "We use little's law for each of the structures: occupancy (N) = throughput (T) * latency (L)\n\nFirst, T_int = T_fp = 0.25 instructions/cycle.\nFor integer reservation station, latency is 3 cycles, so total occupancy is 0.75\nFor fp reservation station, latency is 6 cycles, so total occupancy is 1.5\nFor commit queue we need to think of occupancy per operation type, then aggregate them.\nlatency of integer instructions is 8 cycles, so occupancy is 8 * 0.25 = 2.\nlatency of fp instructions is 20 cycles, so occupancy is 20 * 0.25 = 5.\nSo total commit queue occupancy is 2+5=7.",
              "solution_figures": []
            }
          ]
        }
      ]
    },
    {
      "problem": "Part C: Branch Prediction and Predication for Complex Pipelines",
      "parts": [
        {
          "part": 1,
          "question": [
            {
              "subproblem_context": "Ben Bitdiddle is designing a branch predictor for a pipelined in-order processor with the following stages.\n\n| | Address (PC) generation |\n| :--: | :--: |\n| A | Instruction Fetch Stage 1 |\n| F1 | Instruction Fetch Stage 2 |\n| F2 | Branch Address Calculation / Begin Decode |\n| Branch Predictor | B Complete Decode |\n| J | Steer Instructions to Functional Units |\n| R | Register File Read |\n| E | Execute |\n| - | Remainder of execution pipeline |\n\nThe processor has the following characteristics:\n\n- Issues at most one instruction per cycle.\n- Branch addresses are known at the end of the B stage.\n- Branch conditions (taken / not taken) are known at the end of the E stage.\n\nIn this pipeline, control flow instructions work as follows:\n\n- The A stage fetches the instruction at PC+4 by default.\n- In the B stage (Branch Address Calculation/Begin Decode), conditional branch instructions (e.g., BLE/BNE) look up the predictor. If a branch is predicted to be taken, later instructions are flushed and the PC is redirected to the calculated branch target address.\n- JAL instructions simply perform the jump to the target address in the B stage, flushing all later instructions in the pipeline. Do not worry about how JALR is implemented.",
              "subproblem_question": "Fill out the following table. List all possible predictions the branch predictor can make for conditional branches (one per row). Then, fill the corresponding columns with the number of instructions flushed for each of the branch outcomes. Assume that branches go through the pipeline without any stalls or queueing delays.",
              "subproblem_figures": ["TABLE"]
            }
          ],
          "answer": [
            {
              "solution": "",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 2,
          "question": [
            {
              "subproblem_context": "For the following questions, consider the following C code and its RISC-V assembly equivalent. Note that there are no branches other than the ones listed explicitly in the assembly code:\n\n# C code:\n\n```\nint X[1000000];\nint a, b;\nfor (int i = 1000000; i > 0; i--) {\n    a = X[i];\n    ...\n    // Some work independent of a or b\n    ...\n    if (a >= 0) {\n        b += b + b;\n    } else {\n        b += b * b;\n    }\n}\n```\n\n# RISC-V assembly:\n\n```\n# x1, x2, and x3 contain values of &X, a, and b respectively.\n_loop: LW x2, 0(x1)\n    ADDI x1, x1, -1\n    ...\n    # Some work independent of a or b\n\n| B1: | BLT | x2, x0, _else |\n| | ADD | x3, x3, x3 |\n| | JAL | x0, B2 |\n| _else: | MUL | x3, x3, x3 |\n| B2: | BNE | x1, x0, _loop |\n```",
              "subproblem_question": "Assume that branch B1 is always Not Taken, and the predictor predicts all branches as Taken. On average, how many instructions will be flushed by the processor per iteration of the loop?",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "We go through 2 conditional branches, for which the first one we mispredict as taken. In addition, the unconditional JAL is taken, so that's another 3 instructions flushed. So the total # flushed is 7+3+3=13 cycles.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 3,
          "question": [
            {
              "subproblem_context": "Ben's branch predictor consists of a single branch history table (BHT) that is indexed with the bottom 10 bits of the PC. Each entry in the table is a 1-bit counter that predicts taken if 1, and not taken if 0. The actual branch outcome updates the table at the end of the execute stage (1 if Taken, 0 if Not Taken).\n\nAssume that the contents of array X are uniformly random between [-101,100].",
              "subproblem_question": "Will Ben's predictor have a high or low prediction accuracy for the two branches B1 and B2? Explain your answer.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "B2 is pretty obvious (always taken). B1 will only be predicted ~50% correct because the branch direction is entirely random.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 4,
          "question": [
            {
              "subproblem_question": "Is there a design that can achieve significantly higher accuracy than the BHT for both branches given the assumption about X from Question 3? If so, describe the design briefly, stating how prediction works and how the prediction structures are updated after branch resolution. If not, briefly explain why it's not possible.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "It's not possible to be meaningfully better. B2 is already predicted perfectly by the simple BHT, and we cannot achieve anything higher than 50% for the completely random branch B1.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 5,
          "question": [
            {
              "subproblem_context": "Ben now wants to add support for predication (see the predication handout for details). To do so, he adds a predicate register file (PRF). Instructions that set the predicate write to the PRF in the writeback stage. Predicated instructions also read the PRF in the writeback stage. If the predicate register is set, the predicated instruction writes back its result to the register file. Otherwise, the instruction doesn't write back its result to the register file (effectively becoming a NOP).",
              "subproblem_question": "Rewrite the previous RISC-V assembly code to use predication instead of the B1 branch. You may change only the code within the red box. You should use the minimum number of instructions possible in your solution.",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "| | SETPGE | x2, x0, p0 |\n| (p0) | ADD | x3, x3, x3 |\n| (!p0) | MUL | x3, x3, x3 |\n| B2: | BNE | x1, x0, loop |",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 6,
          "question": [
            {
              "subproblem_question": "Assume that branch B1 is not taken. How many instructions will be flushed by the processor per iteration of the loop for your predicated code?",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "Now there's a single conditional branch which is always taken (and predicted taken) so 3 instructions will be flushed per iteration.",
              "solution_figures": []
            }
          ]
        },
        {
          "part": 7,
          "question": [
            {
              "subproblem_context": "Assume that the contents of array X are uniformly random between [-101,100], like in Question 3.",
              "subproblem_question": "Do you think replacing the B1 branch with predication will improve overall performance? Justify your reasoning. For full points, explain how many cycles on average using predication would save over keeping the branch (or vice versa).",
              "subproblem_figures": []
            }
          ],
          "answer": [
            {
              "solution": "Yes, it will improve performance, but we will need to calculate exactly how much. We only need to examine B1 branch since the cost for B2 branch will be the same.\n\nIn the original code, there are 4 possibilities for B1, all of which have different total # of instructions flushed:\n- taken & predicted taken: 3 instructions\n- taken & predicted not taken: 7 instructions\n- not taken & predicted taken: 10 instructions (+3 due to JAL)\n- not taken & predicted not taken: 3 instructions (+3 due to JAL)\nthese are all equally likely, so total average # instructions flushed is 23/4.\nIn contrast, predication makes the processor execute 1 more instruction in case of branch taken, so there is a 0.5 cycle overhead. So total benefit is 23/4-0.5=21/4 cycles.",
              "solution_figures": []
            }
          ]
        }
      ]
    }
  ]
}
```