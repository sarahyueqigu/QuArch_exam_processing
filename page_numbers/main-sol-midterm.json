{
    "pages": [
        {
            "page": 1,
            "text": "    Name:    SOLUTIONS                                        Student ID:\n                                               Midterm Exam\n                                   Computer Architecture (263-2210-00L)\n                                          ETH Z\u00fcrich, Fall 2017\n                                             Prof. Onur Mutlu\n                                      Problem 1 (30 Points):\n                                      Problem 2 (80 Points):\n                                      Problem 3 (90 Points):\n                                      Problem 4 (40 Points):\n                                      Problem 5 (70 Points):\n                                      Problem 6 (90 Points):\n                                      Problem 7 (70 Points):\n                               Problem 8 (BONUS: 80 Points):\n                        Total (550 (470 + 80 bonus) Points):\nExamination Rules:\n  1. Written exam, 180 minutes in total.\n  2. No books, no calculators, no computers or communication devices.     6 pages of handwritten notes are\n     allowed.\n  3. Write all your answers on this document, space is reserved for your answers after each question. Blank\n     pages are available at the end of the exam.\n  4. Clearly indicate your final answer for each problem. Answers will only be evaluated if they are readable.\n  5. Put your Student ID card visible on the desk during the exam.\n  6. If you feel disturbed, immediately call an assistant.\n  7. Write with a black or blue pen (no pencil, no green or red color).\n  8. Show all your work. For some questions, you may get partial credit even if the end result is wrong due\n     to a calculation mistake.\n  9. Please write your initials at the top of every page.\n   Tips:\n \u2022 Be cognizant of time. Do not spend too much time on one question.\n \u2022 Be concise. You may be penalized for verbosity.\n \u2022 Show work when needed. You will receive partial credit at the instructors\u2019 discretion.\n \u2022 Write legibly. Show your final answer.",
            "md": "# Midterm Exam\n\n# Computer Architecture (263-2210-00L)\n\n# ETH Z\u00fcrich, Fall 2017\n\n# Prof. Onur Mutlu\n\n# Problem 1 (30 Points):\n\n# Problem 2 (80 Points):\n\n# Problem 3 (90 Points):\n\n# Problem 4 (40 Points):\n\n# Problem 5 (70 Points):\n\n# Problem 6 (90 Points):\n\n# Problem 7 (70 Points):\n\n# Problem 8 (BONUS: 80 Points):\n\n# Total (550 (470 + 80 bonus) Points):\n\n# Examination Rules:\n\n1. Written exam, 180 minutes in total.\n2. No books, no calculators, no computers or communication devices. 6 pages of handwritten notes are allowed.\n3. Write all your answers on this document, space is reserved for your answers after each question. Blank pages are available at the end of the exam.\n4. Clearly indicate your final answer for each problem. Answers will only be evaluated if they are readable.\n5. Put your Student ID card visible on the desk during the exam.\n6. If you feel disturbed, immediately call an assistant.\n7. Write with a black or blue pen (no pencil, no green or red color).\n8. Show all your work. For some questions, you may get partial credit even if the end result is wrong due to a calculation mistake.\n9. Please write your initials at the top of every page.\n\n# Tips:\n\n- Be cognizant of time. Do not spend too much time on one question.\n- Be concise. You may be penalized for verbosity.\n- Show work when needed. You will receive partial credit at the instructors\u2019 discretion.\n- Write legibly. Show your final answer.",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 244.67,
                        "y": 63.16,
                        "w": 106.23,
                        "h": 14.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture (263-2210-00L)",
                    "md": "# Computer Architecture (263-2210-00L)",
                    "rows": null,
                    "bBox": {
                        "x": 138.64,
                        "y": 88.47,
                        "w": 318.43,
                        "h": 17.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "ETH Z\u00fcrich, Fall 2017",
                    "md": "# ETH Z\u00fcrich, Fall 2017",
                    "rows": null,
                    "bBox": {
                        "x": 206.34,
                        "y": 120.05,
                        "w": 182.46,
                        "h": 17.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Prof. Onur Mutlu",
                    "md": "# Prof. Onur Mutlu",
                    "rows": null,
                    "bBox": {
                        "x": 251.56,
                        "y": 151.66,
                        "w": 92.62,
                        "h": 12.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 1 (30 Points):",
                    "md": "# Problem 1 (30 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 182.4,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 2 (80 Points):",
                    "md": "# Problem 2 (80 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 204.11,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 3 (90 Points):",
                    "md": "# Problem 3 (90 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 225.83,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 4 (40 Points):",
                    "md": "# Problem 4 (40 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 247.54,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 5 (70 Points):",
                    "md": "# Problem 5 (70 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 269.26,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 6 (90 Points):",
                    "md": "# Problem 6 (90 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 290.97,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 7 (70 Points):",
                    "md": "# Problem 7 (70 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 230.39,
                        "y": 312.69,
                        "w": 99.46,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Problem 8 (BONUS: 80 Points):",
                    "md": "# Problem 8 (BONUS: 80 Points):",
                    "rows": null,
                    "bBox": {
                        "x": 189.02,
                        "y": 334.4,
                        "w": 140.82,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Total (550 (470 + 80 bonus) Points):",
                    "md": "# Total (550 (470 + 80 bonus) Points):",
                    "rows": null,
                    "bBox": {
                        "x": 168.25,
                        "y": 356.52,
                        "w": 161.6,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Examination Rules:",
                    "md": "# Examination Rules:",
                    "rows": null,
                    "bBox": {
                        "x": 57.6,
                        "y": 451.56,
                        "w": 98.34,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "1. Written exam, 180 minutes in total.\n2. No books, no calculators, no computers or communication devices. 6 pages of handwritten notes are allowed.\n3. Write all your answers on this document, space is reserved for your answers after each question. Blank pages are available at the end of the exam.\n4. Clearly indicate your final answer for each problem. Answers will only be evaluated if they are readable.\n5. Put your Student ID card visible on the desk during the exam.\n6. If you feel disturbed, immediately call an assistant.\n7. Write with a black or blue pen (no pencil, no green or red color).\n8. Show all your work. For some questions, you may get partial credit even if the end result is wrong due to a calculation mistake.\n9. Please write your initials at the top of every page.",
                    "md": "1. Written exam, 180 minutes in total.\n2. No books, no calculators, no computers or communication devices. 6 pages of handwritten notes are allowed.\n3. Write all your answers on this document, space is reserved for your answers after each question. Blank pages are available at the end of the exam.\n4. Clearly indicate your final answer for each problem. Answers will only be evaluated if they are readable.\n5. Put your Student ID card visible on the desk during the exam.\n6. If you feel disturbed, immediately call an assistant.\n7. Write with a black or blue pen (no pencil, no green or red color).\n8. Show all your work. For some questions, you may get partial credit even if the end result is wrong due to a calculation mistake.\n9. Please write your initials at the top of every page.",
                    "rows": null,
                    "bBox": {
                        "x": 69.78,
                        "y": 471.48,
                        "w": 468.3,
                        "h": 173.39
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Tips:",
                    "md": "# Tips:",
                    "rows": null,
                    "bBox": {
                        "x": 72.54,
                        "y": 654.8,
                        "w": 25.0,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "- Be cognizant of time. Do not spend too much time on one question.\n- Be concise. You may be penalized for verbosity.\n- Show work when needed. You will receive partial credit at the instructors\u2019 discretion.\n- Write legibly. Show your final answer.",
                    "md": "- Be cognizant of time. Do not spend too much time on one question.\n- Be concise. You may be penalized for verbosity.\n- Show work when needed. You will receive partial credit at the instructors\u2019 discretion.\n- Write legibly. Show your final answer.",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 2,
            "text": "Initials: Solutions                    Computer Architecture                     December 7th, 2017\n                                 This page intentionally left blank\nMidterm Exam                                                                            Page 1 of 20",
            "md": "# Midterm Exam\n\nInitials: Solutions\n\nComputer Architecture\n\nDecember 7th, 2017\n\nThis page intentionally left blank\n\nPage 1 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Initials: Solutions\n\nComputer Architecture\n\nDecember 7th, 2017\n\nThis page intentionally left blank\n\nPage 1 of 20",
                    "md": "Initials: Solutions\n\nComputer Architecture\n\nDecember 7th, 2017\n\nThis page intentionally left blank\n\nPage 1 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 751.56
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 3,
            "text": "Initials: Solutions                     Computer Architecture                       December 7th, 2017\n1     Emerging Memory Technologies                        [30 points]\nComputer scientists at ETH developed a new memory technology, ETH-RAM, which is non-volatile.\nThe access latency of ETH-RAM is close to that of DRAM while it provides higher density compared\nto the latest DRAM technologies. ETH-RAM has one shortcoming, however: it has limited endurance,\ni.e., a memory cell stops functioning after 106 writes are performed to the cell (known as cell wear-out).\n    A bright ETH student has built a computer system using 1 GB of ETH-RAM as main memory. ETH-\nRAM exploits a perfect wear-leveling mechanism, i.e., a mechanism that equally distributes the writes\nover all of the cells of the main memory.\n(a) [15 points] This student is worried about the lifetime of the computer system she has built.    She\n    executes a test program that runs special instructions to bypass the cache hierarchy and repeatedly\n    writes data into different words until all the ETH-RAM cells are worn-out (stop functioning) and\n    the system becomes useless.   The student\u2019s measurements show that ETH-RAM stops functioning\n    (i.e., all its cells are worn-out) in one year (365 days). Assume the following:\n       \u2022 The processor is in-order and there is no memory-level parallelism.\n       \u2022  It takes 5 ns to send a memory request from the processor to the memory controller and it takes\n          28 ns to send the request from the memory controller to ETH-RAM.\n       \u2022 ETH-RAM is word-addressable. Thus, each write request writes 4 bytes to memory.\n    What is the write latency of ETH-RAM? Show your work.\n          twear_out = 2\u00b3\u2070 \u00d7 106 \u00d7 (twrite_M LC + 5 + 28)\n          365 \u00d7 24 \u00d7  22      9       28     6\n                     3600 \u00d7 10 ns = 2   \u00d7 10 \u00d7 (twrite_M LC + 33)\n          twrite_M LC = 365\u00d724\u00d73600\u00d710\u00b3 \u2212 33 = 84.5ns\n                              228\n          Explanation:\n            \u2022 Each memory cell should receive 106 writes.\n            \u2022  Since ETH-RAM is word addressable, the required amount of writes is equal to 2\u00b3\u2070 \u00d7\n               106 (there is no problem if 1 GB is assumed to be equal to 109 bytes).         22\n            \u2022 The processor is in-order and there is no memory-level parallelism, so the total latency\n               of each memory access is equal to twrite_M LC + 5 + 28.\n(b) [15 points] ETH-RAM works in the multi-level cell (MLC) mode in which each memory cell stores\n    2 bits. The student decides to improve the lifetime of ETH-RAM cells by using the single-level cell\n    (SLC) mode. When ETH-RAM is used in SLC mode, the lifetime of each cell improves by a factor of\n    10 and the write latency decreases by 70%. What is the lifetime of the system using the SLC mode,\n    if we repeat the experiment in part (a), with everything else remaining the same in the system?\n    Show your work.\n          twear_out = 2\u00b2\u2079 \u00d7 107 \u00d7 (25.35 + 5 + 28) \u00d7 10\u22129\n          t        = 2\u00b2\n          wear_out    78579686.3s = 2.49 year\n          Explanation:\n            \u2022 Each memory cell should receive 10 \u00d7 106 = 107 writes.\n            \u2022  The memory capacity is reduced by 50% since we are using SLC: Capacity = 230/2 =\n               229\n            \u2022 The required amount of writes is equal to  229 \u00d7 107.\n                                                         22\n            \u2022 The SLC write latency is 0.3 \u00d7 twrite_M LC : twrite_SLC = 0.3 \u00d7 84.5 = 25.35 ns\nMidterm Exam                                                                               Page 2 of 20",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 1 Emerging Memory Technologies\n\n[30 points]\n\nComputer scientists at ETH developed a new memory technology, ETH-RAM, which is non-volatile. The access latency of ETH-RAM is close to that of DRAM while it provides higher density compared to the latest DRAM technologies. ETH-RAM has one shortcoming, however: it has limited endurance, i.e., a memory cell stops functioning after 106 writes are performed to the cell (known as cell wear-out).\n\nA bright ETH student has built a computer system using 1 GB of ETH-RAM as main memory. ETH-RAM exploits a perfect wear-leveling mechanism, i.e., a mechanism that equally distributes the writes over all of the cells of the main memory.\n\n# (a) [15 points]\n\nThis student is worried about the lifetime of the computer system she has built. She executes a test program that runs special instructions to bypass the cache hierarchy and repeatedly writes data into different words until all the ETH-RAM cells are worn-out (stop functioning) and the system becomes useless. The student\u2019s measurements show that ETH-RAM stops functioning (i.e., all its cells are worn-out) in one year (365 days). Assume the following:\n\n- The processor is in-order and there is no memory-level parallelism.\n- It takes 5 ns to send a memory request from the processor to the memory controller and it takes 28 ns to send the request from the memory controller to ETH-RAM.\n- ETH-RAM is word-addressable. Thus, each write request writes 4 bytes to memory.\n\nWhat is the write latency of ETH-RAM? Show your work.\n\ntwear_out = 230 \u00d7 106 \u00d7 (twrite_M LC + 5 + 28)\n\n365 \u00d7 24 \u00d7 3600 \u00d7 109 ns = 2 \u00d7 1022 \u00d7 (twrite_M LC + 33)\n\ntwrite_M LC = 365 \u00d7 24 \u00d7 3600 \u00d7 103 \u2212 33 = 84.5 ns\n\nExplanation:\n\n- Each memory cell should receive 106 writes.\n- Since ETH-RAM is word addressable, the required amount of writes is equal to 230 \u00d7 106 (there is no problem if 1 GB is assumed to be equal to 109 bytes).\n- The processor is in-order and there is no memory-level parallelism, so the total latency of each memory access is equal to twrite_M LC + 5 + 28.\n\n# (b) [15 points]\n\nETH-RAM works in the multi-level cell (MLC) mode in which each memory cell stores 2 bits. The student decides to improve the lifetime of ETH-RAM cells by using the single-level cell (SLC) mode. When ETH-RAM is used in SLC mode, the lifetime of each cell improves by a factor of 10 and the write latency decreases by 70%. What is the lifetime of the system using the SLC mode, if we repeat the experiment in part (a), with everything else remaining the same in the system? Show your work.\n\ntwear_out = 229 \u00d7 107 \u00d7 (25.35 + 5 + 28) \u00d7 10\u22129\n\ntwear_out = 78,579,686.3 s = 2.49 years\n\nExplanation:\n\n- Each memory cell should receive 10 \u00d7 106 = 107 writes.\n- The memory capacity is reduced by 50% since we are using SLC: Capacity = 230/2 = 229.\n- The required amount of writes is equal to 229 \u00d7 107.\n- The SLC write latency is 0.3 \u00d7 twrite_M LC: twrite_SLC = 0.3 \u00d7 84.5 = 25.35 ns\n\nMidterm Exam\n\nPage 2 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 77.4,
                        "h": 586.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 43.11,
                        "w": 236.64,
                        "h": 586.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 586.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "1 Emerging Memory Technologies",
                    "md": "# 1 Emerging Memory Technologies",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 245.09,
                        "h": 562.38
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "[30 points]\n\nComputer scientists at ETH developed a new memory technology, ETH-RAM, which is non-volatile. The access latency of ETH-RAM is close to that of DRAM while it provides higher density compared to the latest DRAM technologies. ETH-RAM has one shortcoming, however: it has limited endurance, i.e., a memory cell stops functioning after 106 writes are performed to the cell (known as cell wear-out).\n\nA bright ETH student has built a computer system using 1 GB of ETH-RAM as main memory. ETH-RAM exploits a perfect wear-leveling mechanism, i.e., a mechanism that equally distributes the writes over all of the cells of the main memory.",
                    "md": "[30 points]\n\nComputer scientists at ETH developed a new memory technology, ETH-RAM, which is non-volatile. The access latency of ETH-RAM is close to that of DRAM while it provides higher density compared to the latest DRAM technologies. ETH-RAM has one shortcoming, however: it has limited endurance, i.e., a memory cell stops functioning after 106 writes are performed to the cell (known as cell wear-out).\n\nA bright ETH student has built a computer system using 1 GB of ETH-RAM as main memory. ETH-RAM exploits a perfect wear-leveling mechanism, i.e., a mechanism that equally distributes the writes over all of the cells of the main memory.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.71,
                        "h": 562.38
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [15 points]",
                    "md": "# (a) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 43.39,
                        "h": 562.38
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "This student is worried about the lifetime of the computer system she has built. She executes a test program that runs special instructions to bypass the cache hierarchy and repeatedly writes data into different words until all the ETH-RAM cells are worn-out (stop functioning) and the system becomes useless. The student\u2019s measurements show that ETH-RAM stops functioning (i.e., all its cells are worn-out) in one year (365 days). Assume the following:\n\n- The processor is in-order and there is no memory-level parallelism.\n- It takes 5 ns to send a memory request from the processor to the memory controller and it takes 28 ns to send the request from the memory controller to ETH-RAM.\n- ETH-RAM is word-addressable. Thus, each write request writes 4 bytes to memory.\n\nWhat is the write latency of ETH-RAM? Show your work.\n\ntwear_out = 230 \u00d7 106 \u00d7 (twrite_M LC + 5 + 28)\n\n365 \u00d7 24 \u00d7 3600 \u00d7 109 ns = 2 \u00d7 1022 \u00d7 (twrite_M LC + 33)\n\ntwrite_M LC = 365 \u00d7 24 \u00d7 3600 \u00d7 103 \u2212 33 = 84.5 ns\n\nExplanation:\n\n- Each memory cell should receive 106 writes.\n- Since ETH-RAM is word addressable, the required amount of writes is equal to 230 \u00d7 106 (there is no problem if 1 GB is assumed to be equal to 109 bytes).\n- The processor is in-order and there is no memory-level parallelism, so the total latency of each memory access is equal to twrite_M LC + 5 + 28.",
                    "md": "This student is worried about the lifetime of the computer system she has built. She executes a test program that runs special instructions to bypass the cache hierarchy and repeatedly writes data into different words until all the ETH-RAM cells are worn-out (stop functioning) and the system becomes useless. The student\u2019s measurements show that ETH-RAM stops functioning (i.e., all its cells are worn-out) in one year (365 days). Assume the following:\n\n- The processor is in-order and there is no memory-level parallelism.\n- It takes 5 ns to send a memory request from the processor to the memory controller and it takes 28 ns to send the request from the memory controller to ETH-RAM.\n- ETH-RAM is word-addressable. Thus, each write request writes 4 bytes to memory.\n\nWhat is the write latency of ETH-RAM? Show your work.\n\ntwear_out = 230 \u00d7 106 \u00d7 (twrite_M LC + 5 + 28)\n\n365 \u00d7 24 \u00d7 3600 \u00d7 109 ns = 2 \u00d7 1022 \u00d7 (twrite_M LC + 33)\n\ntwrite_M LC = 365 \u00d7 24 \u00d7 3600 \u00d7 103 \u2212 33 = 84.5 ns\n\nExplanation:\n\n- Each memory cell should receive 106 writes.\n- Since ETH-RAM is word addressable, the required amount of writes is equal to 230 \u00d7 106 (there is no problem if 1 GB is assumed to be equal to 109 bytes).\n- The processor is in-order and there is no memory-level parallelism, so the total latency of each memory access is equal to twrite_M LC + 5 + 28.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.3,
                        "h": 649.49
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [15 points]",
                    "md": "# (b) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 43.39,
                        "h": 562.38
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "ETH-RAM works in the multi-level cell (MLC) mode in which each memory cell stores 2 bits. The student decides to improve the lifetime of ETH-RAM cells by using the single-level cell (SLC) mode. When ETH-RAM is used in SLC mode, the lifetime of each cell improves by a factor of 10 and the write latency decreases by 70%. What is the lifetime of the system using the SLC mode, if we repeat the experiment in part (a), with everything else remaining the same in the system? Show your work.\n\ntwear_out = 229 \u00d7 107 \u00d7 (25.35 + 5 + 28) \u00d7 10\u22129\n\ntwear_out = 78,579,686.3 s = 2.49 years\n\nExplanation:\n\n- Each memory cell should receive 10 \u00d7 106 = 107 writes.\n- The memory capacity is reduced by 50% since we are using SLC: Capacity = 230/2 = 229.\n- The required amount of writes is equal to 229 \u00d7 107.\n- The SLC write latency is 0.3 \u00d7 twrite_M LC: twrite_SLC = 0.3 \u00d7 84.5 = 25.35 ns\n\nMidterm Exam\n\nPage 2 of 20",
                    "md": "ETH-RAM works in the multi-level cell (MLC) mode in which each memory cell stores 2 bits. The student decides to improve the lifetime of ETH-RAM cells by using the single-level cell (SLC) mode. When ETH-RAM is used in SLC mode, the lifetime of each cell improves by a factor of 10 and the write latency decreases by 70%. What is the lifetime of the system using the SLC mode, if we repeat the experiment in part (a), with everything else remaining the same in the system? Show your work.\n\ntwear_out = 229 \u00d7 107 \u00d7 (25.35 + 5 + 28) \u00d7 10\u22129\n\ntwear_out = 78,579,686.3 s = 2.49 years\n\nExplanation:\n\n- Each memory cell should receive 10 \u00d7 106 = 107 writes.\n- The memory capacity is reduced by 50% since we are using SLC: Capacity = 230/2 = 229.\n- The required amount of writes is equal to 229 \u00d7 107.\n- The SLC write latency is 0.3 \u00d7 twrite_M LC: twrite_SLC = 0.3 \u00d7 84.5 = 25.35 ns\n\nMidterm Exam\n\nPage 2 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.32,
                        "h": 727.05
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 4,
            "text": "Initials: Solutions                     Computer Architecture                       December 7th, 2017\n2    Cache Performance Analysis                     [80 points]\nWe are going to microbenchmark the cache hierarchy of a computer with the following two codes. The\narray data contains 32-bit unsigned integer values. For simplicity, we consider that accesses to the array\nlatency bypass all caches (i.e., latency is not cached). timer() returns a timestamp in cycles.\n(1) j = 0;\n      for (i=0; i<size; i+=stride){\n          start = timer();\n          d = data[i];\n          stop = timer();\n          latency[j++] = stop - start;\n      }\n(2) for (i=0; i<size1; i+=stride1){\n          d = data[i];\n      }\n      j = 0;\n      for (i=0; i<size2; i+=stride2){\n          start = timer();\n          d = data[i];\n          stop = timer();\n          latency[j++] = stop - start;\n      }\n   The cache hierarchy has two levels. L1 is a 4kB set associative cache.\n(a) [15 points] When we run code (1), we obtain the latency values in the following chart for the first 64\n    reads to the array data (in the first 64 iterations of the loop) with stride equal to 1. What are\n    the cache block sizes in L1 and L2?\n                 800\n                 700\n                 600\n              Latency (cycles)\n                 500\n                 400\n                 300\n                 200\n                 100\n                   0\n                     0 2  4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62\n                                                    Iteration (i)\n         L1 cache block size is 32 bytes, and L2 cache block size is 128 bytes.\n         Explanation:\n         The highest latency values (700 cycles) correspond to L2 cache misses. The latency of 300\n         cycles correspond to L1 cache misses that hit the L2 cache. The lowest latency (100 cycles)\n         corresponds to L1 cache hits. We find L1 misses every 8 32-bit elements, and L2 misses\n         every 32 32-bit elements. Thus, L1 cache blocks are of size 32 bytes, while L2 cache blocks\n         are 128 bytes.\nMidterm Exam                                                                               Page 3 of 20",
            "md": "# Computer Architecture\n\n# Cache Performance Analysis\n\nDate: December 7th, 2017\n\nWe are going to microbenchmark the cache hierarchy of a computer with the following two codes. The array data contains 32-bit unsigned integer values. For simplicity, we consider that accesses to the array latency bypass all caches (i.e., latency is not cached). timer() returns a timestamp in cycles.\n\n(1) j = 0;\nfor (i=0; i<size; i+=stride){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n(2) for (i=0; i<size1; i+=stride1){\nd = data[i];\n}\nj = 0;\nfor (i=0; i<size2; i+=stride2){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n\nThe cache hierarchy has two levels. L1 is a 4kB set associative cache.\n\n# (a) [15 points]\n\nWhen we run code (1), we obtain the latency values in the following chart for the first 64 reads to the array data (in the first 64 iterations of the loop) with stride equal to 1. What are the cache block sizes in L1 and L2?\n\n| Latency (cycles) |         |\n| ---------------- | ------- |\n| Iteration (i)    | Latency |\n| 0                | 800     |\n| 2                | 700     |\n| 4                | 600     |\n| 6                | 500     |\n| 8                | 400     |\n| 10               | 300     |\n| 12               | 200     |\n| 14               | 100     |\n| 16               | 0       |\n| 18               |         |\n| 20               |         |\n| 22               |         |\n| 24               |         |\n| 26               |         |\n| 28               |         |\n| 30               |         |\n| 32               |         |\n| 34               |         |\n| 36               |         |\n| 38               |         |\n| 40               |         |\n| 42               |         |\n| 44               |         |\n| 46               |         |\n| 48               |         |\n| 50               |         |\n| 52               |         |\n| 54               |         |\n| 56               |         |\n| 58               |         |\n| 60               |         |\n| 62               |         |\n\nL1 cache block size is 32 bytes, and L2 cache block size is 128 bytes.\n\nExplanation:\n\nThe highest latency values (700 cycles) correspond to L2 cache misses. The latency of 300 cycles correspond to L1 cache misses that hit the L2 cache. The lowest latency (100 cycles) corresponds to L1 cache hits. We find L1 misses every 8 32-bit elements, and L2 misses every 32 32-bit elements. Thus, L1 cache blocks are of size 32 bytes, while L2 cache blocks are 128 bytes.\n\nMidterm Exam\n\nPage 3 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Performance Analysis",
                    "md": "# Cache Performance Analysis",
                    "rows": null,
                    "bBox": {
                        "x": 95.67,
                        "y": 67.62,
                        "w": 197.33,
                        "h": 14.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Date: December 7th, 2017\n\nWe are going to microbenchmark the cache hierarchy of a computer with the following two codes. The array data contains 32-bit unsigned integer values. For simplicity, we consider that accesses to the array latency bypass all caches (i.e., latency is not cached). timer() returns a timestamp in cycles.\n\n(1) j = 0;\nfor (i=0; i<size; i+=stride){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n(2) for (i=0; i<size1; i+=stride1){\nd = data[i];\n}\nj = 0;\nfor (i=0; i<size2; i+=stride2){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n\nThe cache hierarchy has two levels. L1 is a 4kB set associative cache.",
                    "md": "Date: December 7th, 2017\n\nWe are going to microbenchmark the cache hierarchy of a computer with the following two codes. The array data contains 32-bit unsigned integer values. For simplicity, we consider that accesses to the array latency bypass all caches (i.e., latency is not cached). timer() returns a timestamp in cycles.\n\n(1) j = 0;\nfor (i=0; i<size; i+=stride){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n(2) for (i=0; i<size1; i+=stride1){\nd = data[i];\n}\nj = 0;\nfor (i=0; i<size2; i+=stride2){\nstart = timer();\nd = data[i];\nstop = timer();\nlatency[j++] = stop - start;\n}\n\nThe cache hierarchy has two levels. L1 is a 4kB set associative cache.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.53,
                        "h": 534.75
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [15 points]",
                    "md": "# (a) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "When we run code (1), we obtain the latency values in the following chart for the first 64 reads to the array data (in the first 64 iterations of the loop) with stride equal to 1. What are the cache block sizes in L1 and L2?",
                    "md": "When we run code (1), we obtain the latency values in the following chart for the first 64 reads to the array data (in the first 64 iterations of the loop) with stride equal to 1. What are the cache block sizes in L1 and L2?",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 450.96,
                        "h": 510.24
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Latency (cycles) |         |\n| ---------------- | ------- |\n| Iteration (i)    | Latency |\n| 0                | 800     |\n| 2                | 700     |\n| 4                | 600     |\n| 6                | 500     |\n| 8                | 400     |\n| 10               | 300     |\n| 12               | 200     |\n| 14               | 100     |\n| 16               | 0       |\n| 18               |         |\n| 20               |         |\n| 22               |         |\n| 24               |         |\n| 26               |         |\n| 28               |         |\n| 30               |         |\n| 32               |         |\n| 34               |         |\n| 36               |         |\n| 38               |         |\n| 40               |         |\n| 42               |         |\n| 44               |         |\n| 46               |         |\n| 48               |         |\n| 50               |         |\n| 52               |         |\n| 54               |         |\n| 56               |         |\n| 58               |         |\n| 60               |         |\n| 62               |         |",
                    "rows": [
                        [
                            "Latency (cycles)",
                            ""
                        ],
                        [
                            "Iteration (i)",
                            "Latency"
                        ],
                        [
                            "0",
                            "800"
                        ],
                        [
                            "2",
                            "700"
                        ],
                        [
                            "4",
                            "600"
                        ],
                        [
                            "6",
                            "500"
                        ],
                        [
                            "8",
                            "400"
                        ],
                        [
                            "10",
                            "300"
                        ],
                        [
                            "12",
                            "200"
                        ],
                        [
                            "14",
                            "100"
                        ],
                        [
                            "16",
                            "0"
                        ],
                        [
                            "18",
                            ""
                        ],
                        [
                            "20",
                            ""
                        ],
                        [
                            "22",
                            ""
                        ],
                        [
                            "24",
                            ""
                        ],
                        [
                            "26",
                            ""
                        ],
                        [
                            "28",
                            ""
                        ],
                        [
                            "30",
                            ""
                        ],
                        [
                            "32",
                            ""
                        ],
                        [
                            "34",
                            ""
                        ],
                        [
                            "36",
                            ""
                        ],
                        [
                            "38",
                            ""
                        ],
                        [
                            "40",
                            ""
                        ],
                        [
                            "42",
                            ""
                        ],
                        [
                            "44",
                            ""
                        ],
                        [
                            "46",
                            ""
                        ],
                        [
                            "48",
                            ""
                        ],
                        [
                            "50",
                            ""
                        ],
                        [
                            "52",
                            ""
                        ],
                        [
                            "54",
                            ""
                        ],
                        [
                            "56",
                            ""
                        ],
                        [
                            "58",
                            ""
                        ],
                        [
                            "60",
                            ""
                        ],
                        [
                            "62",
                            ""
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.53,
                        "h": 751.56
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "L1 cache block size is 32 bytes, and L2 cache block size is 128 bytes.\n\nExplanation:\n\nThe highest latency values (700 cycles) correspond to L2 cache misses. The latency of 300 cycles correspond to L1 cache misses that hit the L2 cache. The lowest latency (100 cycles) corresponds to L1 cache hits. We find L1 misses every 8 32-bit elements, and L2 misses every 32 32-bit elements. Thus, L1 cache blocks are of size 32 bytes, while L2 cache blocks are 128 bytes.\n\nMidterm Exam\n\nPage 3 of 20",
                    "md": "L1 cache block size is 32 bytes, and L2 cache block size is 128 bytes.\n\nExplanation:\n\nThe highest latency values (700 cycles) correspond to L2 cache misses. The latency of 300 cycles correspond to L1 cache misses that hit the L2 cache. The lowest latency (100 cycles) corresponds to L1 cache hits. We find L1 misses every 8 32-bit elements, and L2 misses every 32 32-bit elements. Thus, L1 cache blocks are of size 32 bytes, while L2 cache blocks are 128 bytes.\n\nMidterm Exam\n\nPage 3 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.32,
                        "h": 727.05
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 5,
            "text": "Initials: Solutions                                  Computer Architecture         December 7th, 2017\n                 (b) [20 points] Using code (2) with stride1 = stride2 = 32, size1 = 1056, and size2 = 1024, we\n    observe latency[0] = 300 cycles. However, if size1 = 1024, latency[0] = 100 cycles. What\n    is the maximum number of ways in L1? (Note: The replacement policy can be either FIFO or LRU).\n         The maximum number of ways is 32.\n         Explanation:\n         In L1 there are a total of 128 cache blocks. If the accessed space is 1056 elements, 33 cache\n         blocks are read. In case of having more than 32 ways, there would be a hit in the second\n         loop. However, with 32 or less ways, the cache block that contains data[0]    is replaced\n         in the last iteration of the first loop.\n(c) [20 points] We want to find out the exact replacement policy, assuming that the associativity is the\n    maximum obtained in part (b). We first run code (2) with stride1 = 32, size1 = 1024, stride2\n    = 64, and size2 = 1056. Then (after resetting j), we run code (1) with stride = 32 and size\n    = 1024. We observe latency[1] = 100 cycles. What is the replacement policy? Explain. (Hint:\n    The replacement policy can be either FIFO or LRU. You need to find the correct one and explain).\n         It is FIFO.\n         Explanation:\n         In the second loop of code (2), the last cache block that is accessed (data[1024]) replaces\n         the cache block that contains data[0], if the replacement policy is FIFO. If the replace-\n         ment policy is LRU, the LRU cache block (the one that contains data[32]). Because we\n         observe that latency[1]     is 100 cycles, and it corresponds to the access to data[32],\n         we conclude the replacement policy is FIFO.\n(d) [25 points] Now we carry out two consecutive runs of code (1) for different values of size. In the\n    first run, stride  is equal to 1. In the second run, stride  is equal to 16. We ignore the latency\n    results of the first run, and average the latency results of the second run. We obtain the following\n    graph. What do the four parts shown with the arrows represent?\n                 800\n                 700\n                 600\n              Latency (cycles)              2                3             4\n                 500\n                 400\n                 300             1\n                 200\n                 100\n                   0                                   size\nMidterm Exam                                                                              Page 4 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\n# (b) [20 points]\n\nUsing code (2) with stride1 = stride2 = 32, size1 = 1056, and size2 = 1024, we observe latency[0] = 300 cycles. However, if size1 = 1024, latency[0] = 100 cycles. What is the maximum number of ways in L1? (Note: The replacement policy can be either FIFO or LRU).\n\nThe maximum number of ways is 32.\n\nExplanation:\n\nIn L1 there are a total of 128 cache blocks. If the accessed space is 1056 elements, 33 cache blocks are read. In case of having more than 32 ways, there would be a hit in the second loop. However, with 32 or less ways, the cache block that contains data[0] is replaced in the last iteration of the first loop.\n\n# (c) [20 points]\n\nWe want to find out the exact replacement policy, assuming that the associativity is the maximum obtained in part (b). We first run code (2) with stride1 = 32, size1 = 1024, stride2 = 64, and size2 = 1056. Then (after resetting j), we run code (1) with stride = 32 and size = 1024. We observe latency[1] = 100 cycles. What is the replacement policy? Explain. (Hint: The replacement policy can be either FIFO or LRU. You need to find the correct one and explain).\n\nIt is FIFO.\n\nExplanation:\n\nIn the second loop of code (2), the last cache block that is accessed (data[1024]) replaces the cache block that contains data[0], if the replacement policy is FIFO. If the replacement policy is LRU, the LRU cache block (the one that contains data[32]). Because we observe that latency[1] is 100 cycles, and it corresponds to the access to data[32], we conclude the replacement policy is FIFO.\n\n# (d) [25 points]\n\nNow we carry out two consecutive runs of code (1) for different values of size. In the first run, stride is equal to 1. In the second run, stride is equal to 16. We ignore the latency results of the first run, and average the latency results of the second run. We obtain the following graph. What do the four parts shown with the arrows represent?\n\n| Latency (cycles) | 2 | 3 | 4 |\n| ---------------- | - | - | - |\n| 800              |   |   |   |\n| 700              |   |   |   |\n| 600              |   |   |   |\n| 500              |   |   |   |\n| 400              |   |   |   |\n| 300              | 1 |   |   |\n| 200              |   |   |   |\n| 100              |   |   |   |\n| 0                |   |   |   |\n\nMidterm Exam\n\nPage 4 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 154.8,
                        "y": 43.11,
                        "w": 368.56,
                        "h": 697.32
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [20 points]",
                    "md": "# (b) [20 points]",
                    "rows": null,
                    "bBox": {
                        "x": 154.8,
                        "y": 647.91,
                        "w": 115.19,
                        "h": 92.52
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Using code (2) with stride1 = stride2 = 32, size1 = 1056, and size2 = 1024, we observe latency[0] = 300 cycles. However, if size1 = 1024, latency[0] = 100 cycles. What is the maximum number of ways in L1? (Note: The replacement policy can be either FIFO or LRU).\n\nThe maximum number of ways is 32.\n\nExplanation:\n\nIn L1 there are a total of 128 cache blocks. If the accessed space is 1056 elements, 33 cache blocks are read. In case of having more than 32 ways, there would be a hit in the second loop. However, with 32 or less ways, the cache block that contains data[0] is replaced in the last iteration of the first loop.",
                    "md": "Using code (2) with stride1 = stride2 = 32, size1 = 1056, and size2 = 1024, we observe latency[0] = 300 cycles. However, if size1 = 1024, latency[0] = 100 cycles. What is the maximum number of ways in L1? (Note: The replacement policy can be either FIFO or LRU).\n\nThe maximum number of ways is 32.\n\nExplanation:\n\nIn L1 there are a total of 128 cache blocks. If the accessed space is 1056 elements, 33 cache blocks are read. In case of having more than 32 ways, there would be a hit in the second loop. However, with 32 or less ways, the cache block that contains data[0] is replaced in the last iteration of the first loop.",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 83.96,
                        "w": 433.95,
                        "h": 662.14
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(c) [20 points]",
                    "md": "# (c) [20 points]",
                    "rows": null,
                    "bBox": {
                        "x": 154.8,
                        "y": 647.91,
                        "w": 115.19,
                        "h": 92.52
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We want to find out the exact replacement policy, assuming that the associativity is the maximum obtained in part (b). We first run code (2) with stride1 = 32, size1 = 1024, stride2 = 64, and size2 = 1056. Then (after resetting j), we run code (1) with stride = 32 and size = 1024. We observe latency[1] = 100 cycles. What is the replacement policy? Explain. (Hint: The replacement policy can be either FIFO or LRU. You need to find the correct one and explain).\n\nIt is FIFO.\n\nExplanation:\n\nIn the second loop of code (2), the last cache block that is accessed (data[1024]) replaces the cache block that contains data[0], if the replacement policy is FIFO. If the replacement policy is LRU, the LRU cache block (the one that contains data[32]). Because we observe that latency[1] is 100 cycles, and it corresponds to the access to data[32], we conclude the replacement policy is FIFO.",
                    "md": "We want to find out the exact replacement policy, assuming that the associativity is the maximum obtained in part (b). We first run code (2) with stride1 = 32, size1 = 1024, stride2 = 64, and size2 = 1056. Then (after resetting j), we run code (1) with stride = 32 and size = 1024. We observe latency[1] = 100 cycles. What is the replacement policy? Explain. (Hint: The replacement policy can be either FIFO or LRU. You need to find the correct one and explain).\n\nIt is FIFO.\n\nExplanation:\n\nIn the second loop of code (2), the last cache block that is accessed (data[1024]) replaces the cache block that contains data[0], if the replacement policy is FIFO. If the replacement policy is LRU, the LRU cache block (the one that contains data[32]). Because we observe that latency[1] is 100 cycles, and it corresponds to the access to data[32], we conclude the replacement policy is FIFO.",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 168.28,
                        "w": 433.72,
                        "h": 577.82
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(d) [25 points]",
                    "md": "# (d) [25 points]",
                    "rows": null,
                    "bBox": {
                        "x": 264.99,
                        "y": 647.91,
                        "w": 5.0,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Now we carry out two consecutive runs of code (1) for different values of size. In the first run, stride is equal to 1. In the second run, stride is equal to 16. We ignore the latency results of the first run, and average the latency results of the second run. We obtain the following graph. What do the four parts shown with the arrows represent?",
                    "md": "Now we carry out two consecutive runs of code (1) for different values of size. In the first run, stride is equal to 1. In the second run, stride is equal to 16. We ignore the latency results of the first run, and average the latency results of the second run. We obtain the following graph. What do the four parts shown with the arrows represent?",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 547.42,
                        "w": 433.84,
                        "h": 198.67
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Latency (cycles) | 2 | 3 | 4 |\n| ---------------- | - | - | - |\n| 800              |   |   |   |\n| 700              |   |   |   |\n| 600              |   |   |   |\n| 500              |   |   |   |\n| 400              |   |   |   |\n| 300              | 1 |   |   |\n| 200              |   |   |   |\n| 100              |   |   |   |\n| 0                |   |   |   |",
                    "rows": [
                        [
                            "Latency (cycles)",
                            "2",
                            "3",
                            "4"
                        ],
                        [
                            "800",
                            "",
                            "",
                            ""
                        ],
                        [
                            "700",
                            "",
                            "",
                            ""
                        ],
                        [
                            "600",
                            "",
                            "",
                            ""
                        ],
                        [
                            "500",
                            "",
                            "",
                            ""
                        ],
                        [
                            "400",
                            "",
                            "",
                            ""
                        ],
                        [
                            "300",
                            "1",
                            "",
                            ""
                        ],
                        [
                            "200",
                            "",
                            "",
                            ""
                        ],
                        [
                            "100",
                            "",
                            "",
                            ""
                        ],
                        [
                            "0",
                            "",
                            "",
                            ""
                        ]
                    ],
                    "bBox": {
                        "x": 71.45,
                        "y": 43.11,
                        "w": 452.21,
                        "h": 751.56
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Midterm Exam\n\nPage 4 of 20",
                    "md": "Midterm Exam\n\nPage 4 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 647.91,
                        "w": 451.32,
                        "h": 146.76
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 6,
            "text": "Initials: Solutions                     Computer Architecture                      December 7th, 2017\n    Before arrow 1:\n         The entire array fits in L1. In arrow 1 the size of the array is the same as the size of L1\n         (4kB).\n    Between arrow 1 and arrow 2:\n         Some accesses in the second run hit in L1 and other accesses hit in L2.\n    Between arrow 2 and arrow 3:\n         All accesses in the second run hit in L2.\n    Between arrow 3 and arrow 4:\n         Still some accesses in the second run hit in L2. Arrow 3 marks the size of the L2 cache.\n    After arrow 4:\n         The accesses of the second run always miss in L2, and it is necessary to access main\n         memory.\n    Explain as needed (if you need more):\nMidterm Exam                                                                              Page 5 of 20",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\nBefore arrow 1:\n\nThe entire array fits in L1. In arrow 1 the size of the array is the same as the size of L1 (4kB).\n\nBetween arrow 1 and arrow 2:\n\nSome accesses in the second run hit in L1 and other accesses hit in L2.\n\nBetween arrow 2 and arrow 3:\n\nAll accesses in the second run hit in L2.\n\nBetween arrow 3 and arrow 4:\n\nStill some accesses in the second run hit in L2. Arrow 3 marks the size of the L2 cache.\n\nAfter arrow 4:\n\nThe accesses of the second run always miss in L2, and it is necessary to access main memory.\n\nExplain as needed (if you need more):\n\n# Midterm Exam\n\nPage 5 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 77.4,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Before arrow 1:\n\nThe entire array fits in L1. In arrow 1 the size of the array is the same as the size of L1 (4kB).\n\nBetween arrow 1 and arrow 2:\n\nSome accesses in the second run hit in L1 and other accesses hit in L2.\n\nBetween arrow 2 and arrow 3:\n\nAll accesses in the second run hit in L2.\n\nBetween arrow 3 and arrow 4:\n\nStill some accesses in the second run hit in L2. Arrow 3 marks the size of the L2 cache.\n\nAfter arrow 4:\n\nThe accesses of the second run always miss in L2, and it is necessary to access main memory.\n\nExplain as needed (if you need more):",
                    "md": "Before arrow 1:\n\nThe entire array fits in L1. In arrow 1 the size of the array is the same as the size of L1 (4kB).\n\nBetween arrow 1 and arrow 2:\n\nSome accesses in the second run hit in L1 and other accesses hit in L2.\n\nBetween arrow 2 and arrow 3:\n\nAll accesses in the second run hit in L2.\n\nBetween arrow 3 and arrow 4:\n\nStill some accesses in the second run hit in L2. Arrow 3 marks the size of the L2 cache.\n\nAfter arrow 4:\n\nThe accesses of the second run always miss in L2, and it is necessary to access main memory.\n\nExplain as needed (if you need more):",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 72.0,
                        "w": 412.31,
                        "h": 416.31
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Page 5 of 20",
                    "md": "Page 5 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 469.46,
                        "y": 784.67,
                        "w": 53.85,
                        "h": 10.0
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 7,
            "text": "Initials: Solutions                   Computer Architecture                    December 7th, 2017\n3    GPUs and SIMD              [90 points]\nWe define the SIMD utilization of a program run on a GPU as the fraction of SIMD lanes that are kept\nbusy with active threads during the run of a program. As we saw in lecture and practice exercises, the\nSIMD utilization of a program is computed across the complete run of the program.\n   The following code segment is run on a GPU. Each thread executes a single iteration of the shown\nloop. Assume that the data values of the arrays A, B, and C are already in vector registers, so there\nare no loads and stores in this program. (Hint: Notice that there are 6 instructions in each thread.) A\nwarp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Please assume that\nall values in arrays B and C have magnitudes less than 10 (i.e., |B[i]| < 10 and |C[i]| < 10, for all i).\nfor (i = 0; i < 1008; i++) {\n  A[i] = B[i] * C[i];\n  if (A[i] < 0) {\n     C[i] = A[i] * B[i];\n     if (C[i] < 0) {\n       A[i] = A[i] + 1;\n     }\n     A[i] = A[i] - 2;\n  }\n}\n   Please answer the following six questions.\n(a) [10 points] How many warps does it take to execute this program?\n        32 warps\n        Explanation: number of warps = d (number of elements) / (warp size) e = d1008/32e =\n        32 warps\n(b) [10 points] What is the maximum possible SIMD utilization of this program?\n        0.984375\n        Explanation:     We  have  31  fully-utilized warps and one  warp  with  only  16 ac-\n        tive threads.  In  case with  no branch  divergence,  the SIMD  utilization would be:\n        (32 \u00d7 31 + 16)/(32 \u00d7 32) = 0.984375\nMidterm Exam                                                                          Page 6 of 20",
            "md": "# Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 3 GPUs and SIMD [90 points]\n\nWe define the SIMD utilization of a program run on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. As we saw in lecture and practice exercises, the SIMD utilization of a program is computed across the complete run of the program.\n\nThe following code segment is run on a GPU. Each thread executes a single iteration of the shown loop. Assume that the data values of the arrays A, B, and C are already in vector registers, so there are no loads and stores in this program. (Hint: Notice that there are 6 instructions in each thread.) A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Please assume that all values in arrays B and C have magnitudes less than 10 (i.e., |B[i]| &lt; 10 and |C[i]| &lt; 10, for all i).\n\nfor (i = 0; i &lt; 1008; i++) {\nA[i] = B[i] * C[i];\nif (A[i] &lt; 0) {\nC[i] = A[i] * B[i];\nif (C[i] &lt; 0) {\nA[i] = A[i] + 1;\n}\nA[i] = A[i] - 2;\n}\n}\n\nPlease answer the following six questions.\n\n# (a) [10 points] How many warps does it take to execute this program?\n\n32 warps\n\nExplanation: number of warps = d (number of elements) / (warp size) e = d1008/32e = 32 warps\n\n# (b) [10 points] What is the maximum possible SIMD utilization of this program?\n\n0.984375\n\nExplanation: We have 31 fully-utilized warps and one warp with only 16 active threads. In case with no branch divergence, the SIMD utilization would be: (32 \u00d7 31 + 16)/(32 \u00d7 32) = 0.984375\n\n# Midterm Exam\n\nPage 6 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Solutions",
                    "md": "# Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "3 GPUs and SIMD [90 points]",
                    "md": "# 3 GPUs and SIMD [90 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 289.99,
                        "h": 469.51
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We define the SIMD utilization of a program run on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. As we saw in lecture and practice exercises, the SIMD utilization of a program is computed across the complete run of the program.\n\nThe following code segment is run on a GPU. Each thread executes a single iteration of the shown loop. Assume that the data values of the arrays A, B, and C are already in vector registers, so there are no loads and stores in this program. (Hint: Notice that there are 6 instructions in each thread.) A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Please assume that all values in arrays B and C have magnitudes less than 10 (i.e., |B[i]| &lt; 10 and |C[i]| &lt; 10, for all i).\n\nfor (i = 0; i &lt; 1008; i++) {\nA[i] = B[i] * C[i];\nif (A[i] &lt; 0) {\nC[i] = A[i] * B[i];\nif (C[i] &lt; 0) {\nA[i] = A[i] + 1;\n}\nA[i] = A[i] - 2;\n}\n}\n\nPlease answer the following six questions.",
                    "md": "We define the SIMD utilization of a program run on a GPU as the fraction of SIMD lanes that are kept busy with active threads during the run of a program. As we saw in lecture and practice exercises, the SIMD utilization of a program is computed across the complete run of the program.\n\nThe following code segment is run on a GPU. Each thread executes a single iteration of the shown loop. Assume that the data values of the arrays A, B, and C are already in vector registers, so there are no loads and stores in this program. (Hint: Notice that there are 6 instructions in each thread.) A warp in the GPU consists of 32 threads, and there are 32 SIMD lanes in the GPU. Please assume that all values in arrays B and C have magnitudes less than 10 (i.e., |B[i]| &lt; 10 and |C[i]| &lt; 10, for all i).\n\nfor (i = 0; i &lt; 1008; i++) {\nA[i] = B[i] * C[i];\nif (A[i] &lt; 0) {\nC[i] = A[i] * B[i];\nif (C[i] &lt; 0) {\nA[i] = A[i] + 1;\n}\nA[i] = A[i] - 2;\n}\n}\n\nPlease answer the following six questions.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.46,
                        "h": 469.51
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [10 points] How many warps does it take to execute this program?",
                    "md": "# (a) [10 points] How many warps does it take to execute this program?",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 350.86,
                        "w": 340.2,
                        "h": 186.28
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "32 warps\n\nExplanation: number of warps = d (number of elements) / (warp size) e = d1008/32e = 32 warps",
                    "md": "32 warps\n\nExplanation: number of warps = d (number of elements) / (warp size) e = d1008/32e = 32 warps",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 429.85,
                        "h": 457.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [10 points] What is the maximum possible SIMD utilization of this program?",
                    "md": "# (b) [10 points] What is the maximum possible SIMD utilization of this program?",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 455.78,
                        "w": 378.75,
                        "h": 81.35
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "0.984375\n\nExplanation: We have 31 fully-utilized warps and one warp with only 16 active threads. In case with no branch divergence, the SIMD utilization would be: (32 \u00d7 31 + 16)/(32 \u00d7 32) = 0.984375",
                    "md": "0.984375\n\nExplanation: We have 31 fully-utilized warps and one warp with only 16 active threads. In case with no branch divergence, the SIMD utilization would be: (32 \u00d7 31 + 16)/(32 \u00d7 32) = 0.984375",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 429.59,
                        "h": 481.47
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Page 6 of 20",
                    "md": "Page 6 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 469.46,
                        "y": 784.67,
                        "w": 53.85,
                        "h": 10.0
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 8,
            "text": "Initials: Solutions                    Computer Architecture                     December 7th, 2017\n(c) [20 points] Please describe what needs to be true about arrays B and C to reach the maximum\n    possible SIMD utilization asked in part (b). (Please cover all possible cases in your answer)\n         For each 32 consecutive elements: ((B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] >\n         0 & C[i] > 0)) || ((B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0))\n         Explanation: We can have two possibilities:\n         (1) No threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements,\n         the following condition is true:\n         (B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)\n         (2) All threads inside a warp take the first \"if\".  It is possible if for 32 consecutive\n         elements, the following condition is true:\n         (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n         This condition also ensures that for the second \"if\", all threads take the branch or no\n         threads take the branch.\n         Finally, for every 32 consecutive elements, we should have one of the mentioned possibili-\n         ties. For the warp with 16 active threads, we should have one of mentioned possibilities\n         for every 16 consecutive elements\n(d) [10 points] What is the minimum  possible SIMD utilization of this program?\n         ((32+32+4)\u00d731+16+16+4)/(32\u00d76\u00d732)=0.3489\n         Explanation:    The   first two lines must  be executed  by  every  thread in  a warp.\n         The minimum utilization results when a single thread from each warp passes both\n         conditions, and every other thread fails to meet the condition on the first \"if\". The thread\n         per warp that meets both conditions, executes four instructions.\n(e) [20 points] Please describe what needs to be true about arrays B and C to reach the minimum\n    possible SIMD utilization asked in part (d). (Please cover all possible cases in your answer)\n         Exactly 1 of every 32 consecutive elements in arrays B and C should have this condition:\n         B[i] > 0 & C[i] < 0\n         Explanation:    Only one thread in a warp should pass the first condition.      There-\n         fore, exactly 1 of every 32 consecutive elements in arrays B and C should have the\n         following condition:\n         (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n         However, the thread in a warp which passes the first condition should also pass the second\n         condition.  Therefore, the only condition which ensures the minimum possible SIMD\n         utilization is: exactly 1 of every 32 consecutive elements in arrays B and C should have\n         this condition: B[i] > 0 & C[i] < 0. For the warp with 16 active threads, this condition\n         should be true for exactly 1 of the 16 elements.\n(f) [20 points] Now consider a GPU that employs Dynamic Warp Formation (DWF)          to improve the\n    SIMD utilization.  As we discussed in the class, DWF dynamically merges threads executing the\n    same instruction (after branch divergence).  What is the maximum achievable SIMD utilization\n    using DWF? Explain your answer (Hint:     The maximum SIMD utilization can happen under the\n    conditions you found in part (e)).\nMidterm Exam                                                                            Page 7 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\n# (c) [20 points] Please describe what needs to be true about arrays B and C to reach the maximum possible SIMD utilization asked in part (b). (Please cover all possible cases in your answer)\n\nFor each 32 consecutive elements: ((B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)) || ((B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0))\n\nExplanation: We can have two possibilities:\n\n1. No threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)\n2. All threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nThis condition also ensures that for the second \"if\", all threads take the branch or no threads take the branch.\n\nFinally, for every 32 consecutive elements, we should have one of the mentioned possibilities. For the warp with 16 active threads, we should have one of mentioned possibilities for every 16 consecutive elements.\n\n# (d) [10 points] What is the minimum possible SIMD utilization of this program?\n\n((32+32+4)\u00d731+16+16+4)/(32\u00d76\u00d732)=0.3489\n\nExplanation: The first two lines must be executed by every thread in a warp. The minimum utilization results when a single thread from each warp passes both conditions, and every other thread fails to meet the condition on the first \"if\". The thread per warp that meets both conditions, executes four instructions.\n\n# (e) [20 points] Please describe what needs to be true about arrays B and C to reach the minimum possible SIMD utilization asked in part (d). (Please cover all possible cases in your answer)\n\nExactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0\n\nExplanation: Only one thread in a warp should pass the first condition. Therefore, exactly 1 of every 32 consecutive elements in arrays B and C should have the following condition: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nHowever, the thread in a warp which passes the first condition should also pass the second condition. Therefore, the only condition which ensures the minimum possible SIMD utilization is: exactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0. For the warp with 16 active threads, this condition should be true for exactly 1 of the 16 elements.\n\n# (f) [20 points] Now consider a GPU that employs Dynamic Warp Formation (DWF) to improve the SIMD utilization. As we discussed in the class, DWF dynamically merges threads executing the same instruction (after branch divergence). What is the maximum achievable SIMD utilization using DWF? Explain your answer (Hint: The maximum SIMD utilization can happen under the conditions you found in part (e)).\n\n# Midterm Exam\n\n# Page 7 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 224.05,
                        "h": 359.41
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 308.85,
                        "y": 43.11,
                        "w": 214.51,
                        "h": 359.41
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(c) [20 points] Please describe what needs to be true about arrays B and C to reach the maximum possible SIMD utilization asked in part (b). (Please cover all possible cases in your answer)",
                    "md": "# (c) [20 points] Please describe what needs to be true about arrays B and C to reach the maximum possible SIMD utilization asked in part (b). (Please cover all possible cases in your answer)",
                    "rows": null,
                    "bBox": {
                        "x": 72.55,
                        "y": 72.0,
                        "w": 451.18,
                        "h": 330.52
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "For each 32 consecutive elements: ((B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)) || ((B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0))\n\nExplanation: We can have two possibilities:\n\n1. No threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)\n2. All threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nThis condition also ensures that for the second \"if\", all threads take the branch or no threads take the branch.\n\nFinally, for every 32 consecutive elements, we should have one of the mentioned possibilities. For the warp with 16 active threads, we should have one of mentioned possibilities for every 16 consecutive elements.",
                    "md": "For each 32 consecutive elements: ((B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)) || ((B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0))\n\nExplanation: We can have two possibilities:\n\n1. No threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i]==0 || C[i]==0) || (B[i] < 0 & C[i] < 0) || (B[i] > 0 & C[i] > 0)\n2. All threads inside a warp take the first \"if\". It is possible if for 32 consecutive elements, the following condition is true: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nThis condition also ensures that for the second \"if\", all threads take the branch or no threads take the branch.\n\nFinally, for every 32 consecutive elements, we should have one of the mentioned possibilities. For the warp with 16 active threads, we should have one of mentioned possibilities for every 16 consecutive elements.",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 119.24,
                        "w": 390.69,
                        "h": 476.55
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(d) [10 points] What is the minimum possible SIMD utilization of this program?",
                    "md": "# (d) [10 points] What is the minimum possible SIMD utilization of this program?",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 338.29,
                        "w": 399.57,
                        "h": 64.23
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "((32+32+4)\u00d731+16+16+4)/(32\u00d76\u00d732)=0.3489\n\nExplanation: The first two lines must be executed by every thread in a warp. The minimum utilization results when a single thread from each warp passes both conditions, and every other thread fails to meet the condition on the first \"if\". The thread per warp that meets both conditions, executes four instructions.",
                    "md": "((32+32+4)\u00d731+16+16+4)/(32\u00d76\u00d732)=0.3489\n\nExplanation: The first two lines must be executed by every thread in a warp. The minimum utilization results when a single thread from each warp passes both conditions, and every other thread fails to meet the condition on the first \"if\". The thread per warp that meets both conditions, executes four instructions.",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 368.61,
                        "w": 390.11,
                        "h": 191.32
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(e) [20 points] Please describe what needs to be true about arrays B and C to reach the minimum possible SIMD utilization asked in part (d). (Please cover all possible cases in your answer)",
                    "md": "# (e) [20 points] Please describe what needs to be true about arrays B and C to reach the minimum possible SIMD utilization asked in part (d). (Please cover all possible cases in your answer)",
                    "rows": null,
                    "bBox": {
                        "x": 72.55,
                        "y": 392.52,
                        "w": 450.23,
                        "h": 92.57
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Exactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0\n\nExplanation: Only one thread in a warp should pass the first condition. Therefore, exactly 1 of every 32 consecutive elements in arrays B and C should have the following condition: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nHowever, the thread in a warp which passes the first condition should also pass the second condition. Therefore, the only condition which ensures the minimum possible SIMD utilization is: exactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0. For the warp with 16 active threads, this condition should be true for exactly 1 of the 16 elements.",
                    "md": "Exactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0\n\nExplanation: Only one thread in a warp should pass the first condition. Therefore, exactly 1 of every 32 consecutive elements in arrays B and C should have the following condition: (B[i] < 0 & C[i] > 0) || (B[i] > 0 & C[i] < 0)\n\nHowever, the thread in a warp which passes the first condition should also pass the second condition. Therefore, the only condition which ensures the minimum possible SIMD utilization is: exactly 1 of every 32 consecutive elements in arrays B and C should have this condition: B[i] > 0 & C[i] < 0. For the warp with 16 active threads, this condition should be true for exactly 1 of the 16 elements.",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 119.24,
                        "w": 390.57,
                        "h": 536.32
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(f) [20 points] Now consider a GPU that employs Dynamic Warp Formation (DWF) to improve the SIMD utilization. As we discussed in the class, DWF dynamically merges threads executing the same instruction (after branch divergence). What is the maximum achievable SIMD utilization using DWF? Explain your answer (Hint: The maximum SIMD utilization can happen under the conditions you found in part (e)).",
                    "md": "# (f) [20 points] Now consider a GPU that employs Dynamic Warp Formation (DWF) to improve the SIMD utilization. As we discussed in the class, DWF dynamically merges threads executing the same instruction (after branch divergence). What is the maximum achievable SIMD utilization using DWF? Explain your answer (Hint: The maximum SIMD utilization can happen under the conditions you found in part (e)).",
                    "rows": null,
                    "bBox": {
                        "x": 73.16,
                        "y": 392.52,
                        "w": 450.28,
                        "h": 354.88
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 392.52,
                        "w": 399.02,
                        "h": 402.15
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Page 7 of 20",
                    "md": "# Page 7 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 466.02,
                        "y": 392.52,
                        "w": 57.3,
                        "h": 402.15
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 9,
            "text": "Initials: Solutions                   Computer Architecture                    December 7th, 2017\n         ((32+32)\u00d731+16+16+32\u00d74)/((32+32)\u00d732+32\u00d74) = 0.985\n         Explanation:   DWF can ideally merge 32 warps with only one active threads in a\n         single warp. This could be happen if none of the threads inside the warp have overlaps.\n         If it happens, we will run 31 fully utilized warps and one warp with 16 active threads for\n         the first and second instructions. Then, we will have only one fully-utilized warp which\n         executes the remaining 4 instructions.\nMidterm Exam                                                                          Page 8 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\nInitials: Solutions\n\n\\(\\frac{(32+32) \\times 31 + 16 + 16 + 32 \\times 4}{(32+32) \\times 32 + 32 \\times 4} = 0.985\\)\n\nExplanation: DWF can ideally merge 32 warps with only one active thread in a single warp. This could happen if none of the threads inside the warp have overlaps. If it happens, we will run 31 fully utilized warps and one warp with 16 active threads for the first and second instructions. Then, we will have only one fully-utilized warp which executes the remaining 4 instructions.\n\n# Midterm Exam\n\nPage 8 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Initials: Solutions\n\n\\(\\frac{(32+32) \\times 31 + 16 + 16 + 32 \\times 4}{(32+32) \\times 32 + 32 \\times 4} = 0.985\\)\n\nExplanation: DWF can ideally merge 32 warps with only one active thread in a single warp. This could happen if none of the threads inside the warp have overlaps. If it happens, we will run 31 fully utilized warps and one warp with 16 active threads for the first and second instructions. Then, we will have only one fully-utilized warp which executes the remaining 4 instructions.",
                    "md": "Initials: Solutions\n\n\\(\\frac{(32+32) \\times 31 + 16 + 16 + 32 \\times 4}{(32+32) \\times 32 + 32 \\times 4} = 0.985\\)\n\nExplanation: DWF can ideally merge 32 warps with only one active thread in a single warp. This could happen if none of the threads inside the warp have overlaps. If it happens, we will run 31 fully utilized warps and one warp with 16 active threads for the first and second instructions. Then, we will have only one fully-utilized warp which executes the remaining 4 instructions.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 429.67,
                        "h": 132.47
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Page 8 of 20",
                    "md": "Page 8 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 469.46,
                        "y": 784.67,
                        "w": 53.85,
                        "h": 10.0
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 10,
            "text": "                 Initials: Solutions                                Computer Architecture                      December 7th, 2017\n                 4    Memory Scheduling                [40 points]\n                 4.1    Basics and Assumptions\n                 To serve a memory request, the memory controller issues one or multiple DRAM commands to access\n                 data from a bank. There are four different DRAM commands as discussed in class.\n                    \u2022 ACTIVATE: Loads the row (that needs to be accessed) into the bank\u2019s row-buffer. This is called\n                       opening a row. (Latency: 15ns)\n                    \u2022     FCFS - Addresses\n                       PRECHARGE: Prepares the bank for the next access by closing the row in the bank (and making\n                       the B0 B2 B0              A0 C0 B1 A0 A0\n                          row buffer empty). (Latency: 15ns)\n                          B3  B2 A0              A1 A0 B0 C0 C1\n                    \u2022 READ/WRITE: Accesses data from the row-buffer. (Latency: 15ns)\n                          FR-FCFS - Addresses\n                    The    B2 B1 B0              B0 A0 C0 A0 A0\n                         diagrams below show the snapshots of memory controller\u2019s request queues at time 0, i.e., t0, when\n                           B3 B2 A0              A0 B0 C0 A1 C1\nB1 A0 A0         applications A, B, and C are executed together on a multi-core processor. Each application runs on a\nB0 C0 C1         separate core but shares the memory subsystem with other applications. Each request is color-coded to\n                 denote the application to which it belongs. Additionally, each request is annotated with a number that\nes               shows the order of the request among the set of enqueued requests of the application to           Channel 0\n                                                                                           Request Queue for       which it belongs.\nC0 A0 A0         For example, A3 means that this is the third request from application A             Channel 0\n                                                                                                     enqueued in the request queue.\nC0 A1 C1         Assume all memory requests are reads and a read request is B4              B3 B2    A3 C1 B1 A2  A1  Bank 0\n                                                                                            considered to be served when the READ\n                 command is complete (i.e., 15 ns after the request\u2019s READ command is issued).\n                                                                                           Youngest            Oldest Row Buffer\n                                                                               Channel 0                           Channel 1\n                                                 Request Queue for Channel 0     Bank 0  Request Queue for Channel 1    Bank 0\n           C1 C1     Request from application A  B4 B3 B2 A3 C1 B1  A2  A1                  B3 B2 A3 A2 A1 B1 C2 C1\n    B1  B4 B1 C2     Request from application B  Youngest           Oldest     Row Buffer  Youngest            Oldest Row Buffer\n              B3     Request from application C\n        B5 B4 B1\n      A1   A1 A1    Assume also the following:                                 Channel 1\n      A1   A2 A1                   Request Queue for Channel 1          Bank 0\n                    \u2022                            B3 B2 A3 A2 A1 B1 C2 C1\n                       The memory system has two DRAM channels, one DRAM bank per channel, and four rows per\n                       bank.                     Youngest           Oldest Row Buffer\n                    \u2022  All the row-buffers are closed (i.e., empty) at time 0.\n                    \u2022  All applications start to stall at time 0 because of memory.\n                    \u2022 No additional requests from any of the applications arrive at the memory controller.\n                    \u2022 An application (A, B, or C) is considered to be stalled until all     of its memory requests (across all\n                       the request buffers) have been served.\n                 4.2    Problem Specification\n                 The below table shows the stall time of applications A, B, and C with the FCFS (First-Come, First-\n                 Served) and FR-FCFS (First-Ready, First-Come, First-Served) scheduling policies.\n                                                 Scheduling  Application A  Application B            Application C\n                                   FCFS FCFS                             195 ns Channel 1\n                                   B3            B2           A3 A2 A1 B1 C2 C1  285 ns                  135 ns\n                                                 FR-FCFS                 135 ns  225 ns                  90 ns\n                    The diagrams FR-FCFS                                t\u2080  Bank 0\n                                   below show the scheduling order of requests for Channel 0 and Channel 1 with the\n                 FCFS and          B3            B2           A3 A1 B1 C2 A2 C1  Row Buffer\n                                                 FR-FCFS scheduling policies.\n                                                 FCFS                          Channel 0   FCFS                    Channel 1\n                                                 B4 B3 B2 A3 C1 B1  A2  A1                 B3 B2 A3  A2 A1 B1 C2  C1\n           C1 C1     Request from application A  FR-FCFS                t\u2080       Bank 0    FR-FCFS                 t\u2080  Bank 0\n    B1  B4 B1 C2     Request from application B                                Row Buffer  B3 B2 A3  A1 B1 C2 A2  C1  Row Buffer\n        B5 B4 B3     Request from application C  B3 B1 B4 B2 A3 C1  A2  A1\n              B1\n      A1   A1 A1                                                                            FCFS                   Channel 0\n      A1   A2 A1\n                 Midterm Exam                                                               B4 B3 B2 A3 C1 B1  A2  A1  Page 9 of 20\n                                                                                            FR-FCFS                t\u2080  Bank 0\n                                                                                            B3 B1 B4 B2 A3 C1  A2  A1  Row Buffer",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 4 Memory Scheduling [40 points]\n\n# 4.1 Basics and Assumptions\n\nTo serve a memory request, the memory controller issues one or multiple DRAM commands to access data from a bank. There are four different DRAM commands as discussed in class.\n\n- ACTIVATE: Loads the row (that needs to be accessed) into the bank\u2019s row-buffer. This is called opening a row. (Latency: 15ns)\n- PRECHARGE: Prepares the bank for the next access by closing the row in the bank (and making the row buffer empty). (Latency: 15ns)\n- READ/WRITE: Accesses data from the row-buffer. (Latency: 15ns)\n\nThe diagrams below show the snapshots of memory controller\u2019s request queues at time 0, i.e., t0, when applications A, B, and C are executed together on a multi-core processor. Each application runs on a separate core but shares the memory subsystem with other applications. Each request is color-coded to denote the application to which it belongs. Additionally, each request is annotated with a number that shows the order of the request among the set of enqueued requests of the application to which it belongs.\n\nFor example, A3 means that this is the third request from application A enqueued in the request queue. Assume all memory requests are reads and a read request is considered to be served when the READ command is complete (i.e., 15 ns after the request\u2019s READ command is issued).\n\n| Channel 0 | Request Queue for Channel 0 | Bank 0                     |\n| --------- | --------------------------- | -------------------------- |\n| C1        | Request from application A  | B4 B3 B2 A3 C1 B1 A2 A1    |\n| B1        | Request from application B  | Youngest Oldest Row Buffer |\n| B3        | Request from application C  |                            |\n\nAssume also the following:\n\n- The memory system has two DRAM channels, one DRAM bank per channel, and four rows per bank.\n- All the row-buffers are closed (i.e., empty) at time 0.\n- All applications start to stall at time 0 because of memory.\n- No additional requests from any of the applications arrive at the memory controller.\n- An application (A, B, or C) is considered to be stalled until all of its memory requests (across all the request buffers) have been served.\n\n# 4.2 Problem Specification\n\nThe below table shows the stall time of applications A, B, and C with the FCFS (First-Come, First-Served) and FR-FCFS (First-Ready, First-Come, First-Served) scheduling policies.\n\n| Scheduling | Application A | Application B | Application C |\n| ---------- | ------------- | ------------- | ------------- |\n| FCFS       | 195 ns        | 285 ns        | 135 ns        |\n| FR-FCFS    | 135 ns        | 225 ns        | 90 ns         |\n\nThe diagrams below show the scheduling order of requests for Channel 0 and Channel 1 with the FCFS and FR-FCFS scheduling policies.\n\n| FCFS                    | Channel 0 | FCFS                    | Channel 1 |\n| ----------------------- | --------- | ----------------------- | --------- |\n| B4 B3 B2 A3 C1 B1 A2 A1 |           | B3 B2 A3 A2 A1 B1 C2 C1 |           |\n\nRequest from application A\n\nRequest from application B\n\nRequest from application C\n\nMidterm Exam\n\nPage 9 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 77.4,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "4 Memory Scheduling [40 points]",
                    "md": "# 4 Memory Scheduling [40 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 218.77,
                        "h": 551.01
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "4.1 Basics and Assumptions",
                    "md": "# 4.1 Basics and Assumptions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 172.49,
                        "h": 38.2
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "To serve a memory request, the memory controller issues one or multiple DRAM commands to access data from a bank. There are four different DRAM commands as discussed in class.\n\n- ACTIVATE: Loads the row (that needs to be accessed) into the bank\u2019s row-buffer. This is called opening a row. (Latency: 15ns)\n- PRECHARGE: Prepares the bank for the next access by closing the row in the bank (and making the row buffer empty). (Latency: 15ns)\n- READ/WRITE: Accesses data from the row-buffer. (Latency: 15ns)\n\nThe diagrams below show the snapshots of memory controller\u2019s request queues at time 0, i.e., t0, when applications A, B, and C are executed together on a multi-core processor. Each application runs on a separate core but shares the memory subsystem with other applications. Each request is color-coded to denote the application to which it belongs. Additionally, each request is annotated with a number that shows the order of the request among the set of enqueued requests of the application to which it belongs.\n\nFor example, A3 means that this is the third request from application A enqueued in the request queue. Assume all memory requests are reads and a read request is considered to be served when the READ command is complete (i.e., 15 ns after the request\u2019s READ command is issued).",
                    "md": "To serve a memory request, the memory controller issues one or multiple DRAM commands to access data from a bank. There are four different DRAM commands as discussed in class.\n\n- ACTIVATE: Loads the row (that needs to be accessed) into the bank\u2019s row-buffer. This is called opening a row. (Latency: 15ns)\n- PRECHARGE: Prepares the bank for the next access by closing the row in the bank (and making the row buffer empty). (Latency: 15ns)\n- READ/WRITE: Accesses data from the row-buffer. (Latency: 15ns)\n\nThe diagrams below show the snapshots of memory controller\u2019s request queues at time 0, i.e., t0, when applications A, B, and C are executed together on a multi-core processor. Each application runs on a separate core but shares the memory subsystem with other applications. Each request is color-coded to denote the application to which it belongs. Additionally, each request is annotated with a number that shows the order of the request among the set of enqueued requests of the application to which it belongs.\n\nFor example, A3 means that this is the third request from application A enqueued in the request queue. Assume all memory requests are reads and a read request is considered to be served when the READ command is complete (i.e., 15 ns after the request\u2019s READ command is issued).",
                    "rows": null,
                    "bBox": {
                        "x": -7.72,
                        "y": 114.2,
                        "w": 531.32,
                        "h": 713.97
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Channel 0 | Request Queue for Channel 0 | Bank 0                     |\n| --------- | --------------------------- | -------------------------- |\n| C1        | Request from application A  | B4 B3 B2 A3 C1 B1 A2 A1    |\n| B1        | Request from application B  | Youngest Oldest Row Buffer |\n| B3        | Request from application C  |                            |",
                    "rows": [
                        [
                            "Channel 0",
                            "Request Queue for Channel 0",
                            "Bank 0"
                        ],
                        [
                            "C1",
                            "Request from application A",
                            "B4 B3 B2 A3 C1 B1 A2 A1"
                        ],
                        [
                            "B1",
                            "Request from application B",
                            "Youngest Oldest Row Buffer"
                        ],
                        [
                            "B3",
                            "Request from application C",
                            ""
                        ]
                    ],
                    "bBox": {
                        "x": -7.72,
                        "y": 43.11,
                        "w": 531.49,
                        "h": 785.06
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Assume also the following:\n\n- The memory system has two DRAM channels, one DRAM bank per channel, and four rows per bank.\n- All the row-buffers are closed (i.e., empty) at time 0.\n- All applications start to stall at time 0 because of memory.\n- No additional requests from any of the applications arrive at the memory controller.\n- An application (A, B, or C) is considered to be stalled until all of its memory requests (across all the request buffers) have been served.",
                    "md": "Assume also the following:\n\n- The memory system has two DRAM channels, one DRAM bank per channel, and four rows per bank.\n- All the row-buffers are closed (i.e., empty) at time 0.\n- All applications start to stall at time 0 because of memory.\n- No additional requests from any of the applications arrive at the memory controller.\n- An application (A, B, or C) is considered to be stalled until all of its memory requests (across all the request buffers) have been served.",
                    "rows": null,
                    "bBox": {
                        "x": -7.72,
                        "y": 229.01,
                        "w": 531.49,
                        "h": 309.93
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "4.2 Problem Specification",
                    "md": "# 4.2 Problem Specification",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 159.06,
                        "h": 499.17
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "The below table shows the stall time of applications A, B, and C with the FCFS (First-Come, First-Served) and FR-FCFS (First-Ready, First-Come, First-Served) scheduling policies.",
                    "md": "The below table shows the stall time of applications A, B, and C with the FCFS (First-Come, First-Served) and FR-FCFS (First-Ready, First-Come, First-Served) scheduling policies.",
                    "rows": null,
                    "bBox": {
                        "x": -7.72,
                        "y": 229.01,
                        "w": 530.71,
                        "h": 587.37
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Scheduling | Application A | Application B | Application C |\n| ---------- | ------------- | ------------- | ------------- |\n| FCFS       | 195 ns        | 285 ns        | 135 ns        |\n| FR-FCFS    | 135 ns        | 225 ns        | 90 ns         |",
                    "rows": [
                        [
                            "Scheduling",
                            "Application A",
                            "Application B",
                            "Application C"
                        ],
                        [
                            "FCFS",
                            "195 ns",
                            "285 ns",
                            "135 ns"
                        ],
                        [
                            "FR-FCFS",
                            "135 ns",
                            "225 ns",
                            "90 ns"
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.44,
                        "h": 748.77
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "The diagrams below show the scheduling order of requests for Channel 0 and Channel 1 with the FCFS and FR-FCFS scheduling policies.",
                    "md": "The diagrams below show the scheduling order of requests for Channel 0 and Channel 1 with the FCFS and FR-FCFS scheduling policies.",
                    "rows": null,
                    "bBox": {
                        "x": -7.72,
                        "y": 229.01,
                        "w": 531.16,
                        "h": 587.37
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| FCFS                    | Channel 0 | FCFS                    | Channel 1 |\n| ----------------------- | --------- | ----------------------- | --------- |\n| B4 B3 B2 A3 C1 B1 A2 A1 |           | B3 B2 A3 A2 A1 B1 C2 C1 |           |",
                    "rows": [
                        [
                            "FCFS",
                            "Channel 0",
                            "FCFS",
                            "Channel 1"
                        ],
                        [
                            "B4 B3 B2 A3 C1 B1 A2 A1",
                            "",
                            "B3 B2 A3 A2 A1 B1 C2 C1",
                            ""
                        ]
                    ],
                    "bBox": {
                        "x": -7.72,
                        "y": 43.11,
                        "w": 531.49,
                        "h": 785.06
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Request from application A\n\nRequest from application B\n\nRequest from application C\n\nMidterm Exam\n\nPage 9 of 20",
                    "md": "Request from application A\n\nRequest from application B\n\nRequest from application C\n\nMidterm Exam\n\nPage 9 of 20",
                    "rows": null,
                    "bBox": {
                        "x": -7.72,
                        "y": 273.32,
                        "w": 531.04,
                        "h": 521.35
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 11,
            "text": "Initials: Solutions                          Computer Architecture                         December 7th, 2017\n    What are the numbers of row hits and row misses for each DRAM bank with either of the scheduling\npolicies? Show your work.\nChannel 0, hits:       FCFS: 3, FR-FCFS: 5\nChannel 0, misses:        FCFS: 5, FR-FCFS: 3\nChannel 1, hits:       FCFS: 2, FR-FCFS: 4\nChannel 1, misses:        FCFS: 6, FR-FCFS: 4\nExtra space for explanation (use only if needed):\n      To calculate the number of hits and misses we should consider the following facts:\n         \u2022 The first request of each channel will be always a row-buffer miss and it requires one\n            ACTIVATE and one READ command which lead to a 30 ns delay.\n         \u2022  For all requests in each channel, except for the first one, a row-buffer miss requires one\n            PRECHARGE, one ACTIVATE, and one READ command which lead to a 45 ns delay.\n         \u2022 A row-buffer hit requires one READ command which leads to a 15 ns delay.\n         \u2022 The stall time of each application is equal to the maximum service time of its requests\n            in both Channel 0 and Channel 1.\n         \u2022 When using the FR-FCFS policy, the requests will be reordered to exploit row buffer\n            locality. For example, the B1 request in Channel 0 is reordered in FR-FCFS with respect\n            to FCFS and executed after C1, A3, B2, and B4 requests. This means that A2, C1, A3,\n            B2, and B4 are all accessing the same row.\n                         FCFS\n                        FCFS       B4    B3    B2  A3   C1    B1   A2  A1\n                           Row id: B4   B3   B2    A3   C1  B1     A2  A1\n                           Row id:  00   2     0   0    0     1   0    0\n                          Hit/miss: m    2    0    0    0    1     0  0\n                         Hit/miss: m     m     h   h    m    m    h  m  t\n                                   +45   m    h    h    m     m    h   m t     Channel 0\n                           Time (ns)    +45   +15  +15  +45  +45  +15 +30 0    Channel 0\n                          Time (ns)+45  +45  +15  +15  +45  +45   +15 +30 0\n                                                                                 Bank 0\n                         FR-FCFS   B3    B1    B4  B2   A3    C1   A2  A1        Bank 0\n                        FR-FCFS    B3   B1   B4    B2  A3   C1     A2  A1\n                           Row id:  2    1     0   0    0     0   0    0       Row Buffer\n                           Row id:  2    1    0    0    0    0     0  0\n                          Hit/miss: m    m     h   h    h     h   h  m  t      Row Buffer\n                         Hit/miss: m     m    h    h    h    h     h   m t\n                           Time (ns)+45  +45  +15  +15  +15  +15  +15  +30 0\n                          Time (ns)+45  +45  +15  +15  +15  +15   +15 +30 0\n                          FCFS\n                         FCFS       B3   B2   A3   A2   A1    B1  C2   C1\n                            Row id:  B3  B2   A3   A2   A1   B1   C2   C1\n                           Row id:  33   2    0    1    0     0   0    1\n                           Hit/miss: m   2    0    1    0    0    0    1\n                          Hit/miss: m    m    m    m    h     h   m   m  t\n                                    +45  m    m    m    h    h    m    m\n                            Time (ns)    +45  +45  +45  +15  +15  +45  +30 t0  Channel 1\n                           Time (ns)+45  +45  +45  +45  +15  +15  +45 +30 0    Channel 1\n                          FR-FCFS                                              Bank 0\n                         FR-FCFS    B3   B2   A3   A1   B1    C2  A2   C1      Bank 0\n                            Row id:  3   2    0    0    0     0   1    1\n                           Row id:  B3   B2   A3   A1   B1   C2   A2   C1\n                           Hit/miss: 3   2    0    0    0    0    1    1       Row Buffer\n                          Hit/miss: m    m    h    h    h    m    h   m  t     Row Buffer\n                                   m     m    h    h    h     m   h    m\n                           Time (ns)+45  +45  +15  +15  +15  +45  +15  +30 t0\n                           Time (ns)+45  +45  +15  +15  +15  +45  +15 +30 0\nMidterm Exam                                                                                      Page 10 of 20",
            "md": "# Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\nWhat are the numbers of row hits and row misses for each DRAM bank with either of the scheduling policies? Show your work.\n\n| Channel 0, hits:   | FCFS: 3 | FR-FCFS: 5 |\n| ------------------ | ------- | ---------- |\n| Channel 0, misses: | FCFS: 5 | FR-FCFS: 3 |\n| Channel 1, hits:   | FCFS: 2 | FR-FCFS: 4 |\n| Channel 1, misses: | FCFS: 6 | FR-FCFS: 4 |\n\nExtra space for explanation (use only if needed):\n\nTo calculate the number of hits and misses we should consider the following facts:\n\n- The first request of each channel will be always a row-buffer miss and it requires one ACTIVATE and one READ command which lead to a 30 ns delay.\n- For all requests in each channel, except for the first one, a row-buffer miss requires one PRECHARGE, one ACTIVATE, and one READ command which lead to a 45 ns delay.\n- A row-buffer hit requires one READ command which leads to a 15 ns delay.\n- The stall time of each application is equal to the maximum service time of its requests in both Channel 0 and Channel 1.\n- When using the FR-FCFS policy, the requests will be reordered to exploit row buffer locality. For example, the B1 request in Channel 0 is reordered in FR-FCFS with respect to FCFS and executed after C1, A3, B2, and B4 requests. This means that A2, C1, A3, B2, and B4 are all accessing the same row.\n\n# FCFS\n\n| FCFS      | B4  | B3  | B2  | A3  | C1  | B1  | A2  | A1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | B4  | B3  | B2  | A3  | C1  | B1  | A2  | A1  |\n| Row id:   | 00  | 2   | 0   | 0   | 0   | 1   | 0   | 0   |\n| Hit/miss: | m   | 2   | 0   | 0   | 0   | 1   | 0   | 0   |\n| Hit/miss: | m   | m   | h   | h   | m   | m   | h   | m   |\n| Time (ns) | +45 | m   | h   | h   | m   | m   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +45 | +45 | +15 | +30 |\n\n# Channel 0\n\n# Time (ns)\n\n| +45 | +45 | +15 | +15 | +45 | +45 | +15 | +30 |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n\n# Bank 0\n\n# FR-FCFS\n\n| FR-FCFS   | B3  | B1  | B4  | B2  | A3  | C1  | A2  | A1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | 2   | 1   | 0   | 0   | 0   | 0   | 0   | 0   |\n| Hit/miss: | m   | m   | h   | h   | h   | h   | h   | m   |\n| Hit/miss: | m   | m   | h   | h   | h   | h   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +15 | +15 | +30 |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +15 | +15 | +30 |\n\n# FCFS\n\n| FCFS      | B3  | B2  | A3  | A2  | A1  | B1  | C2  | C1 |\n| --------- | --- | --- | --- | --- | --- | --- | --- | -- |\n| Row id:   | B3  | B2  | A3  | A2  | A1  | B1  | C2  | C1 |\n| Row id:   | 33  | 2   | 0   | 1   | 0   | 0   | 0   | 1  |\n| Hit/miss: | m   | 2   | 0   | 1   | 0   | 0   | 0   | 1  |\n| Hit/miss: | m   | m   | m   | m   | h   | h   | m   | m  |\n| Time (ns) | +45 | m   | m   | m   | h   | h   | m   | m  |\n| Time (ns) | +45 | +45 | +45 | +15 | +15 | +45 | +30 |    |\n\n# Channel 1\n\n# Time (ns)\n\n| +45 | +45 | +45 | +45 | +15 | +15 | +45 | +30 |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n\n# FR-FCFS\n\n| FR-FCFS   | B3  | B2  | A3  | A1  | B1  | C2  | A2  | C1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | 3   | 2   | 0   | 0   | 0   | 0   | 1   | 1   |\n| Hit/miss: | 3   | 2   | 0   | 0   | 0   | 0   | 1   | 1   |\n| Hit/miss: | m   | m   | h   | h   | h   | m   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +45 | +15 | +30 |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +45 | +15 | +30 |\n",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Solutions",
                    "md": "# Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 359.89,
                        "y": 495.14,
                        "w": 7.69,
                        "h": 172.39
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 210.81,
                        "y": 43.11,
                        "w": 156.78,
                        "h": 624.42
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 210.81,
                        "y": 43.11,
                        "w": 312.55,
                        "h": 632.9
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "What are the numbers of row hits and row misses for each DRAM bank with either of the scheduling policies? Show your work.",
                    "md": "What are the numbers of row hits and row misses for each DRAM bank with either of the scheduling policies? Show your work.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 72.0,
                        "w": 451.12,
                        "h": 595.53
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Channel 0, hits:   | FCFS: 3 | FR-FCFS: 5 |\n| ------------------ | ------- | ---------- |\n| Channel 0, misses: | FCFS: 5 | FR-FCFS: 3 |\n| Channel 1, hits:   | FCFS: 2 | FR-FCFS: 4 |\n| Channel 1, misses: | FCFS: 6 | FR-FCFS: 4 |",
                    "rows": [
                        [
                            "Channel 0, hits:",
                            "FCFS: 3",
                            "FR-FCFS: 5"
                        ],
                        [
                            "Channel 0, misses:",
                            "FCFS: 5",
                            "FR-FCFS: 3"
                        ],
                        [
                            "Channel 1, hits:",
                            "FCFS: 2",
                            "FR-FCFS: 4"
                        ],
                        [
                            "Channel 1, misses:",
                            "FCFS: 6",
                            "FR-FCFS: 4"
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 112.72,
                        "w": 199.97,
                        "h": 96.4
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Extra space for explanation (use only if needed):\n\nTo calculate the number of hits and misses we should consider the following facts:\n\n- The first request of each channel will be always a row-buffer miss and it requires one ACTIVATE and one READ command which lead to a 30 ns delay.\n- For all requests in each channel, except for the first one, a row-buffer miss requires one PRECHARGE, one ACTIVATE, and one READ command which lead to a 45 ns delay.\n- A row-buffer hit requires one READ command which leads to a 15 ns delay.\n- The stall time of each application is equal to the maximum service time of its requests in both Channel 0 and Channel 1.\n- When using the FR-FCFS policy, the requests will be reordered to exploit row buffer locality. For example, the B1 request in Channel 0 is reordered in FR-FCFS with respect to FCFS and executed after C1, A3, B2, and B4 requests. This means that A2, C1, A3, B2, and B4 are all accessing the same row.",
                    "md": "Extra space for explanation (use only if needed):\n\nTo calculate the number of hits and misses we should consider the following facts:\n\n- The first request of each channel will be always a row-buffer miss and it requires one ACTIVATE and one READ command which lead to a 30 ns delay.\n- For all requests in each channel, except for the first one, a row-buffer miss requires one PRECHARGE, one ACTIVATE, and one READ command which lead to a 45 ns delay.\n- A row-buffer hit requires one READ command which leads to a 15 ns delay.\n- The stall time of each application is equal to the maximum service time of its requests in both Channel 0 and Channel 1.\n- When using the FR-FCFS policy, the requests will be reordered to exploit row buffer locality. For example, the B1 request in Channel 0 is reordered in FR-FCFS with respect to FCFS and executed after C1, A3, B2, and B4 requests. This means that A2, C1, A3, B2, and B4 are all accessing the same row.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 234.98,
                        "w": 428.92,
                        "h": 441.03
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "FCFS",
                    "md": "# FCFS",
                    "rows": null,
                    "bBox": {
                        "x": 168.37,
                        "y": 465.25,
                        "w": 25.54,
                        "h": 127.11
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| FCFS      | B4  | B3  | B2  | A3  | C1  | B1  | A2  | A1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | B4  | B3  | B2  | A3  | C1  | B1  | A2  | A1  |\n| Row id:   | 00  | 2   | 0   | 0   | 0   | 1   | 0   | 0   |\n| Hit/miss: | m   | 2   | 0   | 0   | 0   | 1   | 0   | 0   |\n| Hit/miss: | m   | m   | h   | h   | m   | m   | h   | m   |\n| Time (ns) | +45 | m   | h   | h   | m   | m   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +45 | +45 | +15 | +30 |",
                    "rows": [
                        [
                            "FCFS",
                            "B4",
                            "B3",
                            "B2",
                            "A3",
                            "C1",
                            "B1",
                            "A2",
                            "A1"
                        ],
                        [
                            "Row id:",
                            "B4",
                            "B3",
                            "B2",
                            "A3",
                            "C1",
                            "B1",
                            "A2",
                            "A1"
                        ],
                        [
                            "Row id:",
                            "00",
                            "2",
                            "0",
                            "0",
                            "0",
                            "1",
                            "0",
                            "0"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "2",
                            "0",
                            "0",
                            "0",
                            "1",
                            "0",
                            "0"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "m",
                            "h",
                            "h",
                            "m",
                            "m",
                            "h",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "m",
                            "h",
                            "h",
                            "m",
                            "m",
                            "h",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+45",
                            "+45",
                            "+15",
                            "+30"
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 751.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Channel 0",
                    "md": "# Channel 0",
                    "rows": null,
                    "bBox": {
                        "x": 250.71,
                        "y": 483.38,
                        "w": 172.77,
                        "h": 192.63
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Time (ns)",
                    "md": "# Time (ns)",
                    "rows": null,
                    "bBox": {
                        "x": 180.63,
                        "y": 491.55,
                        "w": 186.96,
                        "h": 175.99
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| +45 | +45 | +15 | +15 | +45 | +45 | +15 | +30 |\n| --- | --- | --- | --- | --- | --- | --- | --- |",
                    "rows": [
                        [
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+45",
                            "+45",
                            "+15",
                            "+30"
                        ]
                    ],
                    "bBox": {
                        "x": 177.35,
                        "y": 501.07,
                        "w": 194.62,
                        "h": 175.77
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Bank 0",
                    "md": "# Bank 0",
                    "rows": null,
                    "bBox": {
                        "x": 250.78,
                        "y": 483.38,
                        "w": 166.05,
                        "h": 192.63
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "FR-FCFS",
                    "md": "# FR-FCFS",
                    "rows": null,
                    "bBox": {
                        "x": 168.37,
                        "y": 465.25,
                        "w": 39.35,
                        "h": 177.01
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| FR-FCFS   | B3  | B1  | B4  | B2  | A3  | C1  | A2  | A1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | 2   | 1   | 0   | 0   | 0   | 0   | 0   | 0   |\n| Hit/miss: | m   | m   | h   | h   | h   | h   | h   | m   |\n| Hit/miss: | m   | m   | h   | h   | h   | h   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +15 | +15 | +30 |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +15 | +15 | +30 |",
                    "rows": [
                        [
                            "FR-FCFS",
                            "B3",
                            "B1",
                            "B4",
                            "B2",
                            "A3",
                            "C1",
                            "A2",
                            "A1"
                        ],
                        [
                            "Row id:",
                            "2",
                            "1",
                            "0",
                            "0",
                            "0",
                            "0",
                            "0",
                            "0"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "m",
                            "h",
                            "h",
                            "h",
                            "h",
                            "h",
                            "m"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "m",
                            "h",
                            "h",
                            "h",
                            "h",
                            "h",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+15",
                            "+15",
                            "+15",
                            "+30"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+15",
                            "+15",
                            "+15",
                            "+30"
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 751.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "FCFS",
                    "md": "# FCFS",
                    "rows": null,
                    "bBox": {
                        "x": 168.37,
                        "y": 465.25,
                        "w": 25.54,
                        "h": 127.11
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| FCFS      | B3  | B2  | A3  | A2  | A1  | B1  | C2  | C1 |\n| --------- | --- | --- | --- | --- | --- | --- | --- | -- |\n| Row id:   | B3  | B2  | A3  | A2  | A1  | B1  | C2  | C1 |\n| Row id:   | 33  | 2   | 0   | 1   | 0   | 0   | 0   | 1  |\n| Hit/miss: | m   | 2   | 0   | 1   | 0   | 0   | 0   | 1  |\n| Hit/miss: | m   | m   | m   | m   | h   | h   | m   | m  |\n| Time (ns) | +45 | m   | m   | m   | h   | h   | m   | m  |\n| Time (ns) | +45 | +45 | +45 | +15 | +15 | +45 | +30 |    |",
                    "rows": [
                        [
                            "FCFS",
                            "B3",
                            "B2",
                            "A3",
                            "A2",
                            "A1",
                            "B1",
                            "C2",
                            "C1"
                        ],
                        [
                            "Row id:",
                            "B3",
                            "B2",
                            "A3",
                            "A2",
                            "A1",
                            "B1",
                            "C2",
                            "C1"
                        ],
                        [
                            "Row id:",
                            "33",
                            "2",
                            "0",
                            "1",
                            "0",
                            "0",
                            "0",
                            "1"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "2",
                            "0",
                            "1",
                            "0",
                            "0",
                            "0",
                            "1"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "m",
                            "m",
                            "m",
                            "h",
                            "h",
                            "m",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "m",
                            "m",
                            "m",
                            "h",
                            "h",
                            "m",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+45",
                            "+30",
                            ""
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 751.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Channel 1",
                    "md": "# Channel 1",
                    "rows": null,
                    "bBox": {
                        "x": 231.04,
                        "y": 483.38,
                        "w": 192.43,
                        "h": 182.52
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Time (ns)",
                    "md": "# Time (ns)",
                    "rows": null,
                    "bBox": {
                        "x": 180.63,
                        "y": 491.55,
                        "w": 186.96,
                        "h": 175.99
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| +45 | +45 | +45 | +45 | +15 | +15 | +45 | +30 |\n| --- | --- | --- | --- | --- | --- | --- | --- |",
                    "rows": [
                        [
                            "+45",
                            "+45",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+45",
                            "+30"
                        ]
                    ],
                    "bBox": {
                        "x": 177.35,
                        "y": 501.07,
                        "w": 194.62,
                        "h": 175.77
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "FR-FCFS",
                    "md": "# FR-FCFS",
                    "rows": null,
                    "bBox": {
                        "x": 168.37,
                        "y": 465.25,
                        "w": 39.35,
                        "h": 177.01
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| FR-FCFS   | B3  | B2  | A3  | A1  | B1  | C2  | A2  | C1  |\n| --------- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Row id:   | 3   | 2   | 0   | 0   | 0   | 0   | 1   | 1   |\n| Hit/miss: | 3   | 2   | 0   | 0   | 0   | 0   | 1   | 1   |\n| Hit/miss: | m   | m   | h   | h   | h   | m   | h   | m   |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +45 | +15 | +30 |\n| Time (ns) | +45 | +45 | +15 | +15 | +15 | +45 | +15 | +30 |",
                    "rows": [
                        [
                            "FR-FCFS",
                            "B3",
                            "B2",
                            "A3",
                            "A1",
                            "B1",
                            "C2",
                            "A2",
                            "C1"
                        ],
                        [
                            "Row id:",
                            "3",
                            "2",
                            "0",
                            "0",
                            "0",
                            "0",
                            "1",
                            "1"
                        ],
                        [
                            "Hit/miss:",
                            "3",
                            "2",
                            "0",
                            "0",
                            "0",
                            "0",
                            "1",
                            "1"
                        ],
                        [
                            "Hit/miss:",
                            "m",
                            "m",
                            "h",
                            "h",
                            "h",
                            "m",
                            "h",
                            "m"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+15",
                            "+45",
                            "+15",
                            "+30"
                        ],
                        [
                            "Time (ns)",
                            "+45",
                            "+45",
                            "+15",
                            "+15",
                            "+15",
                            "+45",
                            "+15",
                            "+30"
                        ]
                    ],
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 751.56
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 12,
            "text": "Initials: Solutions                   Computer Architecture                    December 7th, 2017\n5     Branch Prediction           [70 points]\nA processor implements an in-order  pipeline with 12 stages. Each stage completes in a single cycle.\nThe pipeline stalls on a conditional branch instruction until the condition of the branch is evaluated.\nHowever, you do not know at which stage the branch condition is evaluated. Please answer the following\nquestions.\n(a) [15 points] A program with 1000 dynamic instructions completes in 2211 cycles. If 200 of those\n    instructions are conditional branches, at the end of which pipeline stage the branch instructions are\n    resolved? (Assume that the pipeline does not stall for any other reason than the conditional branches\n    (e.g., data dependencies) during the execution of that program.)\n         At the end of the 7th stage.\n         Explanation:  T otal cycles = 12 + 1000 + 200 \u2217 X \u2212 1\n         2211 = 1011 + 200 \u2217 X\n         1400 = 200 \u2217 X\n         X = 6\n         Each branch causes 6 idle cycles (bubbles), thus branches are resolved at the end of 7th\n         stage.\n(b) In a new, higher-performance version of the processor, the architects implement a mysterious branch\n    prediction mechanism to improve the performance of the processor. They keep the rest of the design\n    exactly the same as before. The new design with the mysterious branch predictor completes the\n    execution of the following code in 115 cycles.\n                         MOV R1, #0 // R1 = 0\n                         LOOP_1:\n                              BEQ R1, #5, LAST // Branch to LAST if R1 == 5\n                              ADD R1, R1, #1       // R1 = R1 + 1\n                              MOV R2, #0           // R2 = 0\n                         LOOP_2:\n                              BEQ R2, #3, LOOP_1 // Branch to LOOP_1 if R2==3.\n                              ADD R2, R2, #1          // R2 = R2 + 1\n                              B LOOP_2                // Unconditional branch to LOOP_2\n                         LAST:\n                              MOV R1, #1              // R1 = 0\n    Assume that the pipeline never stalls due to a data dependency. Based on the given information,\n    determine which of the following branch prediction mechanisms could be the mysterious  branch\n    predictor implemented in the new version of the processor. For each branch prediction mechanism\n    below, you should circle the configuration parameters that makes it match the performance of the\n    mysterious branch predictor.\nMidterm Exam                                                                         Page 11 of 20",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 5 Branch Prediction [70 points]\n\nA processor implements an in-order pipeline with 12 stages. Each stage completes in a single cycle. The pipeline stalls on a conditional branch instruction until the condition of the branch is evaluated. However, you do not know at which stage the branch condition is evaluated. Please answer the following questions.\n\n# (a) [15 points]\n\nA program with 1000 dynamic instructions completes in 2211 cycles. If 200 of those instructions are conditional branches, at the end of which pipeline stage the branch instructions are resolved? (Assume that the pipeline does not stall for any other reason than the conditional branches (e.g., data dependencies) during the execution of that program.)\n\nAt the end of the 7th stage.\n\nExplanation: Total cycles = 12 + 1000 + 200 \u2217 X \u2212 1\n\n2211 = 1011 + 200 \u2217 X\n\n1400 = 200 \u2217 X\n\nX = 6\n\nEach branch causes 6 idle cycles (bubbles), thus branches are resolved at the end of 7th stage.\n\n# (b)\n\nIn a new, higher-performance version of the processor, the architects implement a mysterious branch prediction mechanism to improve the performance of the processor. They keep the rest of the design exactly the same as before. The new design with the mysterious branch predictor completes the execution of the following code in 115 cycles.\n\nMOV R1, #0 // R1 = 0\nLOOP_1:\nBEQ R1, #5, LAST // Branch to LAST if R1 == 5\nADD R1, R1, #1       // R1 = R1 + 1\nMOV R2, #0           // R2 = 0\nLOOP_2:\nBEQ R2, #3, LOOP_1 // Branch to LOOP_1 if R2==3.\nADD R2, R2, #1          // R2 = R2 + 1\nB LOOP_2                // Unconditional branch to LOOP_2\nLAST:\nMOV R1, #1              // R1 = 0\n\nAssume that the pipeline never stalls due to a data dependency. Based on the given information, determine which of the following branch prediction mechanisms could be the mysterious branch predictor implemented in the new version of the processor. For each branch prediction mechanism below, you should circle the configuration parameters that makes it match the performance of the mysterious branch predictor.",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 77.4,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "5 Branch Prediction [70 points]",
                    "md": "# 5 Branch Prediction [70 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.64,
                        "h": 532.66
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "A processor implements an in-order pipeline with 12 stages. Each stage completes in a single cycle. The pipeline stalls on a conditional branch instruction until the condition of the branch is evaluated. However, you do not know at which stage the branch condition is evaluated. Please answer the following questions.",
                    "md": "A processor implements an in-order pipeline with 12 stages. Each stage completes in a single cycle. The pipeline stalls on a conditional branch instruction until the condition of the branch is evaluated. However, you do not know at which stage the branch condition is evaluated. Please answer the following questions.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 93.82,
                        "w": 451.64,
                        "h": 506.46
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [15 points]",
                    "md": "# (a) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 8.0,
                        "h": 14.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "A program with 1000 dynamic instructions completes in 2211 cycles. If 200 of those instructions are conditional branches, at the end of which pipeline stage the branch instructions are resolved? (Assume that the pipeline does not stall for any other reason than the conditional branches (e.g., data dependencies) during the execution of that program.)\n\nAt the end of the 7th stage.\n\nExplanation: Total cycles = 12 + 1000 + 200 \u2217 X \u2212 1\n\n2211 = 1011 + 200 \u2217 X\n\n1400 = 200 \u2217 X\n\nX = 6\n\nEach branch causes 6 idle cycles (bubbles), thus branches are resolved at the end of 7th stage.",
                    "md": "A program with 1000 dynamic instructions completes in 2211 cycles. If 200 of those instructions are conditional branches, at the end of which pipeline stage the branch instructions are resolved? (Assume that the pipeline does not stall for any other reason than the conditional branches (e.g., data dependencies) during the execution of that program.)\n\nAt the end of the 7th stage.\n\nExplanation: Total cycles = 12 + 1000 + 200 \u2217 X \u2212 1\n\n2211 = 1011 + 200 \u2217 X\n\n1400 = 200 \u2217 X\n\nX = 6\n\nEach branch causes 6 idle cycles (bubbles), thus branches are resolved at the end of 7th stage.",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 151.6,
                        "w": 433.94,
                        "h": 448.67
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b)",
                    "md": "# (b)",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "In a new, higher-performance version of the processor, the architects implement a mysterious branch prediction mechanism to improve the performance of the processor. They keep the rest of the design exactly the same as before. The new design with the mysterious branch predictor completes the execution of the following code in 115 cycles.\n\nMOV R1, #0 // R1 = 0\nLOOP_1:\nBEQ R1, #5, LAST // Branch to LAST if R1 == 5\nADD R1, R1, #1       // R1 = R1 + 1\nMOV R2, #0           // R2 = 0\nLOOP_2:\nBEQ R2, #3, LOOP_1 // Branch to LOOP_1 if R2==3.\nADD R2, R2, #1          // R2 = R2 + 1\nB LOOP_2                // Unconditional branch to LOOP_2\nLAST:\nMOV R1, #1              // R1 = 0\n\nAssume that the pipeline never stalls due to a data dependency. Based on the given information, determine which of the following branch prediction mechanisms could be the mysterious branch predictor implemented in the new version of the processor. For each branch prediction mechanism below, you should circle the configuration parameters that makes it match the performance of the mysterious branch predictor.",
                    "md": "In a new, higher-performance version of the processor, the architects implement a mysterious branch prediction mechanism to improve the performance of the processor. They keep the rest of the design exactly the same as before. The new design with the mysterious branch predictor completes the execution of the following code in 115 cycles.\n\nMOV R1, #0 // R1 = 0\nLOOP_1:\nBEQ R1, #5, LAST // Branch to LAST if R1 == 5\nADD R1, R1, #1       // R1 = R1 + 1\nMOV R2, #0           // R2 = 0\nLOOP_2:\nBEQ R2, #3, LOOP_1 // Branch to LOOP_1 if R2==3.\nADD R2, R2, #1          // R2 = R2 + 1\nB LOOP_2                // Unconditional branch to LOOP_2\nLAST:\nMOV R1, #1              // R1 = 0\n\nAssume that the pipeline never stalls due to a data dependency. Based on the given information, determine which of the following branch prediction mechanisms could be the mysterious branch predictor implemented in the new version of the processor. For each branch prediction mechanism below, you should circle the configuration parameters that makes it match the performance of the mysterious branch predictor.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.64,
                        "h": 568.52
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 13,
            "text": "Initials: Solutions                    Computer Architecture                     December 7th, 2017\n      i) [15 points] Static Branch Predictor\n        Could this be the mysterious branch predictor?\n                       YES                             NO\n        If YES, for which configuration below is the answer YES? Pick an option for each configuration\n        parameter.\n          i. Static Prediction Direction\n                           Always taken                    Always not taken\n        Explain:\n             YES, if the static prediction direction is always not taken.\n             Explanation: Such a predictor makes 6 mispredictions, which is the number resulting\n             in 115 cycles execution time for the above program.\n     ii) [15 points] Last Time Branch Predictor\n        Could this be the mysterious branch predictor?\n                       YES                             NO\n        If YES, for which configuration is the answer YES? Pick an option for each configuration\n        parameter.\n          i. Initial Prediction Direction\n                           Taken                      Not taken\n         ii. Local for each branch instruction (PC-based) or global (shared among all branches) history?\n                           Local                      Global\n        Explain:\n             NO.\n             Explanation: There is not a configuration for this branch predictor that results in 6\n             mispredictions for the above program.\n    iii) [10 points] Backward taken, Forward not taken (BTFN)\n        Could this be the mysterious branch predictor?\n                        YES                             NO\n        Explain:\n             NO.\n             Explanation:    BTFN predictor does not make exactly 6 mispredictions for the\n             above program.\nMidterm Exam                                                                           Page 12 of 20",
            "md": "# Computer Architecture\n\nDate: December 7th, 2017\n\n# i) [15 points] Static Branch Predictor\n\nCould this be the mysterious branch predictor?\n\n| YES | NO |\n| --- | -- |\n\nIf YES, for which configuration below is the answer YES? Pick an option for each configuration parameter.\n\n# i. Static Prediction Direction\n\n| Always taken | Always not taken |\n| ------------ | ---------------- |\n\nExplain:\n\nYES, if the static prediction direction is always not taken.\n\nExplanation: Such a predictor makes 6 mispredictions, which is the number resulting in 115 cycles execution time for the above program.\n\n# ii) [15 points] Last Time Branch Predictor\n\nCould this be the mysterious branch predictor?\n\n| YES | NO |\n| --- | -- |\n\nIf YES, for which configuration is the answer YES? Pick an option for each configuration parameter.\n\n# i. Initial Prediction Direction\n\n| Taken | Not taken |\n| ----- | --------- |\n\n# ii. Local for each branch instruction (PC-based) or global (shared among all branches) history?\n\n| Local | Global |\n| ----- | ------ |\n\nExplain:\n\nNO.\n\nExplanation: There is not a configuration for this branch predictor that results in 6 mispredictions for the above program.\n\n# iii) [10 points] Backward taken, Forward not taken (BTFN)\n\nCould this be the mysterious branch predictor?\n\n| YES | NO |\n| --- | -- |\n\nExplain:\n\nNO.\n\nExplanation: BTFN predictor does not make exactly 6 mispredictions for the above program.\n\nMidterm Exam\n\nPage 12 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Date: December 7th, 2017",
                    "md": "Date: December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "i) [15 points] Static Branch Predictor",
                    "md": "# i) [15 points] Static Branch Predictor",
                    "rows": null,
                    "bBox": {
                        "x": 97.73,
                        "y": 72.0,
                        "w": 180.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Could this be the mysterious branch predictor?",
                    "md": "Could this be the mysterious branch predictor?",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 85.95,
                        "w": 206.35,
                        "h": 490.72
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| YES | NO |\n| --- | -- |",
                    "rows": [
                        [
                            "YES",
                            "NO"
                        ]
                    ],
                    "bBox": {
                        "x": 92.2,
                        "y": 101.89,
                        "w": 431.06,
                        "h": 550.08
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "If YES, for which configuration below is the answer YES? Pick an option for each configuration parameter.",
                    "md": "If YES, for which configuration below is the answer YES? Pick an option for each configuration parameter.",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 413.9,
                        "h": 490.72
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "i. Static Prediction Direction",
                    "md": "# i. Static Prediction Direction",
                    "rows": null,
                    "bBox": {
                        "x": 117.47,
                        "y": 146.72,
                        "w": 127.6,
                        "h": 10.0
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Always taken | Always not taken |\n| ------------ | ---------------- |",
                    "rows": [
                        [
                            "Always taken",
                            "Always not taken"
                        ]
                    ],
                    "bBox": {
                        "x": 130.05,
                        "y": 161.66,
                        "w": 302.9,
                        "h": 46.44
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Explain:\n\nYES, if the static prediction direction is always not taken.\n\nExplanation: Such a predictor makes 6 mispredictions, which is the number resulting in 115 cycles execution time for the above program.",
                    "md": "Explain:\n\nYES, if the static prediction direction is always not taken.\n\nExplanation: Such a predictor makes 6 mispredictions, which is the number resulting in 115 cycles execution time for the above program.",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 393.52,
                        "h": 562.04
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "ii) [15 points] Last Time Branch Predictor",
                    "md": "# ii) [15 points] Last Time Branch Predictor",
                    "rows": null,
                    "bBox": {
                        "x": 94.97,
                        "y": 286.96,
                        "w": 204.9,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Could this be the mysterious branch predictor?",
                    "md": "Could this be the mysterious branch predictor?",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 85.95,
                        "w": 206.35,
                        "h": 490.72
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| YES | NO |\n| --- | -- |",
                    "rows": [
                        [
                            "YES",
                            "NO"
                        ]
                    ],
                    "bBox": {
                        "x": 92.2,
                        "y": 101.89,
                        "w": 431.06,
                        "h": 550.08
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "If YES, for which configuration is the answer YES? Pick an option for each configuration parameter.",
                    "md": "If YES, for which configuration is the answer YES? Pick an option for each configuration parameter.",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 413.9,
                        "h": 490.72
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "i. Initial Prediction Direction",
                    "md": "# i. Initial Prediction Direction",
                    "rows": null,
                    "bBox": {
                        "x": 117.47,
                        "y": 361.68,
                        "w": 128.43,
                        "h": 10.0
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Taken | Not taken |\n| ----- | --------- |",
                    "rows": [
                        [
                            "Taken",
                            "Not taken"
                        ]
                    ],
                    "bBox": {
                        "x": 92.2,
                        "y": 161.66,
                        "w": 340.75,
                        "h": 401.06
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "ii. Local for each branch instruction (PC-based) or global (shared among all branches) history?",
                    "md": "# ii. Local for each branch instruction (PC-based) or global (shared among all branches) history?",
                    "rows": null,
                    "bBox": {
                        "x": 114.7,
                        "y": 401.53,
                        "w": 408.63,
                        "h": 23.95
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Local | Global |\n| ----- | ------ |",
                    "rows": [
                        [
                            "Local",
                            "Global"
                        ]
                    ],
                    "bBox": {
                        "x": 114.7,
                        "y": 401.53,
                        "w": 408.63,
                        "h": 23.95
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Explain:\n\nNO.\n\nExplanation: There is not a configuration for this branch predictor that results in 6 mispredictions for the above program.",
                    "md": "Explain:\n\nNO.\n\nExplanation: There is not a configuration for this branch predictor that results in 6 mispredictions for the above program.",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 393.24,
                        "h": 562.04
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "iii) [10 points] Backward taken, Forward not taken (BTFN)",
                    "md": "# iii) [10 points] Backward taken, Forward not taken (BTFN)",
                    "rows": null,
                    "bBox": {
                        "x": 92.2,
                        "y": 101.89,
                        "w": 290.89,
                        "h": 490.72
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Could this be the mysterious branch predictor?",
                    "md": "Could this be the mysterious branch predictor?",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 85.95,
                        "w": 206.35,
                        "h": 490.72
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| YES | NO |\n| --- | -- |",
                    "rows": [
                        [
                            "YES",
                            "NO"
                        ]
                    ],
                    "bBox": {
                        "x": 92.2,
                        "y": 101.89,
                        "w": 431.06,
                        "h": 550.08
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Explain:\n\nNO.\n\nExplanation: BTFN predictor does not make exactly 6 mispredictions for the above program.\n\nMidterm Exam\n\nPage 12 of 20",
                    "md": "Explain:\n\nNO.\n\nExplanation: BTFN predictor does not make exactly 6 mispredictions for the above program.\n\nMidterm Exam\n\nPage 12 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 101.89,
                        "w": 451.31,
                        "h": 692.78
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 14,
            "text": "Initials: Solutions                    Computer Architecture                     December 7th, 2017\n     iv) [15 points] Two-bit Counter Based Prediction (using saturating arithmetic)\n        Could this be the mysterious branch predictor?\n                       YES                             NO\n        If YES, for which configuration is the answer YES? Pick an option for each configuration\n        parameter.\n          i. Initial Prediction Direction\n               00 (Strongly not taken)                 01 (Weakly not taken)\n               10 (Weakly taken)                       11 (Strongly taken)\n         ii. Local for each branch instruction (i.e., PC-based, without any interference between different\n            branches) or global (i.e., a single counter shared among all branches) history?\n                           Local                      Global\n        Explain:\n             YES, if local history registers with 00 or 01 initial values are used.\n             Explanation: Such a configuration yields 6 mispredictions, which results in 115 cycles\n             execution time for the above program.\nMidterm Exam                                                                           Page 13 of 20",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# iv) [15 points] Two-bit Counter Based Prediction (using saturating arithmetic)\n\nCould this be the mysterious branch predictor?\n\n| YES | NO |\n| --- | -- |\n\nIf YES, for which configuration is the answer YES? Pick an option for each configuration parameter.\n\n# i. Initial Prediction Direction\n\n| 00 (Strongly not taken) | 01 (Weakly not taken) | 10 (Weakly taken) | 11 (Strongly taken) |\n| ----------------------- | --------------------- | ----------------- | ------------------- |\n\n# ii. Local for each branch instruction (i.e., PC-based, without any interference between different branches) or global (i.e., a single counter shared among all branches) history?\n\n| Local | Global |\n| ----- | ------ |\n\n# Explain:\n\nYES, if local history registers with 00 or 01 initial values are used.\n\nExplanation: Such a configuration yields 6 mispredictions, which results in 115 cycles execution time for the above program.\n\nMidterm Exam\n\nPage 13 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 77.4,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "iv) [15 points] Two-bit Counter Based Prediction (using saturating arithmetic)",
                    "md": "# iv) [15 points] Two-bit Counter Based Prediction (using saturating arithmetic)",
                    "rows": null,
                    "bBox": {
                        "x": 92.48,
                        "y": 72.0,
                        "w": 368.36,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Could this be the mysterious branch predictor?",
                    "md": "Could this be the mysterious branch predictor?",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 85.95,
                        "w": 206.35,
                        "h": 10.0
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| YES | NO |\n| --- | -- |",
                    "rows": [
                        [
                            "YES",
                            "NO"
                        ]
                    ],
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 413.9,
                        "h": 157.03
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "If YES, for which configuration is the answer YES? Pick an option for each configuration parameter.",
                    "md": "If YES, for which configuration is the answer YES? Pick an option for each configuration parameter.",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 101.89,
                        "w": 413.9,
                        "h": 37.9
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "i. Initial Prediction Direction",
                    "md": "# i. Initial Prediction Direction",
                    "rows": null,
                    "bBox": {
                        "x": 117.47,
                        "y": 146.72,
                        "w": 128.43,
                        "h": 10.0
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| 00 (Strongly not taken) | 01 (Weakly not taken) | 10 (Weakly taken) | 11 (Strongly taken) |\n| ----------------------- | --------------------- | ----------------- | ------------------- |",
                    "rows": [
                        [
                            "00 (Strongly not taken)",
                            "01 (Weakly not taken)",
                            "10 (Weakly taken)",
                            "11 (Strongly taken)"
                        ]
                    ],
                    "bBox": {
                        "x": 139.94,
                        "y": 160.67,
                        "w": 304.99,
                        "h": 21.96
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "ii. Local for each branch instruction (i.e., PC-based, without any interference between different branches) or global (i.e., a single counter shared among all branches) history?",
                    "md": "# ii. Local for each branch instruction (i.e., PC-based, without any interference between different branches) or global (i.e., a single counter shared among all branches) history?",
                    "rows": null,
                    "bBox": {
                        "x": 114.7,
                        "y": 186.57,
                        "w": 408.58,
                        "h": 35.9
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Local | Global |\n| ----- | ------ |",
                    "rows": [
                        [
                            "Local",
                            "Global"
                        ]
                    ],
                    "bBox": {
                        "x": 114.7,
                        "y": 186.57,
                        "w": 408.58,
                        "h": 72.35
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Explain:",
                    "md": "# Explain:",
                    "rows": null,
                    "bBox": {
                        "x": 109.35,
                        "y": 229.41,
                        "w": 36.0,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "YES, if local history registers with 00 or 01 initial values are used.\n\nExplanation: Such a configuration yields 6 mispredictions, which results in 115 cycles execution time for the above program.\n\nMidterm Exam\n\nPage 13 of 20",
                    "md": "YES, if local history registers with 00 or 01 initial values are used.\n\nExplanation: Such a configuration yields 6 mispredictions, which results in 115 cycles execution time for the above program.\n\nMidterm Exam\n\nPage 13 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 101.89,
                        "w": 451.31,
                        "h": 692.78
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 15,
            "text": "Initials: Solutions                     Computer Architecture                     December 7th, 2017\n6     SIMD      [90 points]\nWe have two SIMD engines: 1) a traditional vector processor and 2) a traditional array processor. Both\nprocessors can support a vector length up to 16.\n    All instructions can be fully pipelined, the processor can issue one vector instruction per cycle, and\nthe pipeline does not forward data (no chaining). For the sake of simplicity, we ignore the latency of the\npipeline stages other than the execution stages (e.g, decode stage latency: 0 cycles, write back latency:\n0 cycles, etc).\n    We implement the following instructions in both designs, with their corresponding execution latencies:\n  Operation   Description                    Name          Latency of a single operation (VLEN=1)\n  VADD        VDST \u2190 VSRC1 + VSRC2           vector add    5 cycles\n  VMUL        VDST \u2190 VSRC1 * VSRC2           vector mult.  15 cycles\n  VSHR        VDST \u2190 VSRC >> 1               vector shift  1 cycles\n  VLD         VDST \u2190 mem[SRC]                vector load   20 cycles\n  VST         VSRC \u2192 mem[DST]                vector store  20 cycles\n   \u2022  All the vector instructions operate with a vector length specified by VLEN. The VLD instruction\n      loads VLEN consecutive elements from the DST address specified by the value in the VDST register.\n      The VST instruction stores VLEN elements from the VSRC register in consecutive addresses in\n      memory, starting from the address specified in DST.\n   \u2022 Both processors have eight vector registers (VR0 to VR7) which can contain up to 16 elements,\n      and eight scalar registers (R0 to R7). The entire vector register needs to be ready (i.e., populated\n      with all VLEN elements) before any element of it can be used as part of another operation.\n   \u2022 The memory can sustain a throughput of one element per cycle. The memory consists of 16 banks\n      that can be accessed independently. A single memory access can be initiated in each cycle. The\n      memory can sustain 16 parallel accesses if they all go to different banks.\n(a) [10 points] Which processor (array or vector processor) is more costly in terms of chip area? Explain.\n         Array processor\n         Explanation:     An   array processor  requires 16  functional  units for  an  operation\n         whereas a vector processor requires only 1.\n(b) [25 points] The following code takes 52 cycles to execute on the vector processor:\n          VADD VR2 \u2190 VR1,  VR0\n          VADD VR3 \u2190 VR2,  VR5\n          VMUL VR6 \u2190 VR2,  VR3\n    What is the VLEN of the instructions? Explain your answer.\n         VLEN: 10\n         Explanation: 5+(VLEN-1)+5+(VLEN-1)+15+(VLEN-1) = 52 \u21d2 VLEN = 10\n    How long would the same code execute on an array processor with the same vector length?\n         25 cycles\n         Explanation:     there  are  data  dependencies  among   instructions \u21d2   5+5+15=     25\n         cycles\nMidterm Exam                                                                             Page 14 of 20",
            "md": "# Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 6 SIMD [90 points]\n\nWe have two SIMD engines: 1) a traditional vector processor and 2) a traditional array processor. Both processors can support a vector length up to 16.\n\nAll instructions can be fully pipelined, the processor can issue one vector instruction per cycle, and the pipeline does not forward data (no chaining). For the sake of simplicity, we ignore the latency of the pipeline stages other than the execution stages (e.g, decode stage latency: 0 cycles, write back latency: 0 cycles, etc).\n\nWe implement the following instructions in both designs, with their corresponding execution latencies:\n\n| Operation | Description           | Name         | Latency of a single operation (VLEN=1) |\n| --------- | --------------------- | ------------ | -------------------------------------- |\n| VADD      | VDST \u2190 VSRC1 + VSRC2  | vector add   | 5 cycles                               |\n| VMUL      | VDST \u2190 VSRC1 \\* VSRC2 | vector mult. | 15 cycles                              |\n| VSHR      | VDST \u2190 VSRC >> 1      | vector shift | 1 cycles                               |\n| VLD       | VDST \u2190 mem\\[SRC]      | vector load  | 20 cycles                              |\n| VST       | VSRC \u2192 mem\\[DST]      | vector store | 20 cycles                              |\n\nAll the vector instructions operate with a vector length specified by VLEN. The VLD instruction loads VLEN consecutive elements from the DST address specified by the value in the VDST register. The VST instruction stores VLEN elements from the VSRC register in consecutive addresses in memory, starting from the address specified in DST.\n\nBoth processors have eight vector registers (VR0 to VR7) which can contain up to 16 elements, and eight scalar registers (R0 to R7). The entire vector register needs to be ready (i.e., populated with all VLEN elements) before any element of it can be used as part of another operation.\n\nThe memory can sustain a throughput of one element per cycle. The memory consists of 16 banks that can be accessed independently. A single memory access can be initiated in each cycle. The memory can sustain 16 parallel accesses if they all go to different banks.\n\n# (a) [10 points] Which processor (array or vector processor) is more costly in terms of chip area? Explain.\n\nArray processor\n\nExplanation: An array processor requires 16 functional units for an operation whereas a vector processor requires only 1.\n\n# (b) [25 points] The following code takes 52 cycles to execute on the vector processor:\n\nVADD VR2 \u2190 VR1, VR0\n\nVADD VR3 \u2190 VR2, VR5\n\nVMUL VR6 \u2190 VR2, VR3\n\nWhat is the VLEN of the instructions? Explain your answer.\n\nVLEN: 10\n\nExplanation: 5+(VLEN-1)+5+(VLEN-1)+15+(VLEN-1) = 52 \u21d2 VLEN = 10\n\nHow long would the same code execute on an array processor with the same vector length?\n\n25 cycles\n\nExplanation: there are data dependencies among instructions \u21d2 5+5+15= 25 cycles\n\nMidterm Exam Page 14 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Solutions",
                    "md": "# Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "6 SIMD [90 points]",
                    "md": "# 6 SIMD [90 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 123.01,
                        "h": 14.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We have two SIMD engines: 1) a traditional vector processor and 2) a traditional array processor. Both processors can support a vector length up to 16.\n\nAll instructions can be fully pipelined, the processor can issue one vector instruction per cycle, and the pipeline does not forward data (no chaining). For the sake of simplicity, we ignore the latency of the pipeline stages other than the execution stages (e.g, decode stage latency: 0 cycles, write back latency: 0 cycles, etc).\n\nWe implement the following instructions in both designs, with their corresponding execution latencies:",
                    "md": "We have two SIMD engines: 1) a traditional vector processor and 2) a traditional array processor. Both processors can support a vector length up to 16.\n\nAll instructions can be fully pipelined, the processor can issue one vector instruction per cycle, and the pipeline does not forward data (no chaining). For the sake of simplicity, we ignore the latency of the pipeline stages other than the execution stages (e.g, decode stage latency: 0 cycles, write back latency: 0 cycles, etc).\n\nWe implement the following instructions in both designs, with their corresponding execution latencies:",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.44,
                        "h": 611.15
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Operation | Description           | Name         | Latency of a single operation (VLEN=1) |\n| --------- | --------------------- | ------------ | -------------------------------------- |\n| VADD      | VDST \u2190 VSRC1 + VSRC2  | vector add   | 5 cycles                               |\n| VMUL      | VDST \u2190 VSRC1 \\* VSRC2 | vector mult. | 15 cycles                              |\n| VSHR      | VDST \u2190 VSRC >> 1      | vector shift | 1 cycles                               |\n| VLD       | VDST \u2190 mem\\[SRC]      | vector load  | 20 cycles                              |\n| VST       | VSRC \u2192 mem\\[DST]      | vector store | 20 cycles                              |",
                    "rows": [
                        [
                            "Operation",
                            "Description",
                            "Name",
                            "Latency of a single operation (VLEN=1)"
                        ],
                        [
                            "VADD",
                            "VDST \u2190 VSRC1 + VSRC2",
                            "vector add",
                            "5 cycles"
                        ],
                        [
                            "VMUL",
                            "VDST \u2190 VSRC1 * VSRC2",
                            "vector mult.",
                            "15 cycles"
                        ],
                        [
                            "VSHR",
                            "VDST \u2190 VSRC >> 1",
                            "vector shift",
                            "1 cycles"
                        ],
                        [
                            "VLD",
                            "VDST \u2190 mem[SRC]",
                            "vector load",
                            "20 cycles"
                        ],
                        [
                            "VST",
                            "VSRC \u2192 mem[DST]",
                            "vector store",
                            "20 cycles"
                        ]
                    ],
                    "bBox": {
                        "x": 78.38,
                        "y": 177.25,
                        "w": 444.78,
                        "h": 465.65
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "All the vector instructions operate with a vector length specified by VLEN. The VLD instruction loads VLEN consecutive elements from the DST address specified by the value in the VDST register. The VST instruction stores VLEN elements from the VSRC register in consecutive addresses in memory, starting from the address specified in DST.\n\nBoth processors have eight vector registers (VR0 to VR7) which can contain up to 16 elements, and eight scalar registers (R0 to R7). The entire vector register needs to be ready (i.e., populated with all VLEN elements) before any element of it can be used as part of another operation.\n\nThe memory can sustain a throughput of one element per cycle. The memory consists of 16 banks that can be accessed independently. A single memory access can be initiated in each cycle. The memory can sustain 16 parallel accesses if they all go to different banks.",
                    "md": "All the vector instructions operate with a vector length specified by VLEN. The VLD instruction loads VLEN consecutive elements from the DST address specified by the value in the VDST register. The VST instruction stores VLEN elements from the VSRC register in consecutive addresses in memory, starting from the address specified in DST.\n\nBoth processors have eight vector registers (VR0 to VR7) which can contain up to 16 elements, and eight scalar registers (R0 to R7). The entire vector register needs to be ready (i.e., populated with all VLEN elements) before any element of it can be used as part of another operation.\n\nThe memory can sustain a throughput of one element per cycle. The memory consists of 16 banks that can be accessed independently. A single memory access can be initiated in each cycle. The memory can sustain 16 parallel accesses if they all go to different banks.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.3,
                        "h": 444.03
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [10 points] Which processor (array or vector processor) is more costly in terms of chip area? Explain.",
                    "md": "# (a) [10 points] Which processor (array or vector processor) is more costly in terms of chip area? Explain.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 408.67,
                        "w": 450.9,
                        "h": 258.14
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Array processor\n\nExplanation: An array processor requires 16 functional units for an operation whereas a vector processor requires only 1.",
                    "md": "Array processor\n\nExplanation: An array processor requires 16 functional units for an operation whereas a vector processor requires only 1.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 429.34,
                        "h": 599.19
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [25 points] The following code takes 52 cycles to execute on the vector processor:",
                    "md": "# (b) [25 points] The following code takes 52 cycles to execute on the vector processor:",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 449.65,
                        "w": 430.19,
                        "h": 229.11
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "VADD VR2 \u2190 VR1, VR0\n\nVADD VR3 \u2190 VR2, VR5\n\nVMUL VR6 \u2190 VR2, VR3\n\nWhat is the VLEN of the instructions? Explain your answer.\n\nVLEN: 10\n\nExplanation: 5+(VLEN-1)+5+(VLEN-1)+15+(VLEN-1) = 52 \u21d2 VLEN = 10\n\nHow long would the same code execute on an array processor with the same vector length?\n\n25 cycles\n\nExplanation: there are data dependencies among instructions \u21d2 5+5+15= 25 cycles\n\nMidterm Exam Page 14 of 20",
                    "md": "VADD VR2 \u2190 VR1, VR0\n\nVADD VR3 \u2190 VR2, VR5\n\nVMUL VR6 \u2190 VR2, VR3\n\nWhat is the VLEN of the instructions? Explain your answer.\n\nVLEN: 10\n\nExplanation: 5+(VLEN-1)+5+(VLEN-1)+15+(VLEN-1) = 52 \u21d2 VLEN = 10\n\nHow long would the same code execute on an array processor with the same vector length?\n\n25 cycles\n\nExplanation: there are data dependencies among instructions \u21d2 5+5+15= 25 cycles\n\nMidterm Exam Page 14 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.31,
                        "h": 727.05
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 16,
            "text": "Initials: Solutions                   Computer Architecture                    December 7th, 2017\n(c) [25 points] The following code takes 94 cycles to execute on the vector processor:\n   VLD    VR0 \u2190   mem[ R0 ]\n   VLD    VR1 \u2190   mem[ R1 ]\n   VADD VR2 \u2190 VR1,       VR0\n   VSHR VR2 \u2190 VR2\n    VST VR2 \u2192    mem[ R2 ]\n    Assume that the elements loaded in VR0 are all placed in different banks, and that the elements\n    loaded into VR1 are placed in the same banks as the elements in VR0. Similarly, the elements of\n    VR2 are stored in different banks in memory. What is the VLEN of the instructions? Explain your\n    answer.\n        VLEN: 8\n        Explanation:        20+20+(VLEN-1)+5+(VLEN-1)+1+(VLEN-1)+20+(VLEN-1)               =\n        94.\n        \u21d2 VLEN = 8\n(d) [30 points] We replace the memory with a new module whose characteristics are unknown.    The\n    following code (the same as that in (c)) takes 163 cycles to execute on the vector processor:\n   VLD    VR0 \u2190   mem[ R0 ]\n   VLD    VR1 \u2190   mem[ R1 ]\n   VADD VR2 \u2190 VR1,       VR0\n   VSHR VR2 \u2190 VR2\n    VST VR2 \u2192    mem[ R2 ]\n    The VLEN of the instructions is 16. The elements loaded in VR0 are placed in consecutive banks,\n    the elements loaded in VR1 are placed in consecutive banks, and the elements of VR2 are also stored\n    in consecutive banks. What is the number of banks of the new memory module? Explain.\n        [Correction] The number of cycles should be 170 instead of 163.           For grading\n        this question the instructor took into account only the student\u2019s reasoning.\n        Number of banks: 8\n        Explanation:    Assuming that the number of banks is power of two, 20*(16/banks)+\n        20*(16/banks)+ (banks-1)+ 5+ (VLEN-1)+ 1+ (VLEN-1)+ 20*(16/banks)+ (banks-1)\n        = 170 \u21d2 banks=8\nMidterm Exam                                                                         Page 15 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\n# (c) [25 points]\n\nThe following code takes 94 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nAssume that the elements loaded in VR0 are all placed in different banks, and that the elements loaded into VR1 are placed in the same banks as the elements in VR0. Similarly, the elements of VR2 are stored in different banks in memory. What is the VLEN of the instructions? Explain your answer.\n\nVLEN: 8\n\nExplanation: 20+20+(VLEN-1)+5+(VLEN-1)+1+(VLEN-1)+20+(VLEN-1) = 94.\n\n\u21d2 VLEN = 8\n\n# (d) [30 points]\n\nWe replace the memory with a new module whose characteristics are unknown. The following code (the same as that in (c)) takes 163 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nThe VLEN of the instructions is 16. The elements loaded in VR0 are placed in consecutive banks, the elements loaded in VR1 are placed in consecutive banks, and the elements of VR2 are also stored in consecutive banks. What is the number of banks of the new memory module? Explain.\n\n[Correction] The number of cycles should be 170 instead of 163. For grading this question the instructor took into account only the student\u2019s reasoning.\n\nNumber of banks: 8\n\nExplanation: Assuming that the number of banks is power of two, 20*(16/banks)+ 20*(16/banks)+ (banks-1)+ 5+ (VLEN-1)+ 1+ (VLEN-1)+ 20*(16/banks)+ (banks-1) = 170 \u21d2 banks=8\n\n# Midterm Exam\n\nPage 15 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(c) [25 points]",
                    "md": "# (c) [25 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "The following code takes 94 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nAssume that the elements loaded in VR0 are all placed in different banks, and that the elements loaded into VR1 are placed in the same banks as the elements in VR0. Similarly, the elements of VR2 are stored in different banks in memory. What is the VLEN of the instructions? Explain your answer.\n\nVLEN: 8\n\nExplanation: 20+20+(VLEN-1)+5+(VLEN-1)+1+(VLEN-1)+20+(VLEN-1) = 94.\n\n\u21d2 VLEN = 8",
                    "md": "The following code takes 94 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nAssume that the elements loaded in VR0 are all placed in different banks, and that the elements loaded into VR1 are placed in the same banks as the elements in VR0. Similarly, the elements of VR2 are stored in different banks in memory. What is the VLEN of the instructions? Explain your answer.\n\nVLEN: 8\n\nExplanation: 20+20+(VLEN-1)+5+(VLEN-1)+1+(VLEN-1)+20+(VLEN-1) = 94.\n\n\u21d2 VLEN = 8",
                    "rows": null,
                    "bBox": {
                        "x": 88.46,
                        "y": 89.93,
                        "w": 434.79,
                        "h": 439.06
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(d) [30 points]",
                    "md": "# (d) [30 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We replace the memory with a new module whose characteristics are unknown. The following code (the same as that in (c)) takes 163 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nThe VLEN of the instructions is 16. The elements loaded in VR0 are placed in consecutive banks, the elements loaded in VR1 are placed in consecutive banks, and the elements of VR2 are also stored in consecutive banks. What is the number of banks of the new memory module? Explain.\n\n[Correction] The number of cycles should be 170 instead of 163. For grading this question the instructor took into account only the student\u2019s reasoning.\n\nNumber of banks: 8\n\nExplanation: Assuming that the number of banks is power of two, 20*(16/banks)+ 20*(16/banks)+ (banks-1)+ 5+ (VLEN-1)+ 1+ (VLEN-1)+ 20*(16/banks)+ (banks-1) = 170 \u21d2 banks=8",
                    "md": "We replace the memory with a new module whose characteristics are unknown. The following code (the same as that in (c)) takes 163 cycles to execute on the vector processor:\n\nVLD    VR0 \u2190   mem[ R0 ]\nVLD    VR1 \u2190   mem[ R1 ]\nVADD VR2 \u2190 VR1,       VR0\nVSHR VR2 \u2190 VR2\nVST VR2 \u2192    mem[ R2 ]\n\nThe VLEN of the instructions is 16. The elements loaded in VR0 are placed in consecutive banks, the elements loaded in VR1 are placed in consecutive banks, and the elements of VR2 are also stored in consecutive banks. What is the number of banks of the new memory module? Explain.\n\n[Correction] The number of cycles should be 170 instead of 163. For grading this question the instructor took into account only the student\u2019s reasoning.\n\nNumber of banks: 8\n\nExplanation: Assuming that the number of banks is power of two, 20*(16/banks)+ 20*(16/banks)+ (banks-1)+ 5+ (VLEN-1)+ 1+ (VLEN-1)+ 20*(16/banks)+ (banks-1) = 170 \u21d2 banks=8",
                    "rows": null,
                    "bBox": {
                        "x": 88.46,
                        "y": 89.93,
                        "w": 435.17,
                        "h": 462.97
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Page 15 of 20",
                    "md": "Page 15 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 464.48,
                        "y": 784.67,
                        "w": 58.83,
                        "h": 10.0
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 17,
            "text": "Initials: Solutions                     Computer Architecture                      December 7th, 2017\n7     In-DRAM Bitmap Indices                    [70 points]\nRecall that in class we discussed Ambit, which is a DRAM design that can greatly accelerate Bulk Bitwise\nOperations by providing the ability to perform bitwise AND/OR of two rows in a subarray.\n    One real-world application that can benefit from Ambit\u2019s in-DRAM bulk bitwise operations is the\ndatabase bitmap index, as we also discussed in the lecture.  By using bitmap indices, we want to run\nthe following query on a database that keeps track of user actions: \u201cHow many unique users were active\nevery week for the past w weeks?\" Every week, each user is represented by a single bit. If the user was\nactive a given week, the corresponding bit is set to 1. The total number of users is u.\n    We assume the bits corresponding to one week are all in the same row. If u is greater than the total\nnumber of bits in one row (the row size is 8 kilobytes), more rows in different subarrays are used for the\nsame week. We assume that all weeks corresponding to the users in one subarray fit in that subarray.\n    We would like to compare two possible implementations of the database query:\n    \u2022 CPU-based implementation:    This implementation reads the bits of all u users for the w weeks.\n       For each user, it ands the bits corresponding to the past w weeks. Then, it performs a bit-count\n       operation to compute the final result.\n       Since this operation is very memory-bound, we simplify the estimation of the execution time as\n       the time needed to read all bits for the u users in the last w weeks. The memory bandwidth that\n       the CPU can exploit is X bytes/s.\n    \u2022  Ambit-based implementation: This implementation takes advantage of bulk and operations of Am-\n       bit. In each subarray, we reserve one Accumulation row and one Operand  row (besides the control\n       rows that are needed for the regular operation of Ambit). Initially, all bits in the Accumulation row\n       are set to 1. Any row can be moved to the Operand row by using RowClone (recall that RowClone\n       is a mechanism that enables very fast copying of a row to another row in the same subarray). trc\n       and tand are the latencies (in seconds) of RowClone\u2019s copy and Ambit\u2019s and respectively.\n       Since Ambit does not  support bit-count operations inside DRAM, the final bit-count is still ex-\n       ecuted on the CPU. We consider that the execution time of the bit-count operation is negligible\n       compared to the time needed to read all bits from the Accumulation rows by the CPU.\n(a) [15 points] What is the total number of DRAM rows that are occupied by u users and w weeks?\n         T otalRows = d   u  e \u00d7 w.\n                         8\u00d78k\n         Explanation:\n         The u users are spread across a number of subarrays:\n         N umSubarrays = d     u  e.\n                              8\u00d78k\n         Thus, the total number of rows is:\n         T otalRows = d   u  e \u00d7 w.\n                         8\u00d78k\n(b) [20 points] What is the throughput in users/second of the Ambit-based implementation?\n         T hrAmbit = d  u  e\u00d7w\u00d7(tu +t   )+ u   users/second.\n                       8\u00d78k      rc  and  X\u00d78\n         Explanation:\n         First, let us calculate the total time for all bulk and operations. We should add trc and\n         tand for all rows:\n         tand\u2212total = d u  e \u00d7 w \u00d7 (trc + tand) seconds.\n                       8\u00d78k\n         Then, we calculate the time needed to compute the bit count on CPU:\n         t        =  u =   u  seconds.\n          bitcount    ~~8~~  \n                     ~~X~~    X\u00d78\n         Thus, the throughput in users/s is:\n         T hrAmbit =  t      u         users/second.\n                      and\u2212total+tbitcount\nMidterm Exam                                                                              Page 16 of 20",
            "md": "# Initials: Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 7 In-DRAM Bitmap Indices [70 points]\n\nRecall that in class we discussed Ambit, which is a DRAM design that can greatly accelerate Bulk Bitwise Operations by providing the ability to perform bitwise AND/OR of two rows in a subarray.\n\nOne real-world application that can benefit from Ambit\u2019s in-DRAM bulk bitwise operations is the database bitmap index, as we also discussed in the lecture. By using bitmap indices, we want to run the following query on a database that keeps track of user actions: \u201cHow many unique users were active every week for the past w weeks?\" Every week, each user is represented by a single bit. If the user was active a given week, the corresponding bit is set to 1. The total number of users is u.\n\nWe assume the bits corresponding to one week are all in the same row. If u is greater than the total number of bits in one row (the row size is 8 kilobytes), more rows in different subarrays are used for the same week. We assume that all weeks corresponding to the users in one subarray fit in that subarray.\n\nWe would like to compare two possible implementations of the database query:\n\n- CPU-based implementation: This implementation reads the bits of all u users for the w weeks. For each user, it ands the bits corresponding to the past w weeks. Then, it performs a bit-count operation to compute the final result. Since this operation is very memory-bound, we simplify the estimation of the execution time as the time needed to read all bits for the u users in the last w weeks. The memory bandwidth that the CPU can exploit is X bytes/s.\n- Ambit-based implementation: This implementation takes advantage of bulk and operations of Ambit. In each subarray, we reserve one Accumulation row and one Operand row (besides the control rows that are needed for the regular operation of Ambit). Initially, all bits in the Accumulation row are set to 1. Any row can be moved to the Operand row by using RowClone (recall that RowClone is a mechanism that enables very fast copying of a row to another row in the same subarray). trc and tand are the latencies (in seconds) of RowClone\u2019s copy and Ambit\u2019s and respectively. Since Ambit does not support bit-count operations inside DRAM, the final bit-count is still executed on the CPU. We consider that the execution time of the bit-count operation is negligible compared to the time needed to read all bits from the Accumulation rows by the CPU.\n\n# (a) [15 points] What is the total number of DRAM rows that are occupied by u users and w weeks?\n\nTotalRows = d u e \u00d7 w.\n\n8\u00d78k\n\nExplanation:\n\nThe u users are spread across a number of subarrays:\n\nNumSubarrays = d u e.\n\n8\u00d78k\n\nThus, the total number of rows is:\n\nTotalRows = d u e \u00d7 w.\n\n8\u00d78k\n\n# (b) [20 points] What is the throughput in users/second of the Ambit-based implementation?\n\nThrAmbit = d u e \u00d7 w \u00d7 (tu + t) + u users/second.\n\n8\u00d78k\n\nExplanation:\n\nFirst, let us calculate the total time for all bulk and operations. We should add trc and tand for all rows:\n\ntand\u2212total = d u e \u00d7 w \u00d7 (trc + tand) seconds.\n\n8\u00d78k\n\nThen, we calculate the time needed to compute the bit count on CPU:\n\ntbitcount = u = u seconds.\n\n~~8~~\n\n~~X~~  X\u00d78\n\nThus, the throughput in users/s is:\n\nThrAmbit = tu users/second.\n\nand\u2212total + tbitcount\n\nMidterm Exam Page 16 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Initials: Solutions",
                    "md": "# Initials: Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 192.93,
                        "h": 687.49
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 43.11,
                        "w": 236.64,
                        "h": 687.49
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 43.11,
                        "w": 451.36,
                        "h": 687.49
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "7 In-DRAM Bitmap Indices [70 points]",
                    "md": "# 7 In-DRAM Bitmap Indices [70 points]",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 262.08,
                        "h": 662.98
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Recall that in class we discussed Ambit, which is a DRAM design that can greatly accelerate Bulk Bitwise Operations by providing the ability to perform bitwise AND/OR of two rows in a subarray.\n\nOne real-world application that can benefit from Ambit\u2019s in-DRAM bulk bitwise operations is the database bitmap index, as we also discussed in the lecture. By using bitmap indices, we want to run the following query on a database that keeps track of user actions: \u201cHow many unique users were active every week for the past w weeks?\" Every week, each user is represented by a single bit. If the user was active a given week, the corresponding bit is set to 1. The total number of users is u.\n\nWe assume the bits corresponding to one week are all in the same row. If u is greater than the total number of bits in one row (the row size is 8 kilobytes), more rows in different subarrays are used for the same week. We assume that all weeks corresponding to the users in one subarray fit in that subarray.\n\nWe would like to compare two possible implementations of the database query:\n\n- CPU-based implementation: This implementation reads the bits of all u users for the w weeks. For each user, it ands the bits corresponding to the past w weeks. Then, it performs a bit-count operation to compute the final result. Since this operation is very memory-bound, we simplify the estimation of the execution time as the time needed to read all bits for the u users in the last w weeks. The memory bandwidth that the CPU can exploit is X bytes/s.\n- Ambit-based implementation: This implementation takes advantage of bulk and operations of Ambit. In each subarray, we reserve one Accumulation row and one Operand row (besides the control rows that are needed for the regular operation of Ambit). Initially, all bits in the Accumulation row are set to 1. Any row can be moved to the Operand row by using RowClone (recall that RowClone is a mechanism that enables very fast copying of a row to another row in the same subarray). trc and tand are the latencies (in seconds) of RowClone\u2019s copy and Ambit\u2019s and respectively. Since Ambit does not support bit-count operations inside DRAM, the final bit-count is still executed on the CPU. We consider that the execution time of the bit-count operation is negligible compared to the time needed to read all bits from the Accumulation rows by the CPU.",
                    "md": "Recall that in class we discussed Ambit, which is a DRAM design that can greatly accelerate Bulk Bitwise Operations by providing the ability to perform bitwise AND/OR of two rows in a subarray.\n\nOne real-world application that can benefit from Ambit\u2019s in-DRAM bulk bitwise operations is the database bitmap index, as we also discussed in the lecture. By using bitmap indices, we want to run the following query on a database that keeps track of user actions: \u201cHow many unique users were active every week for the past w weeks?\" Every week, each user is represented by a single bit. If the user was active a given week, the corresponding bit is set to 1. The total number of users is u.\n\nWe assume the bits corresponding to one week are all in the same row. If u is greater than the total number of bits in one row (the row size is 8 kilobytes), more rows in different subarrays are used for the same week. We assume that all weeks corresponding to the users in one subarray fit in that subarray.\n\nWe would like to compare two possible implementations of the database query:\n\n- CPU-based implementation: This implementation reads the bits of all u users for the w weeks. For each user, it ands the bits corresponding to the past w weeks. Then, it performs a bit-count operation to compute the final result. Since this operation is very memory-bound, we simplify the estimation of the execution time as the time needed to read all bits for the u users in the last w weeks. The memory bandwidth that the CPU can exploit is X bytes/s.\n- Ambit-based implementation: This implementation takes advantage of bulk and operations of Ambit. In each subarray, we reserve one Accumulation row and one Operand row (besides the control rows that are needed for the regular operation of Ambit). Initially, all bits in the Accumulation row are set to 1. Any row can be moved to the Operand row by using RowClone (recall that RowClone is a mechanism that enables very fast copying of a row to another row in the same subarray). trc and tand are the latencies (in seconds) of RowClone\u2019s copy and Ambit\u2019s and respectively. Since Ambit does not support bit-count operations inside DRAM, the final bit-count is still executed on the CPU. We consider that the execution time of the bit-count operation is negligible compared to the time needed to read all bits from the Accumulation rows by the CPU.",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 93.82,
                        "w": 451.71,
                        "h": 636.78
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [15 points] What is the total number of DRAM rows that are occupied by u users and w weeks?",
                    "md": "# (a) [15 points] What is the total number of DRAM rows that are occupied by u users and w weeks?",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 432.55,
                        "w": 438.3,
                        "h": 298.05
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "TotalRows = d u e \u00d7 w.\n\n8\u00d78k\n\nExplanation:\n\nThe u users are spread across a number of subarrays:\n\nNumSubarrays = d u e.\n\n8\u00d78k\n\nThus, the total number of rows is:\n\nTotalRows = d u e \u00d7 w.\n\n8\u00d78k",
                    "md": "TotalRows = d u e \u00d7 w.\n\n8\u00d78k\n\nExplanation:\n\nThe u users are spread across a number of subarrays:\n\nNumSubarrays = d u e.\n\n8\u00d78k\n\nThus, the total number of rows is:\n\nTotalRows = d u e \u00d7 w.\n\n8\u00d78k",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 448.82,
                        "w": 232.17,
                        "h": 281.78
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [20 points] What is the throughput in users/second of the Ambit-based implementation?",
                    "md": "# (b) [20 points] What is the throughput in users/second of the Ambit-based implementation?",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 448.82,
                        "w": 404.39,
                        "h": 281.78
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "ThrAmbit = d u e \u00d7 w \u00d7 (tu + t) + u users/second.\n\n8\u00d78k\n\nExplanation:\n\nFirst, let us calculate the total time for all bulk and operations. We should add trc and tand for all rows:\n\ntand\u2212total = d u e \u00d7 w \u00d7 (trc + tand) seconds.\n\n8\u00d78k\n\nThen, we calculate the time needed to compute the bit count on CPU:\n\ntbitcount = u = u seconds.\n\n~~8~~\n\n~~X~~  X\u00d78\n\nThus, the throughput in users/s is:\n\nThrAmbit = tu users/second.\n\nand\u2212total + tbitcount\n\nMidterm Exam Page 16 of 20",
                    "md": "ThrAmbit = d u e \u00d7 w \u00d7 (tu + t) + u users/second.\n\n8\u00d78k\n\nExplanation:\n\nFirst, let us calculate the total time for all bulk and operations. We should add trc and tand for all rows:\n\ntand\u2212total = d u e \u00d7 w \u00d7 (trc + tand) seconds.\n\n8\u00d78k\n\nThen, we calculate the time needed to compute the bit count on CPU:\n\ntbitcount = u = u seconds.\n\n~~8~~\n\n~~X~~  X\u00d78\n\nThus, the throughput in users/s is:\n\nThrAmbit = tu users/second.\n\nand\u2212total + tbitcount\n\nMidterm Exam Page 16 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 362.81,
                        "w": 451.31,
                        "h": 431.86
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 18,
            "text": "Initials: Solutions                     Computer Architecture                     December 7th, 2017\n(c) [20 points] What is the throughput in users/second of the CPU implementation?\n         T hrCP U = X\u00d78  users/second.\n                      w\n         Explanation:\n         We calculate the time needed to bring all users and weeks to the CPU:\n         t     =  u\u00d7w = u\u00d7w   seconds.\n          CP U     8\n                   X     X\u00d78\n         Thus, the throughput in users/s is:\n         T hrCP U =  t u  = X\u00d78  users/second.\n                     CP U     w\n(d) [15 points] What is the maximum w for the CPU implementation to be faster than the Ambit-based\n    implementation? Assume u is a multiple of the row size.\n         w < 1\u2212 X \u00d7( 1       .\n                 8k  trc+tand)\n         Explanation:\n         We compare tCP U   with tand\u2212total + tbitcount:\n         tCP U < tand\u2212total + tbitcount;\n         u\u00d7w <    u   \u00d7 w \u00d7 (trc + tand) + u   ;\n         X\u00d78     8\u00d78k                     X\u00d78\n         w <     X \u00d7( 1      .\n              1\u2212 8k  trc+tand)\nMidterm Exam                                                                             Page 17 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\n# (c) [20 points] What is the throughput in users/second of the CPU implementation?\n\nThrCPU = X \u00d7 8 users/second.\n\n# Explanation:\n\nWe calculate the time needed to bring all users and weeks to the CPU:\n\ntCPU = u \u00d7 w = u \u00d7 w seconds.\n\nThus, the throughput in users/s is:\n\nThrCPU = tu = X \u00d7 8 users/second.\n\n# (d) [15 points] What is the maximum w for the CPU implementation to be faster than the Ambit-based implementation? Assume u is a multiple of the row size.\n\nw < 1 - X \u00d7 (1 / (8k trc + tand))\n\n# Explanation:\n\nWe compare tCPU with tand-total + tbitcount:\n\ntCPU < tand-total + tbitcount;\n\nu \u00d7 w < u \u00d7 w \u00d7 (trc + tand) + u;\n\nX \u00d7 8\n\nw < X \u00d7 (1 / (1 - 8k trc + tand))\n\nMidterm Exam Page 17 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 43.11,
                        "w": 236.64,
                        "h": 355.37
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 43.11,
                        "w": 411.97,
                        "h": 140.73
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(c) [20 points] What is the throughput in users/second of the CPU implementation?",
                    "md": "# (c) [20 points] What is the throughput in users/second of the CPU implementation?",
                    "rows": null,
                    "bBox": {
                        "x": 72.55,
                        "y": 72.0,
                        "w": 369.34,
                        "h": 326.48
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "ThrCPU = X \u00d7 8 users/second.",
                    "md": "ThrCPU = X \u00d7 8 users/second.",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 123.15,
                        "w": 165.68,
                        "h": 303.17
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Explanation:",
                    "md": "# Explanation:",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 147.06,
                        "w": 64.0,
                        "h": 207.53
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We calculate the time needed to bring all users and weeks to the CPU:\n\ntCPU = u \u00d7 w = u \u00d7 w seconds.\n\nThus, the throughput in users/s is:\n\nThrCPU = tu = X \u00d7 8 users/second.",
                    "md": "We calculate the time needed to bring all users and weeks to the CPU:\n\ntCPU = u \u00d7 w = u \u00d7 w seconds.\n\nThus, the throughput in users/s is:\n\nThrCPU = tu = X \u00d7 8 users/second.",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 123.15,
                        "w": 309.75,
                        "h": 303.17
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(d) [15 points] What is the maximum w for the CPU implementation to be faster than the Ambit-based implementation? Assume u is a multiple of the row size.",
                    "md": "# (d) [15 points] What is the maximum w for the CPU implementation to be faster than the Ambit-based implementation? Assume u is a multiple of the row size.",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 129.58,
                        "w": 451.43,
                        "h": 296.75
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "w < 1 - X \u00d7 (1 / (8k trc + tand))",
                    "md": "w < 1 - X \u00d7 (1 / (8k trc + tand))",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 129.58,
                        "w": 97.55,
                        "h": 300.93
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Explanation:",
                    "md": "# Explanation:",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 147.06,
                        "w": 64.0,
                        "h": 207.53
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We compare tCPU with tand-total + tbitcount:\n\ntCPU < tand-total + tbitcount;\n\nu \u00d7 w < u \u00d7 w \u00d7 (trc + tand) + u;\n\nX \u00d7 8\n\nw < X \u00d7 (1 / (1 - 8k trc + tand))\n\nMidterm Exam Page 17 of 20",
                    "md": "We compare tCPU with tand-total + tbitcount:\n\ntCPU < tand-total + tbitcount;\n\nu \u00d7 w < u \u00d7 w \u00d7 (trc + tand) + u;\n\nX \u00d7 8\n\nw < X \u00d7 (1 / (1 - 8k trc + tand))\n\nMidterm Exam Page 17 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 129.58,
                        "w": 451.31,
                        "h": 665.09
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 19,
            "text": "Initials: Solutions                   Computer Architecture                    December 7th, 2017\n8     BONUS: Caching vs. Processing-in-Memory                            [80 points]\nWe are given the following piece of code that makes accesses to integer arrays A and B. The size of each\nelement in both A and B is 4 bytes. The base address of array A is 0x00001000, and the base address of\nB is 0x00008000.\nmovi R1, #0x1000 // Store the base address of A in R1\nmovi R2, #0x8000 // Store the base address of B in R2\nmovi R3, #0\nOuter_Loop:\n     movi R4, #0\n     movi R7, #0\n     Inner_Loop:\n           add R5, R3, R4      // R5 = R3 + R4\n           // load 4 bytes from memory address R1+R5\n           ld R5, [R1, R5] // R5 = Memory[R1 + R5],\n           ld R6, [R2, R4] // R6 = Memory[R2 + R4]\n           mul R5, R5, R6      // R5 = R5 * R6\n           add R7, R7, R5      // R7 += R5\n           inc R4              // R4++\n           bne R4, #2, Inner_Loop // If R4 != 2, jump to Inner_Loop\n     //store the data of R7 in memory address R1+R3\n     st [R1, R3], R7           // Memory[R1 + R3] = R7,\n     inc R3                    // R3++\n     bne R3, #16, Outer_Loop // If R3 != 16, jump to Outer_Loop\n    You are running the above code on a single-core processor. For now, assume that the processor does\nnot have caches. Therefore, all load/store instructions access the main memory, which has a fixed 50-\ncycle latency, for both read and write operations. Assume that all load/store operations are serialized,\ni.e., the latency of multiple memory requests cannot be overlapped. Also assume that the execution time\nof a non-memory-access instruction is zero (i.e., we ignore its execution time).\n(a) [15 points] What is the execution time of the above piece of code in cycles?\n         4000 cycles.\n         Explanation: There are 5 memory accesses for each outer loop iteration. The outer loop\n         iterates 16 times, and each memory access takes 50 cycles.\n         16 \u2217 5 \u2217 50 = 4000 cycles\n(b) [25 points] Assume that a 128-byte private cache is added to the processor core in the next-generation\n    processor. The cache block size is 8-byte. The cache is direct-mapped. On a hit, the cache services\n    both read and write requests in 5 cycles. On a miss, the main memory is accessed and the access\n    fills an 8-byte cache line in 50 cycles. Assuming that the cache is initially empty, what is the new\n    execution time on this processor with the described cache? Show your work.\n      900 cycles.\n      Explanation.\n      At the beginning A and B conflict in the first two cache lines. Then the elements of A and B\n      go to different cache lines. The total execution time is 1910 cycles.\n      Here is the access pattern for the first outer loop iteration:\n      0 \u2212 A[0], B[0], A[1], B[1], A[0]\nMidterm Exam                                                                         Page 18 of 20",
            "md": "# Solutions\n\n# Computer Architecture\n\n# December 7th, 2017\n\n# 8 BONUS: Caching vs. Processing-in-Memory\n\nWe are given the following piece of code that makes accesses to integer arrays A and B. The size of each element in both A and B is 4 bytes. The base address of array A is 0x00001000, and the base address of B is 0x00008000.\n\nmovi R1, #0x1000 // Store the base address of A in R1\nmovi R2, #0x8000 // Store the base address of B in R2\nmovi R3, #0\nOuter_Loop:\nmovi R4, #0\nmovi R7, #0\nInner_Loop:\nadd R5, R3, R4      // R5 = R3 + R4\n// load 4 bytes from memory address R1+R5\nld R5, [R1, R5] // R5 = Memory[R1 + R5],\nld R6, [R2, R4] // R6 = Memory[R2 + R4]\nmul R5, R5, R6      // R5 = R5 * R6\nadd R7, R7, R5      // R7 += R5\ninc R4              // R4++\nbne R4, #2, Inner_Loop // If R4 != 2, jump to Inner_Loop\n//store the data of R7 in memory address R1+R3\nst [R1, R3], R7           // Memory[R1 + R3] = R7,\ninc R3                    // R3++\nbne R3, #16, Outer_Loop // If R3 != 16, jump to Outer_Loop\n\nYou are running the above code on a single-core processor. For now, assume that the processor does not have caches. Therefore, all load/store instructions access the main memory, which has a fixed 50-cycle latency, for both read and write operations. Assume that all load/store operations are serialized, i.e., the latency of multiple memory requests cannot be overlapped. Also assume that the execution time of a non-memory-access instruction is zero (i.e., we ignore its execution time).\n\n# (a) [15 points] What is the execution time of the above piece of code in cycles?\n\n4000 cycles.\n\nExplanation: There are 5 memory accesses for each outer loop iteration. The outer loop iterates 16 times, and each memory access takes 50 cycles.\n\n16 \u2217 5 \u2217 50 = 4000 cycles\n\n# (b) [25 points] Assume that a 128-byte private cache is added to the processor core in the next-generation processor. The cache block size is 8-byte. The cache is direct-mapped. On a hit, the cache services both read and write requests in 5 cycles. On a miss, the main memory is accessed and the access fills an 8-byte cache line in 50 cycles. Assuming that the cache is initially empty, what is the new execution time on this processor with the described cache? Show your work.\n\n900 cycles.\n\nExplanation.\n\nAt the beginning A and B conflict in the first two cache lines. Then the elements of A and B go to different cache lines. The total execution time is 1910 cycles.\n\nHere is the access pattern for the first outer loop iteration:\n\n0 \u2212 A[0], B[0], A[1], B[1], A[0]\n\n# Midterm Exam\n\nPage 18 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Solutions",
                    "md": "# Solutions",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "8 BONUS: Caching vs. Processing-in-Memory",
                    "md": "# 8 BONUS: Caching vs. Processing-in-Memory",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 331.46,
                        "h": 14.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "We are given the following piece of code that makes accesses to integer arrays A and B. The size of each element in both A and B is 4 bytes. The base address of array A is 0x00001000, and the base address of B is 0x00008000.\n\nmovi R1, #0x1000 // Store the base address of A in R1\nmovi R2, #0x8000 // Store the base address of B in R2\nmovi R3, #0\nOuter_Loop:\nmovi R4, #0\nmovi R7, #0\nInner_Loop:\nadd R5, R3, R4      // R5 = R3 + R4\n// load 4 bytes from memory address R1+R5\nld R5, [R1, R5] // R5 = Memory[R1 + R5],\nld R6, [R2, R4] // R6 = Memory[R2 + R4]\nmul R5, R5, R6      // R5 = R5 * R6\nadd R7, R7, R5      // R7 += R5\ninc R4              // R4++\nbne R4, #2, Inner_Loop // If R4 != 2, jump to Inner_Loop\n//store the data of R7 in memory address R1+R3\nst [R1, R3], R7           // Memory[R1 + R3] = R7,\ninc R3                    // R3++\nbne R3, #16, Outer_Loop // If R3 != 16, jump to Outer_Loop\n\nYou are running the above code on a single-core processor. For now, assume that the processor does not have caches. Therefore, all load/store instructions access the main memory, which has a fixed 50-cycle latency, for both read and write operations. Assume that all load/store operations are serialized, i.e., the latency of multiple memory requests cannot be overlapped. Also assume that the execution time of a non-memory-access instruction is zero (i.e., we ignore its execution time).",
                    "md": "We are given the following piece of code that makes accesses to integer arrays A and B. The size of each element in both A and B is 4 bytes. The base address of array A is 0x00001000, and the base address of B is 0x00008000.\n\nmovi R1, #0x1000 // Store the base address of A in R1\nmovi R2, #0x8000 // Store the base address of B in R2\nmovi R3, #0\nOuter_Loop:\nmovi R4, #0\nmovi R7, #0\nInner_Loop:\nadd R5, R3, R4      // R5 = R3 + R4\n// load 4 bytes from memory address R1+R5\nld R5, [R1, R5] // R5 = Memory[R1 + R5],\nld R6, [R2, R4] // R6 = Memory[R2 + R4]\nmul R5, R5, R6      // R5 = R5 * R6\nadd R7, R7, R5      // R7 += R5\ninc R4              // R4++\nbne R4, #2, Inner_Loop // If R4 != 2, jump to Inner_Loop\n//store the data of R7 in memory address R1+R3\nst [R1, R3], R7           // Memory[R1 + R3] = R7,\ninc R3                    // R3++\nbne R3, #16, Outer_Loop // If R3 != 16, jump to Outer_Loop\n\nYou are running the above code on a single-core processor. For now, assume that the processor does not have caches. Therefore, all load/store instructions access the main memory, which has a fixed 50-cycle latency, for both read and write operations. Assume that all load/store operations are serialized, i.e., the latency of multiple memory requests cannot be overlapped. Also assume that the execution time of a non-memory-access instruction is zero (i.e., we ignore its execution time).",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.59,
                        "h": 386.48
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(a) [15 points] What is the execution time of the above piece of code in cycles?",
                    "md": "# (a) [15 points] What is the execution time of the above piece of code in cycles?",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 463.82,
                        "w": 346.35,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "4000 cycles.\n\nExplanation: There are 5 memory accesses for each outer loop iteration. The outer loop iterates 16 times, and each memory access takes 50 cycles.\n\n16 \u2217 5 \u2217 50 = 4000 cycles",
                    "md": "4000 cycles.\n\nExplanation: There are 5 memory accesses for each outer loop iteration. The outer loop iterates 16 times, and each memory access takes 50 cycles.\n\n16 \u2217 5 \u2217 50 = 4000 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 111.39,
                        "y": 489.42,
                        "w": 390.67,
                        "h": 57.82
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(b) [25 points] Assume that a 128-byte private cache is added to the processor core in the next-generation processor. The cache block size is 8-byte. The cache is direct-mapped. On a hit, the cache services both read and write requests in 5 cycles. On a miss, the main memory is accessed and the access fills an 8-byte cache line in 50 cycles. Assuming that the cache is initially empty, what is the new execution time on this processor with the described cache? Show your work.",
                    "md": "# (b) [25 points] Assume that a 128-byte private cache is added to the processor core in the next-generation processor. The cache block size is 8-byte. The cache is direct-mapped. On a hit, the cache services both read and write requests in 5 cycles. On a miss, the main memory is accessed and the access fills an 8-byte cache line in 50 cycles. Assuming that the cache is initially empty, what is the new execution time on this processor with the described cache? Show your work.",
                    "rows": null,
                    "bBox": {
                        "x": 71.45,
                        "y": 67.62,
                        "w": 452.01,
                        "h": 557.63
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "900 cycles.\n\nExplanation.\n\nAt the beginning A and B conflict in the first two cache lines. Then the elements of A and B go to different cache lines. The total execution time is 1910 cycles.\n\nHere is the access pattern for the first outer loop iteration:\n\n0 \u2212 A[0], B[0], A[1], B[1], A[0]",
                    "md": "900 cycles.\n\nExplanation.\n\nAt the beginning A and B conflict in the first two cache lines. Then the elements of A and B go to different cache lines. The total execution time is 1910 cycles.\n\nHere is the access pattern for the first outer loop iteration:\n\n0 \u2212 A[0], B[0], A[1], B[1], A[0]",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 645.4,
                        "w": 412.79,
                        "h": 97.67
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Midterm Exam",
                    "md": "# Midterm Exam",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 784.67,
                        "w": 66.25,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Page 18 of 20",
                    "md": "Page 18 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 67.62,
                        "w": 451.31,
                        "h": 727.05
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 20,
            "text": "Initials: Solutions                     Computer Architecture                       December 7th, 2017\n      The first 4 references are loads, the last (A[0]) is a store. The cache is initially empty. We have\n      a cache miss for A[0]. A[0] and A[1] is fetched to 0th index in the cache. Then, B[0] is a miss,\n      and it is conflicting with A[0]. So, A[0] and A[1] are evicted. Similarly, all cache blocks in the\n      first iteration are conflicting with each other. Since we have only cache misses, the latency for\n      those 5 references is 5 \u2217 50 = 250 cycles\n      The status of the cache after making those seven references is:\n        Cache Index                 Cache Block\n             0         A(0,1), B(0,1), A(0,1), B(0,1), A(0,1)\n      Second iteration on the outer loop:\n      1 \u2212 A[1], B[0], A[2], B[1], A[1]\n      Cache hits/misses in the order of the references:\n      H, M, M, H, M\n      Latency = 2 \u2217 5 + 3 \u2217 50 = 165 cycles\n      Cache Status:\n      - A(0,1) is in set 0\n      - A(2,3) is in set 1\n      - the rest of the cache is empty\n      2 \u2212 A[2], B[0], A[3], B[1], A[2]\n      Cache hits/misses:\n      H, M, H, H, H\n      Latency  : 4 \u2217 5 + 1 \u2217 50 = 70 cycles\n      Cache Status:\n      - B(0,1) is in set 0\n      - A(2,3) is in set 1\n      - the rest of the cache is empty\n      3 \u2212 A[3], B[0], A[4], B[1], A[3]\n      Cache hits/misses:\n      H, H, M, H, H\n      Latency  : 4 \u2217 5 + 1 \u2217 50 = 70 cycles\n      Cache Status:\n      - B(0,1) is in set 0\n      - A(2,3) is in set 1\n      - A(4,5) is in set 2\n      - the rest of the cache is empty\n      4 \u2212 A[4], B[0], A[5], B[1], A[4]\n      Cache hits/misses:\n      H, H, H, H, H\n      Latency  : 5 \u2217 5 = 25 cycles\nMidterm Exam                                                                              Page 19 of 20",
            "md": "# Computer Architecture\n\nDate: December 7th, 2017\n\nThe first 4 references are loads, the last (A[0]) is a store. The cache is initially empty. We have a cache miss for A[0]. A[0] and A[1] is fetched to 0th index in the cache. Then, B[0] is a miss, and it is conflicting with A[0]. So, A[0] and A[1] are evicted. Similarly, all cache blocks in the first iteration are conflicting with each other. Since we have only cache misses, the latency for those 5 references is 5 \u2217 50 = 250 cycles.\n\n# Cache Status After First Iteration\n\n| Cache Index | Cache Block                            |\n| ----------- | -------------------------------------- |\n| 0           | A(0,1), B(0,1), A(0,1), B(0,1), A(0,1) |\n\n# Second Iteration on the Outer Loop\n\n1 \u2212 A[1], B[0], A[2], B[1], A[1]\n\nCache hits/misses in the order of the references: H, M, M, H, M\n\nLatency = 2 \u2217 5 + 3 \u2217 50 = 165 cycles\n\n# Cache Status\n\n- A(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n2 \u2212 A[2], B[0], A[3], B[1], A[2]\n\nCache hits/misses: H, M, H, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles\n\n# Cache Status\n\n- B(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n3 \u2212 A[3], B[0], A[4], B[1], A[3]\n\nCache hits/misses: H, H, M, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles\n\n# Cache Status\n\n- B(0,1) is in set 0\n- A(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\n4 \u2212 A[4], B[0], A[5], B[1], A[4]\n\nCache hits/misses: H, H, H, H, H\n\nLatency: 5 \u2217 5 = 25 cycles",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Date: December 7th, 2017\n\nThe first 4 references are loads, the last (A[0]) is a store. The cache is initially empty. We have a cache miss for A[0]. A[0] and A[1] is fetched to 0th index in the cache. Then, B[0] is a miss, and it is conflicting with A[0]. So, A[0] and A[1] are evicted. Similarly, all cache blocks in the first iteration are conflicting with each other. Since we have only cache misses, the latency for those 5 references is 5 \u2217 50 = 250 cycles.",
                    "md": "Date: December 7th, 2017\n\nThe first 4 references are loads, the last (A[0]) is a store. The cache is initially empty. We have a cache miss for A[0]. A[0] and A[1] is fetched to 0th index in the cache. Then, B[0] is a miss, and it is conflicting with A[0]. So, A[0] and A[1] are evicted. Similarly, all cache blocks in the first iteration are conflicting with each other. Since we have only cache misses, the latency for those 5 references is 5 \u2217 50 = 250 cycles.",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 43.11,
                        "w": 423.29,
                        "h": 631.1
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Status After First Iteration",
                    "md": "# Cache Status After First Iteration",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "table",
                    "lvl": null,
                    "value": null,
                    "md": "| Cache Index | Cache Block                            |\n| ----------- | -------------------------------------- |\n| 0           | A(0,1), B(0,1), A(0,1), B(0,1), A(0,1) |",
                    "rows": [
                        [
                            "Cache Index",
                            "Cache Block"
                        ],
                        [
                            "0",
                            "A(0,1), B(0,1), A(0,1), B(0,1), A(0,1)"
                        ]
                    ],
                    "bBox": {
                        "x": 100.07,
                        "y": 43.11,
                        "w": 423.29,
                        "h": 751.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Second Iteration on the Outer Loop",
                    "md": "# Second Iteration on the Outer Loop",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "1 \u2212 A[1], B[0], A[2], B[1], A[1]\n\nCache hits/misses in the order of the references: H, M, M, H, M\n\nLatency = 2 \u2217 5 + 3 \u2217 50 = 165 cycles",
                    "md": "1 \u2212 A[1], B[0], A[2], B[1], A[1]\n\nCache hits/misses in the order of the references: H, M, M, H, M\n\nLatency = 2 \u2217 5 + 3 \u2217 50 = 165 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 166.19,
                        "w": 209.62,
                        "h": 508.02
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Status",
                    "md": "# Cache Status",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "- A(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n2 \u2212 A[2], B[0], A[3], B[1], A[2]\n\nCache hits/misses: H, M, H, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles",
                    "md": "- A(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n2 \u2212 A[2], B[0], A[3], B[1], A[2]\n\nCache hits/misses: H, M, H, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 166.19,
                        "w": 151.59,
                        "h": 508.02
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Status",
                    "md": "# Cache Status",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "- B(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n3 \u2212 A[3], B[0], A[4], B[1], A[3]\n\nCache hits/misses: H, H, M, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles",
                    "md": "- B(0,1) is in set 0\n- A(2,3) is in set 1\n- the rest of the cache is empty\n\n3 \u2212 A[3], B[0], A[4], B[1], A[3]\n\nCache hits/misses: H, H, M, H, H\n\nLatency: 4 \u2217 5 + 1 \u2217 50 = 70 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 166.19,
                        "w": 151.59,
                        "h": 508.02
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Status",
                    "md": "# Cache Status",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "- B(0,1) is in set 0\n- A(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\n4 \u2212 A[4], B[0], A[5], B[1], A[4]\n\nCache hits/misses: H, H, H, H, H\n\nLatency: 5 \u2217 5 = 25 cycles",
                    "md": "- B(0,1) is in set 0\n- A(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\n4 \u2212 A[4], B[0], A[5], B[1], A[4]\n\nCache hits/misses: H, H, H, H, H\n\nLatency: 5 \u2217 5 = 25 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 166.19,
                        "w": 135.59,
                        "h": 508.02
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        },
        {
            "page": 21,
            "text": "Initials: Solutions                     Computer Architecture                       December 7th, 2017\n       Cache Status:\n       - B(0,1) is in set 0\n       - B(2,3) is in set 1\n       - A(4,5) is in set 2\n       - the rest of the cache is empty\n       After this point, single-miss and zero-miss (all hits) iterations are interleaved until the 16th\n       iteration.\n       Overall Latency:\n       165 + 70 + (70 + 25) \u2217 7 = 900 cycles\n (c) [15 points] You are not satisfied with the performance after implementing the described cache. To\n    do better, you consider utilizing a processing unit that is available close to the main memory. This\n    processing unit can directly interface to the main memory with a 10-cycle    latency, for both read\n    and write operations.   How many cycles does it take to execute the same program using the in-\n    memory processing units? (Assume that the in-memory processing unit does not have a cache, and\n    the memory accesses are serialized like in the processor core. The latency of the non-memory-access\n    operations is ignored.)\n         800 cycles.\n         Explanation:    Same as for the processor core without a cache, but the memory access\n         latency is 10 cycles instead of 50. 16 \u2217 5 \u2217 10 = 800\n(d) [15 points] You friend now suggests that, by changing the cache capacity of the single-core proces-\n    sor (in part (b)), she could provide as good performance as the system that utilizes the memory\n    processing unit (in part (c)).\n    Is she correct? What is the minimum capacity required for the cache of the single-core processor to\n    match the performance of the program running on the memory processing unit?\n         No, she is not correct.\n         Explanation: Increasing the cache capacity does not help because doing so cannot elim-\n         inate the conflicts to Set 0 in the first two iterations of the outer loop.\n (e) [10 points] What other changes could be made to the cache design to improve the performance of\n    the single-core processor on this program?\n         Increasing the associativity of the cache.\n         Explanation:     Although there is enough cache capacity to exploit the locality of the\n         accesses, the fact that in the first two iterations the accessed data map to the same set\n         causes conflicts. To improve the hit rate and the performance, we can change the address-\n         to-set mapping policy. For example, we can change the cache design to be set-associative\n         or fully-associative.\nMidterm Exam                                                                              Page 20 of 20",
            "md": "# Computer Architecture\n\n# December 7th, 2017\n\n# Cache Status:\n\n- B(0,1) is in set 0\n- B(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\nAfter this point, single-miss and zero-miss (all hits) iterations are interleaved until the 16th iteration.\n\n# Overall Latency:\n\n165 + 70 + (70 + 25) \u2217 7 = 900 cycles\n\n# (c) [15 points]\n\nYou are not satisfied with the performance after implementing the described cache. To do better, you consider utilizing a processing unit that is available close to the main memory. This processing unit can directly interface to the main memory with a 10-cycle latency, for both read and write operations. How many cycles does it take to execute the same program using the in-memory processing units? (Assume that the in-memory processing unit does not have a cache, and the memory accesses are serialized like in the processor core. The latency of the non-memory-access operations is ignored.)\n\n800 cycles.\n\nExplanation: Same as for the processor core without a cache, but the memory access latency is 10 cycles instead of 50. 16 \u2217 5 \u2217 10 = 800\n\n# (d) [15 points]\n\nYour friend now suggests that, by changing the cache capacity of the single-core processor (in part (b)), she could provide as good performance as the system that utilizes the memory processing unit (in part (c)). Is she correct? What is the minimum capacity required for the cache of the single-core processor to match the performance of the program running on the memory processing unit?\n\nNo, she is not correct.\n\nExplanation: Increasing the cache capacity does not help because doing so cannot eliminate the conflicts to Set 0 in the first two iterations of the outer loop.\n\n# (e) [10 points]\n\nWhat other changes could be made to the cache design to improve the performance of the single-core processor on this program?\n\nIncreasing the associativity of the cache.\n\nExplanation: Although there is enough cache capacity to exploit the locality of the accesses, the fact that in the first two iterations the accessed data map to the same set causes conflicts. To improve the hit rate and the performance, we can change the address-to-set mapping policy. For example, we can change the cache design to be set-associative or fully-associative.\n\nMidterm Exam\n\nPage 20 of 20",
            "images": [],
            "charts": [],
            "tables": [],
            "layout": [],
            "items": [
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Computer Architecture",
                    "md": "# Computer Architecture",
                    "rows": null,
                    "bBox": {
                        "x": 246.97,
                        "y": 43.11,
                        "w": 101.06,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "December 7th, 2017",
                    "md": "# December 7th, 2017",
                    "rows": null,
                    "bBox": {
                        "x": 436.51,
                        "y": 43.11,
                        "w": 86.85,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Cache Status:",
                    "md": "# Cache Status:",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 72.0,
                        "w": 59.61,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "- B(0,1) is in set 0\n- B(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\nAfter this point, single-miss and zero-miss (all hits) iterations are interleaved until the 16th iteration.",
                    "md": "- B(0,1) is in set 0\n- B(2,3) is in set 1\n- A(4,5) is in set 2\n- the rest of the cache is empty\n\nAfter this point, single-miss and zero-miss (all hits) iterations are interleaved until the 16th iteration.",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 83.96,
                        "w": 412.48,
                        "h": 85.72
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "Overall Latency:",
                    "md": "# Overall Latency:",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 175.61,
                        "w": 71.88,
                        "h": 10.0
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "165 + 70 + (70 + 25) \u2217 7 = 900 cycles",
                    "md": "165 + 70 + (70 + 25) \u2217 7 = 900 cycles",
                    "rows": null,
                    "bBox": {
                        "x": 100.07,
                        "y": 187.57,
                        "w": 160.05,
                        "h": 10.0
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(c) [15 points]",
                    "md": "# (c) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "You are not satisfied with the performance after implementing the described cache. To do better, you consider utilizing a processing unit that is available close to the main memory. This processing unit can directly interface to the main memory with a 10-cycle latency, for both read and write operations. How many cycles does it take to execute the same program using the in-memory processing units? (Assume that the in-memory processing unit does not have a cache, and the memory accesses are serialized like in the processor core. The latency of the non-memory-access operations is ignored.)\n\n800 cycles.\n\nExplanation: Same as for the processor core without a cache, but the memory access latency is 10 cycles instead of 50. 16 \u2217 5 \u2217 10 = 800",
                    "md": "You are not satisfied with the performance after implementing the described cache. To do better, you consider utilizing a processing unit that is available close to the main memory. This processing unit can directly interface to the main memory with a 10-cycle latency, for both read and write operations. How many cycles does it take to execute the same program using the in-memory processing units? (Assume that the in-memory processing unit does not have a cache, and the memory accesses are serialized like in the processor core. The latency of the non-memory-access operations is ignored.)\n\n800 cycles.\n\nExplanation: Same as for the processor core without a cache, but the memory access latency is 10 cycles instead of 50. 16 \u2217 5 \u2217 10 = 800",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 227.61,
                        "w": 433.95,
                        "h": 385.26
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(d) [15 points]",
                    "md": "# (d) [15 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "Your friend now suggests that, by changing the cache capacity of the single-core processor (in part (b)), she could provide as good performance as the system that utilizes the memory processing unit (in part (c)). Is she correct? What is the minimum capacity required for the cache of the single-core processor to match the performance of the program running on the memory processing unit?\n\nNo, she is not correct.\n\nExplanation: Increasing the cache capacity does not help because doing so cannot eliminate the conflicts to Set 0 in the first two iterations of the outer loop.",
                    "md": "Your friend now suggests that, by changing the cache capacity of the single-core processor (in part (b)), she could provide as good performance as the system that utilizes the memory processing unit (in part (c)). Is she correct? What is the minimum capacity required for the cache of the single-core processor to match the performance of the program running on the memory processing unit?\n\nNo, she is not correct.\n\nExplanation: Increasing the cache capacity does not help because doing so cannot eliminate the conflicts to Set 0 in the first two iterations of the outer loop.",
                    "rows": null,
                    "bBox": {
                        "x": 89.71,
                        "y": 343.31,
                        "w": 433.71,
                        "h": 269.56
                    }
                },
                {
                    "type": "heading",
                    "lvl": 1,
                    "value": "(e) [10 points]",
                    "md": "# (e) [10 points]",
                    "rows": null,
                    "bBox": {
                        "x": 0.0,
                        "y": 0.0,
                        "w": 595.28,
                        "h": 841.89
                    }
                },
                {
                    "type": "text",
                    "lvl": null,
                    "value": "What other changes could be made to the cache design to improve the performance of the single-core processor on this program?\n\nIncreasing the associativity of the cache.\n\nExplanation: Although there is enough cache capacity to exploit the locality of the accesses, the fact that in the first two iterations the accessed data map to the same set causes conflicts. To improve the hit rate and the performance, we can change the address-to-set mapping policy. For example, we can change the cache design to be set-associative or fully-associative.\n\nMidterm Exam\n\nPage 20 of 20",
                    "md": "What other changes could be made to the cache design to improve the performance of the single-core processor on this program?\n\nIncreasing the associativity of the cache.\n\nExplanation: Although there is enough cache capacity to exploit the locality of the accesses, the fact that in the first two iterations the accessed data map to the same set causes conflicts. To improve the hit rate and the performance, we can change the address-to-set mapping policy. For example, we can change the cache design to be set-associative or fully-associative.\n\nMidterm Exam\n\nPage 20 of 20",
                    "rows": null,
                    "bBox": {
                        "x": 72.0,
                        "y": 343.31,
                        "w": 451.31,
                        "h": 451.36
                    }
                }
            ],
            "status": "OK",
            "links": [],
            "width": 595.276,
            "height": 841.89,
            "triggeredAutoMode": false,
            "parsingMode": "accurate",
            "structuredData": null,
            "noStructuredContent": false,
            "noTextContent": false
        }
    ],
    "job_metadata": {
        "job_pages": 0,
        "job_auto_mode_triggered_pages": 0,
        "job_is_cache_hit": true
    },
    "file_name": "data/main-sol-midterm.pdf",
    "job_id": "ccf849c2-f97a-41d4-bc0b-dce8352d6250",
    "is_done": false,
    "error": null
}