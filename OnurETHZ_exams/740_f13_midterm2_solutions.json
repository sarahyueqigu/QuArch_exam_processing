{
  "exam_name": "Computer Architecture Exam.pdf",
  "problem": "Problem 1: Potpourri (55 pts)",
  "parts": [
    {
      "part": "A",
      "subproblem": [
        {
          "subproblem_context": "Thread prioritization\n\nSuppose we are running a multithreaded application where threads are part of the same application on a multicore processor. The memory controller is shared between the cores.",
          "subproblem_question": "1) Provide one reason why prioritizing a memory non-intensive thread over a memory-intensive one in the memory controller would improve performance. If this is not possible, write N/A and explain why.",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "Prioritizing latency-sensitive (memory non-intensive) threads can increase system throughput",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "A",
      "subproblem": [
        {
          "subproblem_question": "2) Provide one reason why doing the same would degrade performance. If this is not possible, write N/A and explain why.",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "Can delay the critical/bottleneck thread which may not be memory non-intensive",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "B",
      "subproblem": [
        {
          "subproblem_context": "Memory bandwidth",
          "subproblem_question": "Under what conditions would an application's performance increase linearly as memory bandwidth is increased?",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "If memory bandwidth is the performance bottleneck",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "C",
      "subproblem": [
        {
          "subproblem_context": "Fat trees",
          "subproblem_question": "What problem does the fat tree interconnect solve that is present in the tree interconnect?",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "High link contention between root and subnodes – a fat tree increases the bandwidth of these links",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "D",
      "subproblem": [
        {
          "subproblem_context": "Interconnect",
          "subproblem_question": "You are observing a system with many processing elements connected through a network. There is currently no activity on the network (no messages are being sent). On cycle 10, one of the cores generates a message destined for a cache bank somewhere else on the network. You observe the network on cycle 20 and see that this message has not departed the source location. Assume that all components are enabled (not powered off) and operating at full speed. There are no other messages present in the system at this time. Why could this be?",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "The system is using circuit switching, and there is a large delay to set up all links between source and destination.",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "E",
      "subproblem": [
        {
          "subproblem_context": "Slack\n\nAs you recall, we have discussed the idea of slack based prioritization for on-chip interconnects in class. In fact, you reviewed a paper that introduced this concept. The key idea was to prioritize the packet that has the least slack over others in the router, where the slack of a packet (ideally) is defined as the number of cycles the packet can be delayed without hurting performance.\n\nThe concept of slack is actually more general. It can be applied to prioritization at any shared resource, assuming the slack of a \"memory request\" can be estimated well.",
          "subproblem_question": "1) Suppose we have a mechanism that tries to estimate the exact slack of a memory request when the request is injected into the shared resources. Provide two reasons why estimating the exact slack of a packet might be difficult:",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "The exact latency of the request may not be known at the time of injection – the slack may change based on the state of the shared resources and the decisions made by them\n\nHow much the packet would affect performance may not be known at the time of injection – the overlap of latency of the packet may not be known at the time of injection",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "E",
      "subproblem": [
        {
          "subproblem_question": "2) What performance issue can slack-based prioritization cause to other processors in the system? Why?",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "Can cause starvation to some threads",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "E",
      "subproblem": [
        {
          "subproblem_question": "3) How can you solve this problem?",
          "subproblem_figures": []
        }
      ],
      "answer": [
        {
          "solution": "Batching",
          "solution_figures": []
        }
      ]
    },
    {
      "part": "F",
      "subproblem": [
        {
          "subproblem_context": "Dataflow",
          "subproblem_question": "What is the purpose of token tagging in dynamic dataflow architectures?",
          "subproblem_figures": []
        }